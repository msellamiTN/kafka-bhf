# Module 02 - Producer Idempotent (Ubuntu Enterprise)

## üìö Th√©orie (30%) - Producteur Kafka & Idempotence

### 2.1 Cycle de vie du producteur

```mermaid
graph TD
    A[Application BHF] --> B[Producer Record]
    B --> C[Serializer]
    C --> D[Partitioner]
    D --> E[Record Accumulator]
    E --> F[Network Sender]
    F --> G[Kafka Broker]
    G --> H[Leader Replica]
    H --> I[Follower Replicas]
    I --> J[ACK Response]
    J --> K[Producer Callback]
    
    style A fill:#e1f5fe
    style G fill:#f3e5f5
    style H fill:#e8f5e8
```

### 2.2 Probl√®me : Messages dupliqu√©s

#### üè¶ **Sc√©nario BHF critique**
```mermaid
sequenceDiagram
    participant App as Application BHF
    participant Net as Network
    participant Kafka as Kafka Broker
    
    App->>Net: Envoi transaction 1000‚Ç¨
    Net-->>App: Timeout (500ms)
    App->>Net: Retry transaction 1000‚Ç¨
    Net->>Kafka: Transaction 1000‚Ç¨ (1er envoi)
    Net->>Kafka: Transaction 1000‚Ç¨ (retry)
    Kafka-->>App: ACK 1er envoi
    Kafka-->>App: ACK retry
    
    Note over App,Kafka: üí• DOUBLE D√âBIT = 2000‚Ç¨
```

#### ‚ö†Ô∏è **Impact bancaire**
- **Perte financi√®re** : Double d√©bit = perte directe
- **R√©glementaire** : Non-conformit√© ACPR/ECB
- **R√©putation** : Perte de confiance client
- **Op√©rationnel** : Processus de remboursement manuel

### 2.3 Solution : Idempotence Kafka

#### üî• **Configuration idempotent BHF**
```properties
# Configuration obligatoire pour BHF
enable.idempotence=true
acks=all
retries=Integer.MAX_VALUE
max.in.flight.requests.per.connection=5

# Tuning production BHF
delivery.timeout.ms=30000
request.timeout.ms=20000
retry.backoff.ms=100
max.block.ms=60000
```

#### üéØ **M√©canisme interne**
```mermaid
graph LR
    A[Producer ID] --> B[Sequence Number]
    B --> C[Broker State]
    C --> D[Deduplication]
    
    A1["PID:12345"] --> B1["Seq:001"]
    B1 --> C1["(PID:12345, Seq:001)"]
    C1 --> D1["Accept"]
    
    A2["PID:12345"] --> B2["Seq:001"]
    B2 --> C2["(PID:12345, Seq:001)"]
    C2 --> D2["Duplicate ‚Üí Reject"]
    
    style D1 fill:#e8f5e8
    style D2 fill:#ffebee
```

### 2.4 Contraintes techniques - Matrix BHF

| Configuration | Valeur | Impact BHF | Pourquoi ? |
|---------------|--------|------------|------------|
| `enable.idempotence` | `true` | ‚úÖ S√©curit√© | Active l'anti-doublon |
| `acks` | `all` | ‚úÖ Durabilit√© | Garantit persistance compl√®te |
| `max.in.flight.requests` | `‚â§ 5` | ‚úÖ Ordre | Pr√©serve l'ordre des transactions |
| `retries` | `Integer.MAX_VALUE` | ‚úÖ R√©silience | Retry infini pour haute disponibilit√© |
| `delivery.timeout.ms` | `30000` | ‚úÖ SLA | Timeout 30s pour transactions critiques |

---

## üõ†Ô∏è Pratique (70%) - Producer Idempotent BHF Ubuntu

### Lab 02.1 - Producer Idempotent pour Transactions BHF

#### √âtape 1 : Configuration Maven Ubuntu

**pom.xml optimis√© pour Ubuntu Enterprise :**
```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <groupId>com.bhf.kafka</groupId>
  <artifactId>idempotent-producer</artifactId>
  <version>1.0.0</version>
  <name>BHF Idempotent Producer</name>
  <description>Kafka Idempotent Producer for BHF Banking - Ubuntu Enterprise</description>

  <properties>
    <maven.compiler.source>17</maven.compiler.source>
    <maven.compiler.target>17</maven.compiler.target>
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <kafka.version>3.4.1</kafka.version>
    <slf4j.version>1.7.36</slf4j.version>
    <logback.version>1.2.12</logback.version>
  </properties>

  <dependencies>
    <!-- Kafka Core -->
    <dependency>
      <groupId>org.apache.kafka</groupId>
      <artifactId>kafka-clients</artifactId>
      <version>${kafka.version}</version>
    </dependency>
    
    <!-- Logging -->
    <dependency>
      <groupId>org.slf4j</groupId>
      <artifactId>slf4j-api</artifactId>
      <version>${slf4j.version}</version>
    </dependency>
    <dependency>
      <groupId>ch.qos.logback</groupId>
      <artifactId>logback-classic</artifactId>
      <version>${logback.version}</version>
    </dependency>
    
    <!-- JSON Processing -->
    <dependency>
      <groupId>com.fasterxml.jackson.core</groupId>
      <artifactId>jackson-databind</artifactId>
      <version>2.15.2</version>
    </dependency>
    
    <!-- Testing -->
    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
      <version>4.13.2</version>
      <scope>test</scope>
    </dependency>
  </dependencies>

  <build>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-compiler-plugin</artifactId>
        <version>3.11.0</version>
        <configuration>
          <source>17</source>
          <target>17</target>
          <encoding>UTF-8</encoding>
        </configuration>
      </plugin>
      
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-jar-plugin</artifactId>
        <version>3.2.2</version>
        <configuration>
          <archive>
            <manifest>
              <mainClass>com.bhf.kafka.IdempotentProducerApp</mainClass>
            </manifest>
          </archive>
        </configuration>
      </plugin>
      
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-surefire-plugin</artifactId>
        <version>3.0.0-M9</version>
      </plugin>
    </plugins>
  </build>
</project>
```

#### √âtape 2 : Code Producer Idempotent Ubuntu - √âtape par √âtape

##### üìã **√âtape 2.1 - Structure du projet**

```bash
# Cr√©er la structure des dossiers
mkdir -p src/main/java/com/bhf/kafka
mkdir -p src/main/resources
mkdir -p src/test/java/com/bhf/kafka
mkdir -p logs
```

##### üìù **√âtape 2.2 - Code Producer Idempotent**

Cr√©er `src/main/java/com/bhf/kafka/IdempotentProducerApp.java` :

```java
package com.bhf.kafka;

import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;
import java.util.concurrent.ExecutionException;
import java.util.UUID;

/**
 * üè¶ Producer Idempotent BHF - Application principale
 * 
 * Ce producteur garantit l'unicit√© des messages m√™me en cas de retry
 * pour √©viter les doubles d√©bits dans le contexte bancaire BHF.
 */
public class IdempotentProducerApp {
    private static final Logger log = LoggerFactory.getLogger(IdempotentProducerApp.class);

    public static void main(String[] args) {
        log.info("üè¶ D√©marrage du Producer Idempotent BHF");
        
        // üî• √âtape 1 : Configuration du producer
        Properties props = configureProducer();
        
        try (KafkaProducer<String, String> producer = new KafkaProducer<>(props)) {
            
            // üî• √âtape 2 : Cr√©ation de la transaction BHF
            Transaction transaction = createBHFTransaction();
            
            // üî• √âtape 3 : Envoi de la transaction
            sendTransaction(producer, transaction);
            
            // üî• √âtape 4 : V√©rification du r√©sultat
            log.info("‚úÖ Transaction BHF envoy√©e avec succ√®s");
            
        } catch (Exception e) {
            log.error("‚ùå Erreur lors de l'envoi de la transaction", e);
            System.exit(1);
        }
    }
    
    /**
     * üî• Configuration du producer idempotent BHF
     */
    private static Properties configureProducer() {
        Properties props = new Properties();
        
        // Configuration de base
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        
        // üî• Configuration idempotent BHF - OBLIGATOIRE
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
        props.put(ProducerConfig.ACKS_CONFIG, "all");
        props.put(ProducerConfig.RETRIES_CONFIG, Integer.MAX_VALUE);
        props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5);
        
        // Tuning production BHF
        props.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, 30000);
        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 20000);
        props.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 100);
        
        log.info("üìã Configuration producer idempotent termin√©e");
        return props;
    }
    
    /**
     * üè¶ Cr√©ation d'une transaction BHF de test
     */
    private static Transaction createBHFTransaction() {
        String transactionId = "TXN-" + UUID.randomUUID().toString().substring(0, 8).toUpperCase();
        String accountId = "ACC-" + String.format("%06d", (int)(Math.random() * 999999));
        double amount = 100 + Math.random() * 10000;
        
        return new Transaction(transactionId, accountId, amount, "EUR", "DEBIT", "PENDING");
    }
    
    /**
     * üè¶ Envoi de la transaction avec monitoring d√©taill√©
     */
    private static void sendTransaction(KafkaProducer<String, String> producer, Transaction transaction) {
        String topic = "bhf-transactions";
        String key = transaction.getAccountId();
        String value = transaction.toJson();
        
        log.info("üì§ Envoi transaction BHF :");
        log.info("   Transaction ID : {}", transaction.getTransactionId());
        log.info("   Compte : {}", transaction.getAccountId());
        log.info("   Montant : {} {}", transaction.getAmount(), transaction.getCurrency());
        log.info("   Type : {}", transaction.getTransactionType());
        log.info("   Statut : {}", transaction.getStatus());
        
        try {
            ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);
            
            // üî• Envoi synchrone pour garantir la r√©ception
            RecordMetadata metadata = producer.send(record).get();
            
            log.info("‚úÖ Transaction envoy√©e avec succ√®s :");
            log.info("   Topic : {}", metadata.topic());
            log.info("   Partition : {}", metadata.partition());
            log.info("   Offset : {}", metadata.offset());
            log.info("   Timestamp : {}", metadata.timestamp());
            
            // Mise √† jour du statut
            transaction.setStatus("COMPLETED");
            
        } catch (InterruptedException | ExecutionException e) {
            log.error("‚ùå Erreur lors de l'envoi de la transaction {}", transaction.getTransactionId(), e);
            transaction.setStatus("FAILED");
            Thread.currentThread().interrupt();
        }
    }
    
    /**
     * üè¶ Mod√®le Transaction BHF
     */
    private static class Transaction {
        private String transactionId;
        private String accountId;
        private double amount;
        private String currency;
        private String transactionType;
        private String status;
        private long timestamp;
        
        public Transaction(String transactionId, String accountId, double amount, 
                          String currency, String transactionType, String status) {
            this.transactionId = transactionId;
            this.accountId = accountId;
            this.amount = amount;
            this.currency = currency;
            this.transactionType = transactionType;
            this.status = status;
            this.timestamp = System.currentTimeMillis();
        }
        
        // Getters
        public String getTransactionId() { return transactionId; }
        public String getAccountId() { return accountId; }
        public double getAmount() { return amount; }
        public String getCurrency() { return currency; }
        public String getTransactionType() { return transactionType; }
        public String getStatus() { return status; }
        public long getTimestamp() { return timestamp; }
        
        // Setters
        public void setStatus(String status) { this.status = status; }
        
        public String toJson() {
            return String.format(
                "{\"transactionId\":\"%s\",\"accountId\":\"%s\",\"amount\":%.2f,\"currency\":\"%s\",\"type\":\"%s\",\"status\":\"%s\",\"timestamp\":%d}",
                transactionId, accountId, amount, currency, transactionType, status, timestamp
            );
        }
    }
}
```
                
                log.info("‚úÖ Transaction envoy√©e avec succ√®s :");
                log.info("   Topic : {}", metadata.topic());
                log.info("   Partition : {}", metadata.partition());
                log.info("   Offset : {}", metadata.offset());
                log.info("   Timestamp : {}", metadata.timestamp());
                
            } catch (InterruptedException | ExecutionException e) {
                log.error("‚ùå Erreur lors de l'envoi de la transaction", e);
            }
        }
    }
}
```

#### √âtape 3 : Test de l'idempotence - √âtape par √âtape

##### üìã **√âtape 3.1 : Pr√©paration de l'environnement**
```bash
# V√©rifier que Kafka est d√©marr√©
if ! docker exec kafka kafka-topics --list --bootstrap-server localhost:9092 &>/dev/null; then
    echo "‚ùå Kafka n'est pas en cours d'ex√©cution"
    echo "D√©marrez Kafka avec: docker-compose -f docker-compose.enterprise.yml up -d"
    exit 1
fi

# V√©rifier que le topic existe
if ! docker exec kafka kafka-topics --describe --topic bhf-transactions --bootstrap-server localhost:9092 &>/dev/null; then
    echo "üìÑ Cr√©ation du topic bhf-transactions..."
    docker exec kafka kafka-topics --create --topic bhf-transactions --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
fi

# Nettoyer les logs pr√©c√©dents
docker exec kafka kafka-console-consumer --topic bhf-transactions --bootstrap-server localhost:9092 --from-beginning --timeout-ms 1000 > /dev/null || true
```

##### üìù **√âtape 3.2 : Compilation et Build**
```bash
# √âtape 3.2.1 : Compilation Maven
echo "üì¶ √âtape 3.2.1 - Compilation Maven..."
mvn clean compile

# V√©rification de la compilation
if [ $? -eq 0 ]; then
    echo "‚úÖ Compilation r√©ussie"
else
    echo "‚ùå √âchecec de la compilation"
    exit 1
fi

# √âtape 3.2.2 : Build Docker
echo "üì¶ √âtape 3.2.2 - Build Docker..."
./scripts/build-deploy.sh docker
```

##### üìù **√âtape 3.3 : D√©ploiement**
```bash
# √âtape 3.3.1 : D√©ploiement Docker Compose
echo "üì¶ √âtape 3.3.1 - D√©ploiement Docker Compose..."
./scripts/build-deploy.sh deploy

# √âtape 3.3.2 : V√©rification du d√©ploiement
echo "üì¶ √âtape 3.3.2 - V√©rification du d√©ploiement..."
./scripts/build-deploy.sh verify
```

##### üìù **√âtape 3.4 : Test d'idempotence**
```bash
# √âtape 3.4.1 : Test d'idempotence - 3 envois
echo "üîÑ √âtape 3.4.1 - Test d'idempotence (3 envois pour 1 seul message)"

# √âtape 3.4.2 : Ex√©cution du test
echo "üì§ Envoi de la transaction 3 fois..."
for i in {1..3}; do
    echo "üì§ Envoi $i/3"
    mvn exec:java -Dexec.mainClass="com.bhf.kafka.IdempotentProducerApp" -q
    sleep 1
done

# √âtape 3.4.3 : V√©rification des r√©sultats
echo "üîç √âtape 3.4.3 - V√©rification de l'unicit√©..."
message_count=$(docker exec kafka kafka-console-consumer --topic bhf-transactions --bootstrap-server localhost:9092 --from-beginning --timeout-ms 5000 2>/dev/null | wc -l)

if [ "$message_count" -eq 1 ]; then
    echo "‚úÖ Test d'idempotence r√©ussi : 1 seul message malgr√© 3 envois"
else
    echo "‚ùå Test d'idempotence √©chou√© : $message_count messages trouv√©s"
    echo "üîç Analyse des logs pour diagnostiquer..."
    docker-compose logs bhf-producer --tail=20
fi

# √âtape 3.4.4 : Affichage du message unique
echo "üìÑ Message unique re√ßu :"
docker exec kafka kafka-console-consumer --topic bhf-transactions --bootstrap-server localhost:9092 --from-beginning --property print.key=true --timeout-ms 5000 2>/dev/null
```

##### üìù **√âtape 3.5 : Test de performance**
```bash
# √âtape 3.5 : Test de performance - 100 envois rapides
echo "‚ö° √âtape 3.5 - Test de performance (100 envois rapides)"

# D√©marrer le timer
start_time=$(date +%s%N)

# Envoi 100 messages en parall√®le
for i in {1..100}; do
    mvn exec:java -Dexec.mainClass="com.bhf.kafka.IdempotentProducerApp" -q &
done

# Attendre fin de tous les processus
wait

# Calculer la dur√©e
end_time=$(date +%s%N)
duration=$((($end_time - $start_time) / 1000000)) # Convertir en millisecondes

echo "üìä Performance: 100 envois en ${duration}ms"
echo "üìà Moyenne: $(($duration / 100))ms par envoi"
echo "üìà Throughput: $(($duration / 1000)) tx/sec"
```

---

#### √âtape 4 : V√©rification des r√©sultats

```bash
# √âtape 4.1 : V√©rification de l'unicit√©
echo "üîç √âtape 4.1 - V√©rification de l'unicit√©..."

# Compter les messages
message_count=$(docker exec kafka kafka-console-consumer --topic bhf-transactions --bootstrap-server localhost:9092 --from-beginning --timeout-ms 5000 2>/dev/null | wc -l)

# Validation
if [ "$message_count" -eq 1 ]; then
    echo "‚úÖ Test d'idempotence r√©ussi : 1 seul message malgr√© 3 envois"
    echo "üîç Garantie d'unicit√© valid√©e"
else
    echo "‚ùå Test d'idempotence √©chou√© : $message_count messages trouv√©s"
    echo "üîç Analyse des logs pour diagnostiquer..."
    docker-compose logs bhf-producer --tail=20
fi

# √âtape 4.2 : Affichage du message unique
echo "üìÑ Message unique re√ßu :"
docker exec kafka kafka-console-consumer --topic bhf-transactions --bootstrap-server localhost:9092 --from-beginning --property print.key=true --timeout-ms 5000 2>/dev/null
```

#### √âtape 4.3 : Monitoring et m√©triques
```bash
# √âtape 4.3 : Monitoring du producer
echo "üìä √âtape 4.3 - Monitoring du producer..."

# Statut du conteneur
docker ps | grep bhf-idempotent-producer

# Logs r√©cents
docker-compose logs --tail=10 bhf-producer

# M√©triques Kafka
docker exec kafka jcmd 1 VM.native_memory summary 2>/dev/null || echo "JMX non disponible"

# Performance r√©seau
netstat -an | grep :9092 | wc -l | xargs echo "Kafka connections:"
```

---

## üéØ **Checkpoint Module 02 - Enhanced**

### ‚úÖ **Validation des comp√©tences techniques**

- [ ] **Configuration Maven** : pom.xml optimis√© pour Ubuntu Enterprise
- [ ] **Dockerfile** : Multi-stage build optimis√© avec s√©curit√©
- [ **Docker Compose** : Services orchestr√©s avec health checks
- [ ] **Code Java** : Architecture claire et comment√©e √©tape par √©tape
- [ ] **Tests automatis√©s** : Scripts de validation et performance
- [ ] **Monitoring** : Logs centralis√©s et m√©triques temps r√©el

### üìù **Questions de checkpoint avanc√©es**

1. **Pourquoi `max.in.flight.requests.per.connection=5` est crucial ?**
   - Garantit l'ordre des messages avec retries
   - Pr√©serve les garanties exactly-once
   - Impact sur latence vs ordering

2. **Comment Docker am√©liore-t-il le d√©ploiement ?**
   - Isolation compl√®te de l'environnement
   - Reproductibilit√© garantie
   - D√©ploiement one-command
   - Health checks automatiques

3. **Quelle est la diff√©rence entre `delivery.timeout.ms` et `request.timeout.ms` ?**
   - `delivery.timeout` : Temps total pour l'envoi complet
   - `request.timeout` : Timeout pour une seule requ√™te
   - Impact sur la gestion des timeouts r√©seau

---

## üöÄ **Prochain Module 02 - Workflow Complet**

```mermaid
graph TD
    A[D√©but] --> B[Configuration Maven]
    B --> C[Build Docker]
    C --> D[D√©ploiement]
    D --> E[Tests]
    E --> F[Validation]
    F --> G[Monitoring]
    
    A --> B --> C --> D --> E --> F --> G
    
    style A fill:#e1f5fe
    style G fill:#e8f5e8
```

---

## üéì **Ressources Additionnelles**

### üìö **Documentation technique**
- **Kafka Idempotence Guide** : Documentation officielle
- **Docker Best Practices** : Optimisation production
- **Ubuntu Performance Tuning** : Param√®tres syst√®me pour Kafka
- **BHF Architecture Patterns** : Patterns sp√©cifiques bancaires

### üõ†Ô∏è **Scripts et Outils**
- `build-deploy.sh` : Build et d√©ploiement automatis√©
- `test-idempotence.sh` : Tests d'idempotence et performance
- `monitor.sh` : Monitoring syst√®me et Kafka
- `cleanup.sh` : Nettoyage complet

### üéØ **Support et D√©pannage**
- **Logs centralis√©s** : Tous les logs dans `~/kafka-formation-bhf/logs/`
- **Health checks** : Monitoring automatique des services
- **M√©triques temps r√©el** : Performance et disponibilit√©
- **Alertes automatiques** : D√©tection d'anomalies

---

## üè¶ **Conclusion Module 02**

Le Module 02 est maintenant **100% Ubuntu Enterprise** avec :

- ‚úÖ **√âtapes d√©taill√©es** pour chaque √©tape
- ‚úÖ **Diagrammes Mermaid** pour visualisation
- ‚úÖ **Code comment√©** pour auto-formation
- ‚úÖ **Docker complet** avec build et d√©ploiement
- ‚úÖ **Scripts automatis√©s** pour validation
- ‚úÖ **Monitoring int√©gr√©** et optimis√©

**Module 02 - Producer Idempotent - Ubuntu Enterprise Ready!** üêßüê≥üè¶‚úÖ

---

## üéØ Checkpoint Module 02

### ‚úÖ Validation des comp√©tences

- [ ] Producer idempotent configur√©
- [ ] Messages uniques malgr√© retries
- [ ] Configuration BHF appliqu√©e
- [ ] Logs de retry et succ√®s observ√©s

### üìù Questions de checkpoint

1. **Pourquoi `acks=all` est obligatoire avec l'idempotence ?**
   - Garantit que tous les replicas ont persist√© avant l'ACK
   - Essentiel pour la d√©duplication

2. **Quel est l'impact sur la performance ?**
   - Latence l√©g√®rement augment√©e (attente de tous les replicas)
   - Mais garantie forte pour transactions bancaires

3. **Comment BHF utilise-t-il l'idempotence en production ?**
   - √âvite les doubles d√©bits
   - Garantit l'int√©grit√© des transactions
   - Conforme aux exigences r√©glementaires

---

## üöÄ Prochain module

**Module 03** : Consumer Read-Committed - Strat√©gies de commit et isolation des transactions.
