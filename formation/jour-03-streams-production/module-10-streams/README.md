# Module 10 - Kafka Streams WordCount EOS v2

## ğŸ“š ThÃ©orie (30%) - Kafka Streams Architecture

### 10.1 Streams Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Source Topic â”‚â”€â”€â”€â–¶â”‚   Stream    â”‚â”€â”€â”€â–¶â”‚Output Topic â”‚
â”‚   Input     â”‚    â”‚ Processing  â”‚    â”‚   Result    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ State Store â”‚
                   â”‚ (Local)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.2 Exactly-Once v2 vs v1

| CaractÃ©ristique | EOS v1 | EOS v2 |
|----------------|--------|--------|
| **Performance** | 2-phase commit | OptimisÃ© |
| **Latency** | Ã‰levÃ©e | RÃ©duite |
| **ScalabilitÃ©** | LimitÃ©e | AmÃ©liorÃ©e |
| **ComplexitÃ©** | Simple | ModerÃ©e |

### 10.3 WordCount Topology

```
Input Topic          Stream Processing          Output Topic
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚"hello world"â”‚â”€â”€â”€â–¶â”‚  ["hello", â”‚â”€â”€â”€â–¶â”‚"hello": 3   â”‚
â”‚"kafka rocks"â”‚    â”‚   "world"]  â”‚    â”‚"world": 2   â”‚
â”‚"hello kafka"â”‚    â”‚   ["kafka", â”‚    â”‚"kafka": 2   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   "rocks"]  â”‚    â”‚"rocks": 1   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚   Count     â”‚
                   â”‚ Aggregation â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Pratique (70%) - Streams WordCount EOS v2

### Lab 10.1 - Application Streams BHF

#### Ã‰tape 1 : Configuration Maven

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-streams</artifactId>
        <version>3.4.1</version>
    </dependency>
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-api</artifactId>
        <version>1.7.36</version>
    </dependency>
    <dependency>
        <groupId>ch.qos.logback</groupId>
        <artifactId>logback-classic</artifactId>
        <version>1.2.12</version>
    </dependency>
</dependencies>
```

#### Ã‰tape 2 : Application Streams

```java
package com.bhf.kafka.streams;

import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.Produced;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;
import java.util.concurrent.CountDownLatch;

public class BhfWordCountStreamsApp {
    private static final Logger log = LoggerFactory.getLogger(BhfWordCountStreamsApp.class);

    public static void main(String[] args) {
        // ğŸ”¥ Configuration Streams EOS v2
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "bhf-wordcount-eos-v2");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        // ğŸ”¥ Exactly-Once v2 pour BHF
        props.put(StreamsConfig.PROCESSING_GUARANTEE_CONFIG, StreamsConfig.EXACTLY_ONCE_V2);
        props.put(StreamsConfig.STATE_DIR_CONFIG, "/tmp/kafka-streams/bhf-wordcount");
        props.put(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 3);
        props.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 1000);

        StreamsBuilder builder = new StreamsBuilder();

        // ğŸ”¥ Construction de la topology WordCount
        KStream<String, String> textLines = builder.stream("bhf-transaction-events");
        
        KStream<String, Long> wordCounts = textLines
            .flatMapValues(textLine -> textLine.toLowerCase().split("\\W+"))
            .groupBy((key, word) -> word)
            .count();

        wordCounts.toStream().to("bhf-wordcount-output", 
            Produced.with(Serdes.String(), Serdes.Long()));

        Topology topology = builder.build();
        log.info("ğŸ¦ Topology BHF WordCount: {}", topology.describe());

        KafkaStreams streams = new KafkaStreams(topology, props);
        CountDownLatch latch = new CountDownLatch(1);

        // ğŸ”¥ Shutdown handler gracieux
        Runtime.getRuntime().addShutdownHook(new Thread(() -> {
            log.info("ğŸ”„ ArrÃªt de l'application Streams BHF");
            streams.close();
            latch.countDown();
        }));

        try {
            streams.start();
            log.info("âœ… Application BHF WordCount EOS v2 dÃ©marrÃ©e");
            latch.await();
        } catch (Throwable e) {
            log.error("ğŸ’¥ Erreur application BHF Streams", e);
            System.exit(1);
        }
    }
}
```

#### Ã‰tape 3 : Test de l'application

```powershell
# 1. CrÃ©er les topics BHF
docker exec kafka kafka-topics --create --topic bhf-transaction-events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
docker exec kafka kafka-topics --create --topic bhf-wordcount-output --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

# 2. Compiler et exÃ©cuter
mvn clean package
java -jar target/bhf-wordcount-streams.jar
```

#### Ã‰tape 4 : Envoi de donnÃ©es BHF

```powershell
# Producer d'Ã©vÃ©nements de transaction BHF
docker exec -it kafka kafka-console-producer --topic bhf-transaction-events --bootstrap-server localhost:9092

# Envoyer des Ã©vÃ©nements BHF
> payment-processed:{"amount":1500.00,"status":"COMPLETED","timestamp":1643723400123}
> payment-validated:{"amount":250.50,"status":"VALIDATED","timestamp":1643723400456}
> payment-failed:{"amount":100.00,"status":"FAILED","timestamp":1643723400789}
> payment-processed:{"amount":500.00,"status":"COMPLETED","timestamp":1643723401123}
```

#### Ã‰tape 5 : VÃ©rification des rÃ©sultats

```powershell
# Consumer des rÃ©sultats de comptage
docker exec kafka kafka-console-consumer --topic bhf-wordcount-output --bootstrap-server localhost:9092 --from-beginning --property print.key=true --property key.separator="="
```

**RÃ©sultat attendu :**
```
payment	3
processed	2
amount	4
1500.00	1
250.50	1
100.00	1
500.00	1
status	3
completed	2
validated	1
failed	1
timestamp	4
1643723400123	1
1643723400456	1
1643723400789	1
1643723401123	1
```

#### Ã‰tape 6 : Test de l'EOS v2

```powershell
# Envoyer les mÃªmes messages plusieurs fois
# Observer que le comptage reste cohÃ©rent (pas de double comptage)
```

---

## ğŸ¯ Checkpoint Module 10

### âœ… Validation des compÃ©tences

- [ ] Application Streams configurÃ©e avec EOS v2
- [ ] Topology WordCount fonctionnelle
- [ State stores locaux crÃ©Ã©s
- [ ] Exactly-Once garanti (pas de double comptage)

### ğŸ“ Questions de checkpoint

1. **Pourquoi EOS v2 est meilleur pour BHF ?**
   - Latence rÃ©duite pour transactions temps rÃ©el
   - ScalabilitÃ© amÃ©liorÃ©e pour gros volumes

2. **Quel est l'impact des state stores ?**
   - Persistance locale pour reprise aprÃ¨s crash
   - Performance accrue pour agrÃ©gations

3. **Comment monitorer une application Streams ?**
   - JMX metrics pour throughput/latence
   - State store size pour monitoring

---

## ğŸš€ Prochain module

**Module 11** : Monitoring Kafka - JMX, Prometheus, et alertes BHF.
