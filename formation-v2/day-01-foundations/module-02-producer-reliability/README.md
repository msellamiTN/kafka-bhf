# Module 02 - Fiabilit√© du Producteur Kafka (Idempotence) - Formation Auto-rythm√©e

## Dur√©e estim√©e

‚è±Ô∏è **60-90 minutes**

## Objectifs p√©dagogiques

√Ä la fin de ce module, vous serez capable de :

1. ‚úÖ Comprendre la diff√©rence entre un producer **idempotent** et **non-idempotent**
2. ‚úÖ Ma√Ætriser l'envoi **synchrone** vs **asynchrone** et les callbacks
3. ‚úÖ Configurer les **retries** et **timeouts** pour la fiabilit√©
4. ‚úÖ Comprendre l'impact des **cl√©s** sur le partitionnement
5. ‚úÖ Utiliser **Toxiproxy** pour simuler des pannes r√©seau
6. ‚úÖ Observer et d√©boguer les messages via **Kafka UI**
7. ‚úÖ Comprendre la **log compaction** et son utilit√©

---

## üìñ Partie Th√©orique Approfondie

### 1. Le Producteur Kafka en d√©tail

#### Cycle de vie d'un message

```mermaid
sequenceDiagram
    participant App as Application
    participant Prod as Producer
    participant Ser as Serializer
    participant Part as Partitioner
    participant Batch as RecordAccumulator
    participant Net as NetworkClient
    participant Broker as Kafka Broker
    
    App->>Prod: send(record)
    Prod->>Ser: serialize(key, value)
    Ser-->>Prod: byte[]
    Prod->>Part: partition(topic, key)
    Part-->>Prod: partition number
    Prod->>Batch: append to batch
    Note over Batch: Attend linger.ms ou batch.size
    Batch->>Net: send batch
    Net->>Broker: ProduceRequest
    Broker->>Broker: Write to log
    Broker->>Broker: Replicate
    Broker-->>Net: ProduceResponse (offset)
    Net-->>Prod: RecordMetadata
    Prod-->>App: Future/Callback
```

#### Composants internes du Producer

```mermaid
flowchart TB
    subgraph Producer["üì§ Kafka Producer"]
        subgraph Config["Configuration"]
            BS["batch.size<br/>16KB"]
            LI["linger.ms<br/>0ms"]
            AC["acks<br/>all"]
            RE["retries<br/>‚àû"]
        end
        
        subgraph Pipeline["Pipeline d'envoi"]
            SER["üîÑ Serializer<br/>Key + Value"]
            PAR["üìä Partitioner<br/>Round-robin / Hash"]
            ACC["üì¶ RecordAccumulator<br/>Batching"]
            SND["üåê Sender Thread<br/>Network I/O"]
        end
        
        SER --> PAR --> ACC --> SND
    end
    
    SND -->|"ProduceRequest"| K["üì¶ Kafka Broker"]
    K -->|"ACK"| SND
```

---

### 2. Les Acknowledgments (ACKs)

#### Niveaux d'ACK

```mermaid
flowchart TB
    subgraph acks0["acks=0 (Fire & Forget)"]
        P0["Producer"] -->|"Envoie"| B0["Broker"]
        P0 -.->|"N'attend pas"| X0["‚ùå"]
    end
    
    subgraph acks1["acks=1 (Leader Only)"]
        P1["Producer"] -->|"Envoie"| L1["Leader"]
        L1 -->|"ACK"| P1
        L1 -.->|"R√©plique apr√®s"| F1["Follower"]
    end
    
    subgraph acksAll["acks=all (Toutes les ISR)"]
        P2["Producer"] -->|"Envoie"| L2["Leader"]
        L2 -->|"R√©plique"| F2["Follower 1"]
        L2 -->|"R√©plique"| F3["Follower 2"]
        F2 -->|"ACK"| L2
        F3 -->|"ACK"| L2
        L2 -->|"ACK"| P2
    end
    
    style acks0 fill:#ffebee
    style acks1 fill:#fff3e0
    style acksAll fill:#e8f5e9
```

#### Comparaison des modes ACK

| Mode | Durabilit√© | Performance | Risque de perte |
|------|------------|-------------|-----------------|
| `acks=0` | ‚ùå Aucune | ‚ö°‚ö°‚ö° Maximale | √âlev√© |
| `acks=1` | ‚ö†Ô∏è Partielle | ‚ö°‚ö° Bonne | Moyen |
| `acks=all` | ‚úÖ Compl√®te | ‚ö° Mod√©r√©e | Minimal |

---

### 3. L'Idempotence en profondeur

#### Le probl√®me des doublons

```mermaid
sequenceDiagram
    participant P as Producer
    participant B as Broker
    
    P->>B: Message "order-123"
    B->>B: Write OK
    B--xP: ACK perdu (r√©seau)
    Note over P: Timeout ‚Üí Retry
    P->>B: Message "order-123" (retry)
    B->>B: Write OK (DOUBLON !)
    B-->>P: ACK
    
    Note over B: ‚ùå 2 messages identiques
```

#### Solution : Producer Idempotent

```mermaid
sequenceDiagram
    participant P as Producer (PID=42)
    participant B as Broker
    
    P->>B: Message "order-123" (seq=0)
    B->>B: Write OK, store seq=0
    B--xP: ACK perdu
    Note over P: Timeout ‚Üí Retry
    P->>B: Message "order-123" (seq=0, retry)
    B->>B: Check: seq=0 d√©j√† vu ‚Üí SKIP
    B-->>P: ACK (avec offset original)
    
    Note over B: ‚úÖ 1 seul message
```

#### M√©canisme interne

| Concept | Description |
|---------|-------------|
| **PID** (Producer ID) | Identifiant unique du producer (assign√© au d√©marrage) |
| **Epoch** | Version du producer (incr√©ment√© si red√©marrage) |
| **Sequence Number** | Num√©ro s√©quentiel par partition (0, 1, 2, ...) |

```
Message format avec idempotence:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PID: 42 ‚îÇ Epoch: 0 ‚îÇ SeqNum: 5 ‚îÇ Partition: 0  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                   Payload                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### 4. Retries et Gestion des erreurs

#### Timeline des retries

```mermaid
gantt
    title Sc√©nario de retry avec succ√®s
    dateFormat X
    axisFormat %s
    
    section Request 1
    Envoi initial        :a1, 0, 1
    Attente ACK         :a2, 1, 2
    Timeout             :crit, a3, 2, 3
    
    section Retry 1
    Backoff (100ms)     :b1, 3, 4
    Retry               :b2, 4, 5
    Attente ACK         :b3, 5, 6
    Timeout             :crit, b4, 6, 7
    
    section Retry 2
    Backoff (200ms)     :c1, 7, 9
    Retry               :c2, 9, 10
    ACK re√ßu            :done, c3, 10, 11
```

#### Param√®tres de retry

```mermaid
flowchart LR
    subgraph Timeouts["‚è±Ô∏è Timeouts"]
        RT["request.timeout.ms<br/>30s"]
        DT["delivery.timeout.ms<br/>120s"]
    end
    
    subgraph Retries["üîÑ Retries"]
        R["retries<br/>2147483647"]
        RB["retry.backoff.ms<br/>100ms"]
    end
    
    subgraph Constraint["‚ö†Ô∏è Contrainte"]
        C["delivery.timeout.ms ‚â•<br/>request.timeout.ms +<br/>linger.ms"]
    end
```

#### Erreurs r√©cup√©rables vs non-r√©cup√©rables

| Type | Exemples | Action |
|------|----------|--------|
| **R√©cup√©rable** | NetworkException, LeaderNotAvailable | Retry automatique |
| **Non-r√©cup√©rable** | InvalidTopicException, AuthorizationException | √âchec imm√©diat |
| **Fatal** | ProducerFenced, OutOfMemory | Arr√™t du producer |

---

### 5. Synchrone vs Asynchrone

#### Mode Synchrone

```mermaid
sequenceDiagram
    participant C as Client HTTP
    participant A as API
    participant P as Producer
    participant K as Kafka
    
    C->>A: POST /send (sync)
    A->>P: send()
    P->>K: ProduceRequest
    K-->>P: ProduceResponse
    P-->>A: RecordMetadata
    A-->>C: 200 OK + offset
    
    Note over C,A: ‚è±Ô∏è Client bloqu√© pendant l'envoi
```

#### Mode Asynchrone

```mermaid
sequenceDiagram
    participant C as Client HTTP
    participant A as API
    participant P as Producer
    participant K as Kafka
    participant S as StatusStore
    
    C->>A: POST /send (async)
    A->>P: send() + callback
    A->>S: Store requestId=PENDING
    A-->>C: 202 Accepted + requestId
    
    Note over C: Client lib√©r√© imm√©diatement
    
    P->>K: ProduceRequest
    K-->>P: ProduceResponse
    P->>S: Update requestId=OK
    
    C->>A: GET /status?requestId=...
    A->>S: Get status
    A-->>C: 200 OK + offset
```

#### Comparaison

| Aspect | Synchrone | Asynchrone |
|--------|-----------|------------|
| **Latence per√ßue** | Haute | Basse |
| **Complexit√©** | Simple | Plus complexe |
| **Gestion d'erreur** | Imm√©diate | Diff√©r√©e (polling) |
| **D√©bit** | Limit√© | √âlev√© |
| **Cas d'usage** | APIs critiques | Haute performance |

---

### 6. Partitionnement et Cl√©s

#### Strat√©gies de partitionnement

```mermaid
flowchart TB
    subgraph NoKey["Sans cl√© (Round-Robin)"]
        M1["Msg 1"] --> P0a["Partition 0"]
        M2["Msg 2"] --> P1a["Partition 1"]
        M3["Msg 3"] --> P2a["Partition 2"]
        M4["Msg 4"] --> P0a
    end
    
    subgraph WithKey["Avec cl√© (Hash)"]
        K1["key=A"] --> Hash1["hash('A') % 3 = 1"]
        K2["key=B"] --> Hash2["hash('B') % 3 = 0"]
        K3["key=A"] --> Hash3["hash('A') % 3 = 1"]
        
        Hash1 --> P1b["Partition 1"]
        Hash2 --> P0b["Partition 0"]
        Hash3 --> P1b
    end
    
    style NoKey fill:#fff3e0
    style WithKey fill:#e8f5e9
```

#### Garantie d'ordre avec les cl√©s

```
Topic: orders (3 partitions)

key="customer-42":
  Partition 1: [order-1] ‚Üí [order-2] ‚Üí [order-3] ‚úÖ Ordre garanti

key="customer-99":
  Partition 0: [order-A] ‚Üí [order-B] ‚Üí [order-C] ‚úÖ Ordre garanti

‚ö†Ô∏è Pas d'ordre garanti ENTRE les partitions
```

---

### 7. Log Compaction

#### Principe

```mermaid
flowchart LR
    subgraph Before["Avant Compaction"]
        B1["k1:v1"]
        B2["k2:v1"]
        B3["k1:v2"]
        B4["k3:v1"]
        B5["k1:v3"]
        B6["k2:v2"]
    end
    
    Compact["üîÑ Compaction"]
    
    subgraph After["Apr√®s Compaction"]
        A1["k3:v1"]
        A2["k1:v3"]
        A3["k2:v2"]
    end
    
    Before --> Compact --> After
```

#### Cas d'usage

| Sc√©nario | Exemple | Cl√© | Valeur |
|----------|---------|-----|--------|
| **√âtat utilisateur** | Profil client | userId | JSON profil |
| **Position GPS** | Flotte v√©hicules | vehicleId | lat/long |
| **Configuration** | Feature flags | featureName | enabled/disabled |
| **Inventaire** | Stock produits | productId | quantit√© |

---

### 8. Toxiproxy : Simulation de pannes

#### Architecture avec Toxiproxy

```mermaid
flowchart LR
    subgraph Normal["Mode Normal"]
        A1["API"] -->|"29092"| K1["Kafka"]
    end
    
    subgraph Proxy["Mode Proxy"]
        A2["API"] -->|"29093"| T["üíÄ Toxiproxy"]
        T -->|"29092"| K2["Kafka"]
        
        subgraph Toxics["Effets injectables"]
            L["‚è±Ô∏è Latency"]
            TO["‚èπÔ∏è Timeout"]
            BW["üìâ Bandwidth"]
            SL["üîÄ Slicer"]
        end
    end
    
    style T fill:#fff3e0
```

#### Types de pannes simulables

| Toxic | Effet | Param√®tres |
|-------|-------|------------|
| **latency** | Ajoute un d√©lai | `latency`, `jitter` |
| **timeout** | Coupe la connexion apr√®s N ms | `timeout` |
| **bandwidth** | Limite le d√©bit | `rate` (KB/s) |
| **slicer** | Fragmente les paquets | `average_size`, `delay` |
| **slow_close** | Fermeture lente | `delay` |

```json
// Exemple : ajouter 5 secondes de latence
{
  "name": "latency",
  "type": "latency",
  "stream": "downstream",
  "attributes": {
    "latency": 5000,
    "jitter": 500
  }
}
```

---

## üèóÔ∏è Architecture du module

```mermaid
flowchart TB
    subgraph Client["Votre Machine"]
        curl["üñ•Ô∏è curl / Postman"]
    end
    
    subgraph Docker["Docker Environment"]
        Java["‚òï Java API<br/>Port: 18080"]
        DotNet["üî∑ .NET API<br/>Port: 18081"]
        Toxi["üíÄ Toxiproxy<br/>Port: 8474<br/>(tests de pannes)"]
        K["üì¶ Kafka Broker<br/>Port: 29092"]
        UI["üìä Kafka UI<br/>Port: 8080"]
    end
    
    curl --> Java
    curl --> DotNet
    Java -->|"kafka:29092"| K
    DotNet -->|"kafka:29092"| K
    Toxi -.->|"proxy disponible<br/>sur :29093"| K
    K --> UI
    
    style Toxi fill:#fff3e0
    style K fill:#e8f5e8
```

> **Note** : Les APIs se connectent directement √† Kafka. Toxiproxy est disponible sur le port 29093 pour les tests d'injection de pannes manuels.

---

## üîå Ports et endpoints

### Services

| Service | Port Docker | Port K8s | URL |
|---------|-------------|----------|-----|
| Java API | 18080 | 31080 | http://localhost:18080 (Docker) / http://localhost:31080 (K8s) |
| .NET API | 18081 | 31081 | http://localhost:18081 (Docker) / http://localhost:31081 (K8s) |
| Toxiproxy | 8474 | 31474 | http://localhost:8474 (Docker) / http://localhost:31474 (K8s) |
| Kafka UI | 8080 | 30808 | http://localhost:8080 (Docker) / http://localhost:30808 (K8s) |

### Endpoints des APIs

| M√©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/health` | Health check |
| POST | `/api/v1/send` | Envoyer un message |
| GET | `/api/v1/status` | Statut d'un envoi async |

### Param√®tres de `/api/v1/send`

| Param√®tre | Valeurs | Description |
|-----------|---------|-------------|
| `mode` | `plain`, `idempotent` | Mode du producer |
| `sendMode` | `sync`, `async` | Synchrone ou asynchrone |
| `eventId` | string | Identifiant unique du message |
| `key` | string (optionnel) | Cl√© de partitionnement |
| `partition` | int (optionnel) | Partition cible |

---

## üìã Pr√©-requis

### Logiciels

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

- ‚úÖ Docker + Docker Compose
- ‚úÖ curl (ligne de commande)
- ‚úÖ Navigateur web

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

- ‚úÖ Cluster Kubernetes (K3s, OKD, ou OpenShift)
- ‚úÖ kubectl configur√©
- ‚úÖ Strimzi Operator install√©
- ‚úÖ curl (ligne de commande)

</details>

### Cluster Kafka d√©marr√©

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
cd formation-v2/
./scripts/up.sh   # Mode single-node par d√©faut
# ou: ./scripts/up.sh cluster   # Mode cluster 3 brokers
```

**V√©rification** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}' | grep kafka
```

**R√©sultat attendu** : `kafka` et `kafka-ui` sont `Up (healthy)`.

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# V√©rifier que le cluster Kafka est pr√™t
kubectl get kafka -n kafka

# R√©sultat attendu:
# NAME        DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   ...
# bhf-kafka   3                                              True    ...
```

**V√©rification des pods** :

```bash
kubectl get pods -n kafka -l strimzi.io/cluster=bhf-kafka
```

</details>

---

## ÔøΩÔ∏è Phase de D√©veloppement (Optionnel)

### Objectif

Si vous souhaitez **d√©velopper les APIs depuis z√©ro** plut√¥t que d'utiliser le code fourni, suivez les tutoriels d√©taill√©s ci-dessous.

> **Note** : Cette phase est **optionnelle**. Si vous voulez simplement d√©ployer et tester les APIs existantes, passez directement au [Lab 02.0](#-lab-020---d√©marrage-du-module).

---

### Option A : D√©velopper l'API Java

**Tutoriel complet** : [`TUTORIAL-JAVA.md`](./TUTORIAL-JAVA.md)

Ce tutoriel vous guide pas √† pas pour cr√©er l'API Java Spring Boot :

| √âtape | Description | Temps estim√© |
|-------|-------------|--------------|
| **√âtape 1** | Structure du projet Maven | 5 min |
| **√âtape 2** | Configuration `pom.xml` avec d√©pendances Kafka | 5 min |
| **√âtape 3** | Application Spring Boot principale | 5 min |
| **√âtape 4** | Service Producer (Plain + Idempotent) | 20 min |
| **√âtape 5** | Controllers REST (send + status + health) | 15 min |
| **√âtape 6** | Tests avec REST Client | 10 min |
| **√âtape 7** | Dockerfile multi-stage | 5 min |
| **√âtape 8** | Build et d√©ploiement Docker | 10 min |

**Pr√©requis pour le d√©veloppement Java** :
- VS Code avec extensions Java
- JDK 17+
- Maven 3.8+

**Commandes rapides** :

```bash
# Cr√©er la structure
mkdir -p java/src/main/java/com/bhf/m02/{api,kafka}

# Suivre le tutoriel TUTORIAL-JAVA.md
code TUTORIAL-JAVA.md

# Build local (sans Docker)
cd java
mvn clean package
mvn spring-boot:run

# Build Docker
docker build -t m02-java-api:latest -f Dockerfile .
```

---

### Option B : D√©velopper l'API .NET

**Tutoriel complet** : [`TUTORIAL-DOTNET.md`](./TUTORIAL-DOTNET.md)

Ce tutoriel vous guide pas √† pas pour cr√©er l'API .NET Minimal API :

| √âtape | Description | Temps estim√© |
|-------|-------------|--------------|
| **√âtape 1** | Cr√©er le projet .NET | 5 min |
| **√âtape 2** | `Program.cs` avec Confluent.Kafka | 20 min |
| **√âtape 3** | Endpoints REST (send + status + health) | 15 min |
| **√âtape 4** | Tests avec REST Client | 10 min |
| **√âtape 5** | Dockerfile | 5 min |
| **√âtape 6** | Build et d√©ploiement Docker | 10 min |

**Pr√©requis pour le d√©veloppement .NET** :
- VS Code avec extensions C#
- .NET SDK 8.0+

**Commandes rapides** :

```bash
# Cr√©er le projet
mkdir dotnet && cd dotnet
dotnet new web -n M02ProducerReliability
cd M02ProducerReliability
dotnet add package Confluent.Kafka

# Suivre le tutoriel TUTORIAL-DOTNET.md
code ../TUTORIAL-DOTNET.md

# Run local (sans Docker)
dotnet run

# Build Docker
docker build -t m02-dotnet-api:latest -f Dockerfile .
```

---

### Workflow Complet : D√©veloppement ‚Üí D√©ploiement

```mermaid
flowchart TB
    START["üéØ D√©but du Module"]
    
    subgraph DEV["üõ†Ô∏è Phase D√©veloppement (Optionnel)"]
        D1["üìñ Lire TUTORIAL-JAVA.md<br/>ou TUTORIAL-DOTNET.md"]
        D2["üíª Coder l'API<br/>√©tape par √©tape"]
        D3["üß™ Tester localement<br/>mvn spring-boot:run<br/>ou dotnet run"]
        D4["üê≥ Cr√©er Dockerfile"]
        D5["üì¶ Build image Docker<br/>docker build"]
        
        D1 --> D2 --> D3 --> D4 --> D5
    end
    
    subgraph DEPLOY["üöÄ Phase D√©ploiement"]
        L1["Lab 02.0: D√©marrer services"]
        L2["Lab 02.1: Tests synchrones"]
        L3["Lab 02.2: Tests asynchrones"]
        L4["Lab 02.3: Injection pannes"]
        L5["Lab 02.4: Validation idempotence"]
        
        L1 --> L2 --> L3 --> L4 --> L5
    end
    
    START --> |"Je veux coder"| DEV
    START --> |"Je veux d√©ployer"| DEPLOY
    DEV --> DEPLOY
    
    style DEV fill:#e3f2fd
    style DEPLOY fill:#f3e5f5
```

---

### Comparaison des Approches

| Approche | Avantages | Inconv√©nients | Temps |
|----------|-----------|---------------|-------|
| **D√©velopper depuis z√©ro** | ‚úÖ Comprendre chaque ligne<br/>‚úÖ Personnaliser le code<br/>‚úÖ Apprendre Spring Boot/.NET | ‚è±Ô∏è Plus long<br/>üêõ Risque d'erreurs | ~75 min |
| **Utiliser le code fourni** | ‚ö° Rapide<br/>‚úÖ Code test√©<br/>‚úÖ Focus sur Kafka | ‚ùå Moins d'apprentissage du code | ~10 min |

---

### Fichiers de R√©f√©rence

Le code source complet est disponible dans :

```text
module-02-producer-reliability/
‚îú‚îÄ‚îÄ java/                          # API Java Spring Boot
‚îÇ   ‚îú‚îÄ‚îÄ src/main/java/com/bhf/m02/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ M02ProducerReliabilityApplication.java
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ProducerController.java
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ HealthController.java
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ kafka/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ProducerService.java
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ dotnet/                        # API .NET Minimal API
‚îÇ   ‚îú‚îÄ‚îÄ M02ProducerReliability/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Program.cs
‚îÇ   ‚îú‚îÄ‚îÄ M02ProducerReliability.csproj
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ TUTORIAL-JAVA.md              # üìñ Guide d√©veloppement Java
‚îú‚îÄ‚îÄ TUTORIAL-DOTNET.md            # üìñ Guide d√©veloppement .NET
‚îî‚îÄ‚îÄ README.md                     # üìñ Ce fichier
```

---

## ÔøΩüìö Lab 02.0 - D√©marrage du module

### Objectif

D√©marrer les services du module (APIs Java/.NET + Toxiproxy) et v√©rifier leur bon fonctionnement.

> **Pr√©requis** : Si vous avez suivi la phase de d√©veloppement, assurez-vous que vos images Docker sont construites. Sinon, les images seront construites automatiquement lors du d√©ploiement.

---

### √âtape 1 - Positionnement

**Objectif** : Se placer dans le bon r√©pertoire.

```bash
cd formation-v2/
```

---

### √âtape 2 - D√©marrage des services

**Objectif** : Lancer les conteneurs du module.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Explication** : Cette commande lance :

- **Toxiproxy** : Proxy r√©seau pour injecter des pannes
- **toxiproxy-init** : Configuration initiale du proxy (one-shot)
- **m02-java-api** : API Spring Boot (Java)
- **m02-dotnet-api** : API ASP.NET (.NET)

**Commande** :

```bash
# Si le cluster Kafka est d√©j√† d√©marr√© via ./scripts/up.sh :
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml up -d --build
```

**‚è±Ô∏è Temps d'attente** : 2-3 minutes (build des images Java/.NET).

**R√©sultat attendu** :

```text
[+] Running 4/4
 ‚úî Container toxiproxy        Healthy
 ‚úî Container toxiproxy-init   Started
 ‚úî Container m02-java-api     Started
 ‚úî Container m02-dotnet-api   Started
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Explication** : En mode K8s, les APIs sont d√©ploy√©es comme des Deployments avec des Services NodePort. Les manifests YAML sont pr√©-configur√©s dans le dossier `k8s/`.

#### Architecture K8s du Module

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Namespace: kafka                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Java API      ‚îÇ  ‚îÇ   .NET API      ‚îÇ  ‚îÇ  Toxiproxy  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   NodePort:     ‚îÇ  ‚îÇ   NodePort:     ‚îÇ  ‚îÇ  NodePort:  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   31080         ‚îÇ  ‚îÇ   31081         ‚îÇ  ‚îÇ  31474      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                   ‚îÇ         ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                ‚îÇ                             ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ                    ‚îÇ   Kafka Bootstrap     ‚îÇ                 ‚îÇ
‚îÇ                    ‚îÇ   bhf-kafka:9092      ‚îÇ                 ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Option A : D√©ploiement automatis√© (Recommand√©)

Des scripts automatis√©s sont disponibles pour simplifier le d√©ploiement :

```bash
cd day-01-foundations/module-02-producer-reliability/scripts/k8s
chmod +x *.sh

# Pipeline complet (build + import + deploy + test)
sudo ./00-full-deploy.sh
```

**Ce script ex√©cute automatiquement** :
1. Construction des images Docker
2. Import des images dans K3s containerd
3. D√©ploiement des manifests Kubernetes
4. Validation des pods et services
5. Tests des APIs

#### Option B : D√©ploiement manuel √©tape par √©tape

**√âtape 2.1 - Construction des images Docker**

```bash
cd formation-v2/day-01-foundations/module-02-producer-reliability

# Build Java API
docker build -t m02-java-api:latest -f java/Dockerfile java/

# Build .NET API  
docker build -t m02-dotnet-api:latest -f dotnet/Dockerfile dotnet/

# V√©rifier les images
docker images | grep m02
```

**R√©sultat attendu** :

```text
m02-java-api      latest    xxxxx    xx seconds ago    438MB
m02-dotnet-api    latest    xxxxx    xx seconds ago    425MB
```

**√âtape 2.2 - Import des images dans K3s**

> **Important** : K3s utilise **containerd** comme runtime, pas Docker. Les images doivent √™tre export√©es puis import√©es dans containerd.

```bash
# Exporter les images Docker
sudo docker save m02-java-api:latest -o /tmp/m02-java-api.tar
sudo docker save m02-dotnet-api:latest -o /tmp/m02-dotnet-api.tar

# Importer dans K3s containerd
sudo k3s ctr images import /tmp/m02-java-api.tar
sudo k3s ctr images import /tmp/m02-dotnet-api.tar

# V√©rifier les images import√©es
sudo k3s ctr images list | grep m02
```

**R√©sultat attendu** :

```text
docker.io/library/m02-java-api:latest      application/vnd.oci.image.index.v1+json   sha256:xxx   119.5 MiB
docker.io/library/m02-dotnet-api:latest    application/vnd.oci.image.index.v1+json   sha256:xxx   115.4 MiB
```

**√âtape 2.3 - D√©ploiement des manifests**

```bash
# D√©ployer tous les services
kubectl apply -f k8s/

# Ou d√©ployer individuellement :
kubectl apply -f k8s/toxiproxy.yaml
kubectl apply -f k8s/toxiproxy-init.yaml
kubectl apply -f k8s/m02-java-api.yaml
kubectl apply -f k8s/m02-dotnet-api.yaml
```

**R√©sultat attendu** :

```text
deployment.apps/toxiproxy created
service/toxiproxy created
job.batch/toxiproxy-init created
deployment.apps/m02-java-api created
service/m02-java-api created
deployment.apps/m02-dotnet-api created
service/m02-dotnet-api created
```

**√âtape 2.4 - V√©rification des d√©ploiements**

```bash
# V√©rifier les pods
kubectl get pods -n kafka -l 'app in (toxiproxy,m02-java-api,m02-dotnet-api)'

# V√©rifier les services
kubectl get svc -n kafka | grep -E "m02|toxiproxy"
```

**R√©sultat attendu** :

```text
NAME                       READY   STATUS    RESTARTS   AGE
toxiproxy-xxxxx            1/1     Running   0          Xs
m02-java-api-xxxxx         1/1     Running   0          Xs
m02-dotnet-api-xxxxx       1/1     Running   0          Xs

NAME             TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                         AGE
m02-java-api     NodePort   10.x.x.x        <none>        8080:31080/TCP                  Xs
m02-dotnet-api   NodePort   10.x.x.x        <none>        8080:31081/TCP                  Xs
toxiproxy        NodePort   10.x.x.x        <none>        8474:31474/TCP,29093:32093/TCP  Xs
```

#### Tableau des ports K8s

| Service | Port interne | NodePort | Description |
| ------- | ------------ | -------- | ----------- |
| m02-java-api | 8080 | 31080 | API Java Spring Boot |
| m02-dotnet-api | 8080 | 31081 | API .NET ASP.NET |
| toxiproxy (API) | 8474 | 31474 | API de gestion Toxiproxy |
| toxiproxy (Proxy) | 29093 | 32093 | Proxy Kafka avec injection de latence |

#### D√©pannage K8s

**Probl√®me : ImagePullBackOff**

```bash
# V√©rifier que les images sont dans containerd
sudo k3s ctr images list | grep m02

# Si absent, r√©importer
sudo ./scripts/k8s/02-import-images.sh
```

**Probl√®me : Toxiproxy CrashLoopBackOff**

```bash
# V√©rifier les logs
kubectl logs -n kafka -l app=toxiproxy

# Le manifest utilise /version pour les health checks
# Si probl√®me persiste, red√©ployer
kubectl delete deployment toxiproxy -n kafka
kubectl apply -f k8s/toxiproxy.yaml
```

**Probl√®me : API ne r√©pond pas**

```bash
# Tester depuis l'int√©rieur du cluster
kubectl run curl --rm -it --image=curlimages/curl:8.5.0 -n kafka -- \
  curl http://m02-java-api:8080/health
```

</details>

---

### √âtape 3 - V√©rification des conteneurs

**Objectif** : S'assurer que tous les services sont op√©rationnels.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'
```

**R√©sultat attendu** :

| Conteneur | Statut attendu |
|-----------|----------------|
| kafka | Up (healthy) |
| kafka-ui | Up (healthy) |
| toxiproxy | Up |
| toxiproxy-init | Exited (0) ‚úÖ normal |
| m02-java-api | Up |
| m02-dotnet-api | Up |

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
kubectl get pods -n kafka
```

**R√©sultat attendu** :

| Pod | Statut attendu |
|-----|----------------|
| bhf-kafka-* | Running |
| m02-java-api-* | Running |
| m02-dotnet-api-* | Running (si d√©ploy√©) |

</details>

---

### √âtape 4 - Test de sant√© des APIs

**Objectif** : V√©rifier que les APIs r√©pondent.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
# Test Java API
curl -fsS http://localhost:18080/health
# R√©sultat attendu: OK

# Test .NET API
curl -fsS http://localhost:18081/health
# R√©sultat attendu: OK
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# Test Java API (NodePort 31080)
curl -fsS http://localhost:31080/health
# R√©sultat attendu: OK

# Test .NET API (NodePort 31081)
curl -fsS http://localhost:31081/health
# R√©sultat attendu: OK

# Si localhost ne fonctionne pas, utilisez l'IP du node:
curl -fsS http://$(hostname -I | awk '{print $1}'):31080/health
```

</details>

**‚úÖ Checkpoint 02.0** : Les deux APIs r√©pondent `OK`.

---

## üìö Lab 02.1 - Envoi synchrone (baseline)

### Objectif

Envoyer un message en mode **synchrone** et comprendre la r√©ponse avec l'offset.

---

### √âtape 5 - Envoi d'un message synchrone (Java API)

**Objectif** : Envoyer un message et recevoir l'ACK Kafka.

**Th√©orie** : En mode **synchrone**, l'API attend la confirmation de Kafka avant de r√©pondre. La r√©ponse contient :
- Le **topic** de destination
- La **partition** utilis√©e
- L'**offset** du message

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
# G√©n√©rer un ID unique
EVENT_ID="JAVA-SYNC-$(date +%s)"
echo "EventId: $EVENT_ID"

# Envoyer le message
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# G√©n√©rer un ID unique
EVENT_ID="JAVA-SYNC-$(date +%s)"
echo "EventId: $EVENT_ID"

# Envoyer le message (NodePort 31080)
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

**R√©sultat attendu** :

```json
{
  "status": "OK",
  "topic": "bhf-transactions",
  "partition": 0,
  "offset": 5,
  "eventId": "JAVA-SYNC-1706400000"
}
```

**Explication de la r√©ponse** :

| Champ | Description |
|-------|-------------|
| `status` | OK = message √©crit avec succ√®s |
| `topic` | Topic de destination |
| `partition` | Partition o√π le message est stock√© |
| `offset` | Position du message dans la partition |
| `eventId` | Identifiant unique envoy√© |

---

### √âtape 6 - Envoi avec l'API .NET

**Objectif** : V√©rifier que l'API .NET fonctionne de la m√™me mani√®re.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
EVENT_ID="DOTNET-SYNC-$(date +%s)"
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
EVENT_ID="DOTNET-SYNC-$(date +%s)"
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

**‚úÖ Checkpoint 02.1** : Les deux APIs retournent un JSON avec `partition` et `offset`.

---

### √âtape 7 - Visualisation dans Kafka UI

**Objectif** : Observer les messages envoy√©s.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Actions** :

1. Ouvrez **http://localhost:8080**
2. Cliquez sur le cluster **BHF-Training**
3. Menu **Topics** ‚Üí **bhf-transactions**
4. Onglet **Messages** ‚Üí **Fetch Messages**

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Via kubectl** :

```bash
# Consommer les messages directement
kubectl run kafka-consumer --rm -it --restart=Never \
  --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  -n kafka -- bin/kafka-console-consumer.sh \
  --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic bhf-transactions --from-beginning --max-messages 5
```

**Via Kafka UI (si d√©ploy√©)** : Acc√©dez via le NodePort ou Route configur√©.

</details>

**Ce que vous devez voir** :
- Vos messages avec les `eventId` envoy√©s
- La partition et l'offset de chaque message
- Le timestamp d'envoi

---

## üìö Lab 02.2 - Envoi asynchrone et callbacks

### Objectif

Comprendre le mode **asynchrone** et comment r√©cup√©rer le statut via polling.

---

### √âtape 8 - Envoi asynchrone (Java)

**Objectif** : Envoyer un message sans attendre l'ACK.

**Th√©orie** : En mode **asynchrone** :
1. L'API retourne imm√©diatement un `requestId`
2. Le message est envoy√© en arri√®re-plan
3. Vous consultez le statut via `/api/v1/status`

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
EVENT_ID="JAVA-ASYNC-$(date +%s)"

# Envoyer en asynchrone
RESPONSE=$(curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=idempotent&sendMode=async&eventId=$EVENT_ID")
echo "R√©ponse: $RESPONSE"

# Extraire le requestId
REQ_ID=$(echo "$RESPONSE" | sed -n 's/.*"requestId":"\([^"]*\)".*/\1/p')
echo "RequestId: $REQ_ID"
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
EVENT_ID="JAVA-ASYNC-$(date +%s)"

# Envoyer en asynchrone (NodePort 31080)
RESPONSE=$(curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=idempotent&sendMode=async&eventId=$EVENT_ID")
echo "R√©ponse: $RESPONSE"

# Extraire le requestId
REQ_ID=$(echo "$RESPONSE" | sed -n 's/.*"requestId":"\([^"]*\)".*/\1/p')
echo "RequestId: $REQ_ID"
```

</details>

**R√©sultat attendu** :

```json
{
  "status": "ACCEPTED",
  "requestId": "abc123-def456",
  "eventId": "JAVA-ASYNC-1706400000"
}
```

---

### √âtape 9 - Consultation du statut

**Objectif** : R√©cup√©rer le r√©sultat de l'envoi asynchrone.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
# Attendre 2 secondes pour que l'envoi se termine
sleep 2

# Consulter le statut
curl -fsS "http://localhost:18080/api/v1/status?requestId=$REQ_ID"
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# Attendre 2 secondes pour que l'envoi se termine
sleep 2

# Consulter le statut (NodePort 31080)
curl -fsS "http://localhost:31080/api/v1/status?requestId=$REQ_ID"
```

</details>

**R√©sultat attendu (succ√®s)** :

```json
{
  "state": "OK",
  "topic": "bhf-transactions",
  "partition": 1,
  "offset": 10
}
```

**R√©sultat possible (en cours)** :

```json
{
  "state": "PENDING"
}
```

**‚úÖ Checkpoint 02.2** : Vous savez envoyer en asynchrone et r√©cup√©rer le statut.

---

## üìö Lab 02.3 - Injection de pannes avec Toxiproxy

### Objectif

Simuler des probl√®mes r√©seau pour observer le comportement des retries.

---

### √âtape 10 - V√©rification du proxy Toxiproxy

**Objectif** : Confirmer que le proxy Kafka est configur√©.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
curl -fsS http://localhost:8474/proxies | python3 -m json.tool
```

**R√©sultat attendu** : Un proxy nomm√© `kafka` avec :
- `listen`: `0.0.0.0:29093`
- `upstream`: `kafka:29092`

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
# Obtenir l'IP du node
NODE_IP=$(hostname -I | awk '{print $1}')

# V√©rifier la version de Toxiproxy
curl -fsS http://${NODE_IP}:31474/version

# Lister les proxies configur√©s
curl -fsS http://${NODE_IP}:31474/proxies | python3 -m json.tool
```

**R√©sultat attendu** :

```json
{
    "version": "2.9.0"
}
```

Et un proxy nomm√© `kafka` avec :
- `listen`: `0.0.0.0:29093`
- `upstream`: `bhf-kafka-kafka-bootstrap:9092`

</details>

---

### √âtape 11 - Injection de latence

**Objectif** : Ajouter 5 secondes de latence sur les r√©ponses Kafka.

**Th√©orie** : La latence peut provoquer des **timeouts** c√¥t√© producer, ce qui d√©clenche des **retries**.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande pour ajouter la latence** :

```bash
curl -fsS -H 'Content-Type: application/json' \
  -X POST http://localhost:8474/proxies/kafka/toxics \
  -d '{
    "name": "latency",
    "type": "latency",
    "stream": "downstream",
    "attributes": {
      "latency": 5000,
      "jitter": 0
    }
  }'
```

**V√©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Commande pour ajouter la latence** :

```bash
NODE_IP=$(hostname -I | awk '{print $1}')

curl -fsS -H 'Content-Type: application/json' \
  -X POST http://${NODE_IP}:31474/proxies/kafka/toxics \
  -d '{
    "name": "latency",
    "type": "latency",
    "stream": "downstream",
    "attributes": {
      "latency": 5000,
      "jitter": 0
    }
  }'
```

**V√©rification** :

```bash
curl -fsS http://${NODE_IP}:31474/proxies/kafka/toxics
```

</details>

---

### √âtape 12 - Test avec latence

**Objectif** : Observer le comportement avec la latence.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
EVENT_ID="LATENCY-TEST-$(date +%s)"
time curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**Observation** : La requ√™te prend ~5 secondes de plus que d'habitude.

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
NODE_IP=$(hostname -I | awk '{print $1}')
EVENT_ID="LATENCY-TEST-$(date +%s)"

time curl -fsS -X POST "http://${NODE_IP}:31080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**Observation** : La requ√™te prend ~5 secondes de plus que d'habitude.

> **Note** : Pour que les APIs utilisent Toxiproxy, elles doivent √™tre configur√©es pour se connecter via le proxy (port 29093/32093) au lieu de directement √† Kafka. Par d√©faut, les manifests K8s connectent les APIs directement √† Kafka.

</details>

---

### √âtape 13 - Suppression de la latence

**Objectif** : Retirer la latence pour continuer les tests.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
curl -fsS -X DELETE http://localhost:8474/proxies/kafka/toxics/latency
```

**V√©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
# R√©sultat: [] (liste vide)
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
NODE_IP=$(hostname -I | awk '{print $1}')

curl -fsS -X DELETE http://${NODE_IP}:31474/proxies/kafka/toxics/latency
```

**V√©rification** :

```bash
curl -fsS http://${NODE_IP}:31474/proxies/kafka/toxics
# R√©sultat: [] (liste vide)
```

</details>

---

### Alternatives K8s pour simuler des pannes

En mode Kubernetes, vous pouvez √©galement utiliser ces m√©thodes natives pour simuler des pannes :

#### M√©thode 1 : Suppression de pod (simule un crash)

```bash
# Supprimer un pod Kafka pour simuler un crash
kubectl delete pod -n kafka -l strimzi.io/name=bhf-kafka-kafka --wait=false

# Observer la r√©cup√©ration automatique
kubectl get pods -n kafka -w
```

#### M√©thode 2 : NetworkPolicy (simule une partition r√©seau)

```bash
# Cr√©er une NetworkPolicy pour bloquer le trafic
kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: block-kafka-traffic
  namespace: kafka
spec:
  podSelector:
    matchLabels:
      app: m02-java-api
  policyTypes:
  - Egress
  egress: []
EOF

# Tester l'envoi (devrait √©chouer)
curl -X POST "http://${NODE_IP}:31080/api/v1/send?mode=plain&sendMode=sync&eventId=TEST"

# Supprimer la NetworkPolicy
kubectl delete networkpolicy block-kafka-traffic -n kafka
```

#### M√©thode 3 : Chaos Engineering avec Litmus ou Chaos Mesh

Pour des tests de chaos plus avanc√©s, consid√©rez :
- **Litmus Chaos** : https://litmuschaos.io/
- **Chaos Mesh** : https://chaos-mesh.org/

---

## üìö Lab 02.4 - Idempotence vs Plain (test cl√©)

### Objectif

Prouver que l'idempotence √©vite les doublons lors des retries.

---

### √âtape 14 - Ex√©cution du test automatis√©

**Objectif** : Valider le comportement idempotent vs non-idempotent.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Explication** : Le script `validate.sh` :

1. Injecte de la latence via Toxiproxy
2. Envoie des messages en mode `plain` et `idempotent`
3. Compte les messages dans Kafka
4. V√©rifie que `idempotent` = 1 message exactement

**Commande** :

```bash
./day-01-foundations/module-02-producer-reliability/scripts/validate.sh
```

**R√©sultat attendu** :

```text
OK: java_idempotent=1 java_plain=1 dotnet_idempotent=1 dotnet_plain=1
```

**Note** : Si `java_plain` ou `dotnet_plain` > 1, c'est normal ! Cela prouve que les retries peuvent cr√©er des doublons sans idempotence.

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Explication** : En mode K8s, le script valide le producteur idempotent sans injection de latence Toxiproxy.

**Commande** :

```bash
./day-01-foundations/module-02-producer-reliability/scripts/validate.sh --k8s
```

**R√©sultat attendu** :

```text
Running validation in K8s mode...
NOTE: K8s mode tests idempotent producer without Toxiproxy latency injection
OK: java_idempotent=1 (K8s mode - no latency injection)
```

> **Note** : Si les APIs ne sont pas d√©ploy√©es sur K8s, le script validera uniquement le cluster Kafka.

</details>

**‚úÖ Checkpoint 02.4** : L'idempotence produit exactement 1 message.

---

## üìö Lab 02.5 - Partitionnement

### Objectif

Comprendre comment les cl√©s influencent le partitionnement.

---

### √âtape 15 - Envoi sur des partitions diff√©rentes

**Objectif** : Envoyer des messages sur des partitions sp√©cifiques.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
# Message sur partition 0
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P0-$(date +%s)&partition=0"

# Message sur partition 1
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P1-$(date +%s)&partition=1"

# Message sur partition 2
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P2-$(date +%s)&partition=2"
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
# Message sur partition 0 (NodePort 31080)
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=P0-$(date +%s)&partition=0"

# Message sur partition 1
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=P1-$(date +%s)&partition=1"

# Message sur partition 2
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=P2-$(date +%s)&partition=2"
```

</details>

---

### √âtape 16 - V√©rification des partitions

**Objectif** : Confirmer la distribution des messages.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic bhf-transactions \
  --from-beginning \
  --timeout-ms 5000 \
  --property print.partition=true \
  --property print.offset=true
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
kubectl run kafka-consumer --rm -it --restart=Never \
  --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  -n kafka -- bin/kafka-console-consumer.sh \
  --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic bhf-transactions --from-beginning \
  --timeout-ms 5000 \
  --property print.partition=true \
  --property print.offset=true
```

</details>

**R√©sultat attendu** : Messages sur diff√©rentes partitions (0, 1, 2).

---

## üìö Lab 02.6 - Log compaction

### Objectif

Comprendre la compaction et son utilit√© pour les √©tats.

---

### √âtape 17 - Cr√©ation d'un topic compact√©

**Objectif** : Cr√©er un topic avec la politique de compaction.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic bhf-compact-demo \
  --partitions 1 \
  --replication-factor 1 \
  --config cleanup.policy=compact \
  --config segment.ms=1000 \
  --config min.cleanable.dirty.ratio=0.01
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
cat <<EOF | kubectl apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: bhf-compact-demo
  namespace: kafka
  labels:
    strimzi.io/cluster: bhf-kafka
spec:
  partitions: 1
  replicas: 3
  config:
    cleanup.policy: compact
    segment.ms: "1000"
    min.cleanable.dirty.ratio: "0.01"
EOF
```

</details>

---

### √âtape 18 - Envoi de plusieurs versions

**Objectif** : Envoyer plusieurs valeurs pour la m√™me cl√©.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

```bash
KEY="customer-42"

# Version 1
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V1&key=$KEY"

# Version 2
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V2&key=$KEY"

# Version 3 (finale)
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V3&key=$KEY"
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

```bash
KEY="customer-42"

# Version 1 (NodePort 31081)
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V1&key=$KEY"

# Version 2
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V2&key=$KEY"

# Version 3 (finale)
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V3&key=$KEY"
```

</details>

**Note** : Apr√®s compaction (asynchrone), seul `V3` sera conserv√© pour `customer-42`.

**‚úÖ Checkpoint 02.6** : Vous comprenez la log compaction.

---

## ‚úÖ R√©capitulatif des checkpoints

| # | Checkpoint | Statut |
|---|------------|--------|
| 02.0 | APIs Java et .NET r√©pondent OK | ‚òê |
| 02.1 | Envoi synchrone retourne partition/offset | ‚òê |
| 02.2 | Envoi asynchrone + r√©cup√©ration du statut | ‚òê |
| 02.3 | Injection de latence via Toxiproxy | ‚òê |
| 02.4 | Script validate.sh retourne OK | ‚òê |
| 02.5 | Messages sur diff√©rentes partitions | ‚òê |
| 02.6 | Compr√©hension de la log compaction | ‚òê |

---

## üîß Troubleshooting

### APIs ne d√©marrent pas

**Sympt√¥me** : `m02-java-api` ou `m02-dotnet-api` en erreur.

**Solution** :

```bash
# V√©rifier les logs
docker logs m02-java-api --tail 100
docker logs m02-dotnet-api --tail 100

# Reconstruire les images
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml \
  up -d --build --force-recreate
```

### Toxiproxy ne r√©pond pas

**Sympt√¥me** : `curl: (7) Failed to connect to localhost port 8474`.

**Solution** :

```bash
# V√©rifier les logs
docker logs toxiproxy

# V√©rifier le healthcheck
docker inspect toxiproxy --format='{{.State.Health.Status}}'

# Red√©marrer si n√©cessaire
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml restart toxiproxy

# Recr√©er le proxy apr√®s red√©marrage
curl -fsS -X POST http://localhost:8474/proxies \
  -H 'Content-Type: application/json' \
  -d '{"name":"kafka","listen":"0.0.0.0:29093","upstream":"kafka:29092"}'
```

### Messages non visibles dans Kafka UI

**Sympt√¥me** : Le topic existe mais pas de messages.

**Solution** :

1. Cliquez sur **Fetch Messages**
2. R√©glez le filtre sur **Earliest** (depuis le d√©but)
3. V√©rifiez le bon topic (`bhf-transactions`)

---

## üßπ Nettoyage

**Objectif** : Arr√™ter les services du module.

**Commande** :

```bash
# Arr√™ter uniquement le module
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml down

# Arr√™ter tout (module + cluster Kafka)
./scripts/down.sh
```

---

## üìñ Pour aller plus loin

### Exercices suppl√©mentaires

1. **Modifiez les timeouts** dans `docker-compose.module.yml` et observez l'impact
2. **Injectez un timeout complet** avec Toxiproxy et observez les erreurs
3. **Testez avec diff√©rentes cl√©s** et observez la distribution sur les partitions

### Ressources

- [Kafka Producer Configuration](https://kafka.apache.org/documentation/#producerconfigs)
- [Idempotent Producer](https://kafka.apache.org/documentation/#semantics)
- [Toxiproxy Documentation](https://github.com/Shopify/toxiproxy)

---

## üõ†Ô∏è Tutorials pas-√†-pas

| IDE | Tutorial | Description |
|-----|----------|-------------|
| **VS Code** | [TUTORIAL-DOTNET.md](./TUTORIAL-DOTNET.md) | Minimal API avec Confluent.Kafka |
| **Visual Studio 2022** | [TUTORIAL-VS2022.md](./TUTORIAL-VS2022.md) | Projet complet avec debugging, tests, Swagger |
| **IntelliJ / VS Code** | [TUTORIAL-JAVA.md](./TUTORIAL-JAVA.md) | Spring Boot avec kafka-clients |

---

## ‚û°Ô∏è Module suivant

Une fois ce module termin√©, passez au :

üëâ **[Module 03 - Consumer Read-Committed](../module-03-consumer-read-committed/README.md)**
