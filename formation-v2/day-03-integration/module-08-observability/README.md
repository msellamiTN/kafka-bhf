# ğŸ“Š Module 08 - ObservabilitÃ© & Monitoring

| DurÃ©e | Niveau | PrÃ©requis |
|-------|--------|-----------|
| 2 heures | IntermÃ©diaire | Modules 01-07 complÃ©tÃ©s |

## ğŸ¯ Objectifs d'apprentissage

Ã€ la fin de ce module, vous serez capable de :

- âœ… Collecter les mÃ©triques Kafka via JMX
- âœ… Monitorer le consumer lag
- âœ… Configurer des alertes
- âœ… Mettre en place le tracing distribuÃ©

---

## ğŸ“š Partie ThÃ©orique (30%)

### 1. MÃ©triques clÃ©s Kafka

```mermaid
flowchart LR
    B["ğŸ–¥ï¸ Broker"] --- P["ğŸ“¤ Producer"] --- C["ğŸ“¥ Consumer"]
    C --> LAG["ğŸ”¥ LAG"]
    style LAG fill:#ff6b6b,color:#fff
```

---

### 2. Consumer Lag - La mÃ©trique critique

```mermaid
flowchart LR
    subgraph lag["LAG = 4"]
        CO["Consumer: 8"] -.->|"ğŸ”¥ LAG"| LEO["Log End: 12"]
    end
    style lag fill:#ffcccc
```

> **LAG = Log End Offset - Consumer Committed Offset = 4**

| LAG | Status |
|-----|--------|
| **= 0** | âœ… Parfait, consumer Ã  jour |
| **< 100** | ğŸŸ¡ Normal, lÃ©gÃ¨re latence |
| **> 1000** | âš ï¸ Attention, consumer lent |
| **croissant** | ğŸ”¥ ALERTE, consumer ne suit pas |

#### Causes du lag Ã©levÃ©

| Cause | SymptÃ´me | Solution |
|-------|----------|----------|
| Consumer lent | Lag croissant constant | Optimiser le traitement |
| Pas assez de consumers | Lag sur toutes partitions | Ajouter des consumers |
| Rebalancing frÃ©quent | Pics de lag | Optimiser session.timeout |
| GC pauses | Lag intermittent | Tuner la JVM |

---

### 3. Architecture de monitoring

```mermaid
flowchart LR
    K["ğŸ–¥ï¸ Kafka"] --> JMX["ğŸ”Œ JMX"] --> PROM[("ğŸ“ˆ Prometheus")] --> GRAF["ğŸ“Š Grafana"] --> ALERT["ğŸš¨ Alert"]
    style PROM fill:#e8f5e9
```

---

### 4. TraÃ§age distribuÃ©

Le traÃ§age distribuÃ© permet de suivre une requÃªte Ã  travers plusieurs services et topics Kafka.

```mermaid
flowchart LR
    subgraph Trace["ğŸ”— Trace ID: abc-123"]
        SA["ğŸ”µ Service A<br/>Span 1"] -->|"ğŸ“¨ order.created"| K1["ğŸ“¦ Kafka"]
        K1 -->|"ğŸ“¥"| SB["ğŸŸ¢ Service B<br/>Span 2"]
        SB -->|"ğŸ“¨ payment.requested"| K2["ğŸ“¦ Kafka"]
        K2 -->|"ğŸ“¥"| SC["ğŸŸ  Service C<br/>Span 3"]
    end
    
    style SA fill:#e3f2fd
    style SB fill:#e8f5e9
    style SC fill:#fff3e0
```

#### Propagation du contexte

Les **headers Kafka** transportent le contexte de trace selon le standard W3C Trace Context :

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Headers Kafka                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  traceparent: 00-0af7651916cd43dd8448eb211c80319c-b7ad6b...â”‚
â”‚  tracestate: vendor=value                                   â”‚
â”‚  correlation-id: order-12345                                â”‚
â”‚  causation-id: event-67890                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Header | Format | Description |
|--------|--------|-------------|
| **traceparent** | `version-traceid-spanid-flags` | Identifiant W3C standard |
| **tracestate** | `vendor=value` | MÃ©tadonnÃ©es vendor-specific |
| **correlation-id** | UUID | ID de corrÃ©lation mÃ©tier |
| **causation-id** | UUID | ID de l'Ã©vÃ©nement parent |

#### CorrÃ©lation des Ã©vÃ©nements

```mermaid
flowchart TB
    subgraph Correlation["ğŸ“Š CorrÃ©lation des Ã©vÃ©nements"]
        E1["ğŸ›’ OrderCreated<br/>correlation: order-123<br/>causation: null"]
        E2["ğŸ’³ PaymentRequested<br/>correlation: order-123<br/>causation: order-created-1"]
        E3["ğŸ“¦ ShipmentCreated<br/>correlation: order-123<br/>causation: payment-completed-2"]
    end
    
    E1 -->|"cause"| E2 -->|"cause"| E3
```

#### ImplÃ©mentation Java avec OpenTelemetry

```java
// Producer - Injection du contexte
@Autowired
private Tracer tracer;

public void send(String topic, String key, String value) {
    Span span = tracer.spanBuilder("kafka-produce")
        .setSpanKind(SpanKind.PRODUCER)
        .startSpan();
    
    try (Scope scope = span.makeCurrent()) {
        ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, value);
        
        // Injecter le contexte dans les headers
        Context context = Context.current();
        GlobalOpenTelemetry.getPropagators().getTextMapPropagator()
            .inject(context, record.headers(), (headers, k, v) -> 
                headers.add(k, v.getBytes()));
        
        producer.send(record);
    } finally {
        span.end();
    }
}
```

```java
// Consumer - Extraction du contexte
public void consume(ConsumerRecord<String, String> record) {
    // Extraire le contexte des headers
    Context extractedContext = GlobalOpenTelemetry.getPropagators()
        .getTextMapPropagator()
        .extract(Context.current(), record.headers(), 
            (headers, key) -> {
                Header h = headers.lastHeader(key);
                return h != null ? new String(h.value()) : null;
            });
    
    Span span = tracer.spanBuilder("kafka-consume")
        .setSpanKind(SpanKind.CONSUMER)
        .setParent(extractedContext)
        .startSpan();
    
    try (Scope scope = span.makeCurrent()) {
        // Traitement du message
        processMessage(record);
    } finally {
        span.end();
    }
}
```

#### Visualisation dans Jaeger

```mermaid
gantt
    title Trace Timeline - Order Processing
    dateFormat X
    axisFormat %s
    
    section Service A
    OrderCreated (50ms)     :a1, 0, 50
    
    section Kafka
    Produce (5ms)           :k1, 50, 55
    Consume (5ms)           :k2, 55, 60
    
    section Service B
    PaymentProcess (100ms)  :b1, 60, 160
    
    section Service C
    ShipmentCreate (30ms)   :c1, 160, 190
```

---

## ğŸ”Œ Ports et Services

| Service | Port | Description |
|---------|------|-------------|
| Prometheus | 9090 | MÃ©triques |
| Grafana | 3000 | Dashboards |
| JMX Exporter | 9404 | Export mÃ©triques Kafka |
| Jaeger | 16686 | Tracing UI |

---

## ğŸ› ï¸ Partie Pratique (70%)

### PrÃ©requis

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
cd formation-v2/
./scripts/up.sh
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# VÃ©rifier que le cluster Kafka est prÃªt
kubectl get kafka -n kafka
kubectl get pods -n kafka -l strimzi.io/cluster=bhf-kafka

# VÃ©rifier les mÃ©triques JMX exposÃ©es par Strimzi
kubectl get pods -n kafka -l strimzi.io/kind=Kafka -o jsonpath='{.items[*].metadata.name}'
```

</details>

---

### Ã‰tape 1 - DÃ©marrer le stack de monitoring

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
docker compose -f day-03-integration/module-08-observability/docker-compose.module.yml up -d
```

**VÃ©rification** :

```bash
# Prometheus
curl -s http://localhost:9090/-/healthy

# Grafana
curl -s http://localhost:3000/api/health
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# DÃ©ployer Prometheus et Grafana via Helm
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Installer kube-prometheus-stack
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace \
  --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false

# VÃ©rifier le dÃ©ploiement
kubectl get pods -n monitoring
```

**AccÃ¨s** :

```bash
# Prometheus (port-forward)
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090

# Grafana (port-forward)
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80
# Login: admin / prom-operator
```

> **Note** : Strimzi expose automatiquement les mÃ©triques JMX via PodMonitor CRs.

</details>

---

### Ã‰tape 2 - Lab 1 : Explorer les mÃ©triques Kafka

#### 2.1 Via Kafka CLI

```bash
# Consumer lag pour un groupe
docker exec kafka kafka-consumer-groups \
  --describe \
  --group orders-consumer-group \
  --bootstrap-server localhost:9092
```

**RÃ©sultat attendu** :

```
GROUP                TOPIC      PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
orders-consumer-group orders    0          100             105             5
orders-consumer-group orders    1          200             200             0
```

#### 2.2 Via JMX

```bash
# Lister les MBeans Kafka
docker exec kafka kafka-run-class kafka.tools.JmxTool \
  --jmx-url service:jmx:rmi:///jndi/rmi://localhost:9999/jmxrmi \
  --object-name 'kafka.server:type=BrokerTopicMetrics,name=*'
```

---

### Ã‰tape 3 - Lab 2 : Configurer Prometheus

#### 3.1 VÃ©rifier les targets

Ouvrez http://localhost:9090/targets

**Targets attendus** :
- `kafka-jmx-exporter` : UP
- `kafka-ui` : UP (si configurÃ©)

#### 3.2 ExÃ©cuter des requÃªtes PromQL

```promql
# Messages produits par seconde
rate(kafka_server_brokertopicmetrics_messagesin_total[5m])

# Consumer lag
kafka_consumer_consumer_fetch_manager_metrics_records_lag

# Bytes in/out
rate(kafka_server_brokertopicmetrics_bytesin_total[5m])
```

---

### Ã‰tape 4 - Lab 3 : Dashboard Grafana

#### 4.1 AccÃ©der Ã  Grafana

1. Ouvrez http://localhost:3000
2. Login: `admin` / `admin`
3. Changez le mot de passe si demandÃ©

#### 4.2 Importer un dashboard

1. Cliquez sur **+** â†’ **Import**
2. Entrez l'ID du dashboard Kafka : `7589`
3. SÃ©lectionnez la datasource Prometheus
4. Cliquez sur **Import**

#### 4.3 Explorer les mÃ©triques

- **Throughput** : Messages/sec, Bytes/sec
- **Latency** : Request latency percentiles
- **Consumer Lag** : Par topic et partition
- **Resources** : CPU, Memory, Disk

---

### Ã‰tape 5 - Lab 4 : Simuler du lag et observer

#### 5.1 CrÃ©er du lag artificiellement

```bash
# Produire beaucoup de messages
for i in {1..1000}; do
  echo "message-$i" | docker exec -i kafka kafka-console-producer \
    --topic test-lag \
    --bootstrap-server localhost:9092
done
```

#### 5.2 Observer le lag dans Grafana

1. Allez sur le dashboard Kafka
2. Trouvez le panel "Consumer Lag"
3. Observez le lag augmenter puis diminuer quand le consumer rattrape

---

### Ã‰tape 6 - Lab 5 : Configurer une alerte

#### 6.1 CrÃ©er une rÃ¨gle d'alerte dans Grafana

1. Allez dans **Alerting** â†’ **Alert rules**
2. Cliquez sur **New alert rule**
3. Configurez :
   - **Name** : High Consumer Lag
   - **Query** : `kafka_consumergroup_lag > 1000`
   - **Condition** : Is above 1000
   - **Evaluation** : Every 1m for 5m
4. Sauvegardez

#### 6.2 Tester l'alerte

Reproduisez du lag et vÃ©rifiez que l'alerte se dÃ©clenche.

---

## âœ… Checkpoint de validation

- [ ] Stack de monitoring dÃ©marrÃ©
- [ ] MÃ©triques Kafka visibles dans Prometheus
- [ ] Dashboard Grafana importÃ© et fonctionnel
- [ ] Consumer lag visible et compris
- [ ] Alerte configurÃ©e et testÃ©e

---

## ğŸ”§ Troubleshooting

### Prometheus ne collecte pas les mÃ©triques

```bash
# VÃ©rifier JMX Exporter
curl -s http://localhost:9404/metrics | head -20
```

### Grafana ne montre pas de donnÃ©es

1. VÃ©rifiez la datasource Prometheus
2. Testez une requÃªte simple : `up`
3. VÃ©rifiez les time ranges

---

## ğŸ§¹ Nettoyage

```bash
docker compose -f day-03-integration/module-08-observability/docker-compose.module.yml down -v
```

---

## ğŸ“– Pour aller plus loin

### Exercices supplÃ©mentaires

1. **Configurez des alertes Slack** via Grafana
2. **Ajoutez le tracing** avec Jaeger
3. **CrÃ©ez un dashboard custom** pour votre application

### Ressources

- [Kafka Monitoring Documentation](https://kafka.apache.org/documentation/#monitoring)
- [Prometheus + Kafka](https://prometheus.io/docs/instrumenting/exporters/)
- [Grafana Kafka Dashboards](https://grafana.com/grafana/dashboards/)
