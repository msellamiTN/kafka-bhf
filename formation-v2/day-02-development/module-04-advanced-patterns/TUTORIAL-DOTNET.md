# ğŸ› ï¸ Tutorial VS Code : API .NET - Consumer Kafka avec Rebalancing

## ğŸ“‹ Vue d'ensemble

Ce tutorial vous guide pas Ã  pas pour implÃ©menter un **Consumer Kafka ASP.NET** avec :
- **Gestion du Rebalancing** (CooperativeSticky)
- **Callbacks de partition** (Assigned, Revoked, Lost)
- **Commit manuel** des offsets
- **API REST** pour monitoring

```mermaid
flowchart LR
    K["ğŸ“¦ Kafka"] --> C["ğŸ”„ Consumer"] --> API["ğŸŒ REST API"]
    C -->|"rebalance"| CB["ğŸ“Š Callbacks"]
```

---

## ğŸ¯ PrÃ©requis

### Outils requis

| Outil | Version | Installation |
|-------|---------|--------------|
| **VS Code** | Latest | [code.visualstudio.com](https://code.visualstudio.com) |
| **.NET SDK** | 8.0+ | `winget install Microsoft.DotNet.SDK.8` |
| **Docker Desktop** | Latest | [docker.com](https://docker.com) |

### Extensions VS Code recommandÃ©es

```bash
# Installation via CLI
code --install-extension ms-dotnettools.csharp
code --install-extension ms-dotnettools.csdevkit
code --install-extension ms-azuretools.vscode-docker
code --install-extension humao.rest-client
```

---

## ğŸ“ Ã‰tape 1 : CrÃ©er le projet

### 1.1 Initialiser le projet .NET

```powershell
# CrÃ©er le dossier et initialiser
mkdir module04-dotnet-consumer
cd module04-dotnet-consumer

# CrÃ©er un projet ASP.NET Minimal API
dotnet new web -n Module04Consumer

# Entrer dans le projet
cd Module04Consumer

# Ouvrir dans VS Code
code .
```

### 1.2 Ajouter le package Confluent.Kafka

```powershell
dotnet add package Confluent.Kafka
```

### 1.3 Structure finale

```
Module04Consumer/
â”œâ”€â”€ Module04Consumer.csproj    # Configuration projet
â”œâ”€â”€ Program.cs                 # Code principal
â”œâ”€â”€ Dockerfile                 # Image Docker
â””â”€â”€ requests.http              # Tests API
```

---

## ğŸ“¦ Ã‰tape 2 : Configuration du projet (.csproj)

### 2.1 VÃ©rifier `Module04Consumer.csproj`

```xml
<Project Sdk="Microsoft.NET.Sdk.Web">

  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <Nullable>enable</Nullable>
    <ImplicitUsings>enable</ImplicitUsings>
  </PropertyGroup>

  <ItemGroup>
    <!-- Client Kafka officiel pour .NET -->
    <PackageReference Include="Confluent.Kafka" Version="2.3.0" />
  </ItemGroup>

</Project>
```

### 2.2 Confluent.Kafka expliquÃ©

| Classe | RÃ´le |
|--------|------|
| `ConsumerConfig` | Configuration du consumer |
| `ConsumerBuilder<K,V>` | CrÃ©ateur de consumer avec handlers |
| `IConsumer<K,V>` | Interface du consumer |
| `ConsumeResult<K,V>` | RÃ©sultat d'un poll |

---

## ğŸ’» Ã‰tape 3 : Programme principal (Program.cs)

### 3.1 CrÃ©er `Program.cs` complet

```csharp
using Confluent.Kafka;
using System.Text.Json;

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CONFIGURATION ASP.NET
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
var builder = WebApplication.CreateBuilder(args);

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// VARIABLES D'ENVIRONNEMENT
// Peuvent Ãªtre surchargÃ©es via Docker ou appsettings.json
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
var bootstrapServers = Environment.GetEnvironmentVariable("KAFKA_BOOTSTRAP_SERVERS") 
    ?? "localhost:9092";
var topic = Environment.GetEnvironmentVariable("KAFKA_TOPIC") 
    ?? "orders";
var groupId = Environment.GetEnvironmentVariable("KAFKA_GROUP_ID") 
    ?? "orders-consumer-group";
var autoOffsetReset = Environment.GetEnvironmentVariable("KAFKA_AUTO_OFFSET_RESET") 
    ?? "earliest";

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CONFIGURATION CONSUMER KAFKA
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
var consumerConfig = new ConsumerConfig
{
    // Serveur(s) Kafka
    BootstrapServers = bootstrapServers,
    
    // ID du groupe de consumers
    // Tous les consumers avec le mÃªme GroupId partagent les partitions
    GroupId = groupId,
    
    // OÃ¹ commencer si pas d'offset sauvegardÃ©
    // Earliest = dÃ©but du topic, Latest = fin du topic
    AutoOffsetReset = Enum.Parse<AutoOffsetReset>(autoOffsetReset, true),
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // COMMIT MANUEL
    // Plus de contrÃ´le : on commit aprÃ¨s traitement rÃ©ussi
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    EnableAutoCommit = false,
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // TIMEOUTS DE SESSION
    // SessionTimeoutMs : dÃ©lai avant que Kafka considÃ¨re le consumer mort
    // HeartbeatIntervalMs : frÃ©quence des heartbeats (doit Ãªtre < SessionTimeout/3)
    // MaxPollIntervalMs : dÃ©lai max entre deux poll() avant kick
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    SessionTimeoutMs = 45000,      // 45 secondes
    HeartbeatIntervalMs = 15000,   // 15 secondes
    MaxPollIntervalMs = 300000,    // 5 minutes
    
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // STRATÃ‰GIE D'ASSIGNATION
    // CooperativeSticky : Rebalancing incrÃ©mental, minimise les interruptions
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PartitionAssignmentStrategy = PartitionAssignmentStrategy.CooperativeSticky
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Ã‰TAT DU CONSUMER (pour monitoring)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
var messagesProcessed = 0L;
var partitionsAssigned = new List<string>();
var lastRebalanceTime = DateTime.MinValue;
var rebalanceCount = 0;
var cts = new CancellationTokenSource();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// DÃ‰MARRER LE CONSUMER EN BACKGROUND
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Task.Run(() => ConsumeMessages(cts.Token));

var app = builder.Build();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ENDPOINTS REST API
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

// Health check
app.MapGet("/health", () => Results.Ok(new { status = "UP" }));

// Statistiques du consumer
app.MapGet("/api/v1/stats", () => Results.Ok(new
{
    messagesProcessed,
    partitionsAssigned,
    rebalanceCount,
    lastRebalanceTime = lastRebalanceTime == DateTime.MinValue 
        ? "N/A" 
        : lastRebalanceTime.ToString("O")
}));

// Partitions actuellement assignÃ©es
app.MapGet("/api/v1/partitions", () => Results.Ok(new
{
    partitions = partitionsAssigned,
    count = partitionsAssigned.Count
}));

app.Run();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// FONCTION DE CONSOMMATION
// Boucle infinie qui poll les messages Kafka
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
async Task ConsumeMessages(CancellationToken cancellationToken)
{
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // CRÃ‰ATION DU CONSUMER AVEC HANDLERS DE REBALANCING
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    using var consumer = new ConsumerBuilder<string, string>(consumerConfig)
        
        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        // CALLBACK : PARTITIONS ASSIGNÃ‰ES
        // AppelÃ© quand de nouvelles partitions sont assignÃ©es
        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        .SetPartitionsAssignedHandler((c, partitions) =>
        {
            rebalanceCount++;
            lastRebalanceTime = DateTime.UtcNow;
            partitionsAssigned = partitions
                .Select(p => $"{p.Topic}-{p.Partition}")
                .ToList();
            
            Console.WriteLine($"[REBALANCE] Partitions assigned: " +
                $"{string.Join(", ", partitionsAssigned)}");
        })
        
        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        // CALLBACK : PARTITIONS RÃ‰VOQUÃ‰ES
        // AppelÃ© AVANT que les partitions soient retirÃ©es
        // â†’ Moment idÃ©al pour committer les offsets
        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        .SetPartitionsRevokedHandler((c, partitions) =>
        {
            var revoked = partitions
                .Select(p => $"{p.Topic}-{p.Partition}")
                .ToList();
            
            Console.WriteLine($"[REBALANCE] Partitions revoked: " +
                $"{string.Join(", ", revoked)}");
            
            try
            {
                // Committer avant de perdre les partitions
                c.Commit();
                Console.WriteLine("[REBALANCE] Offsets committed before revocation");
            }
            catch (Exception ex)
            {
                Console.WriteLine($"[REBALANCE] Error committing offsets: {ex.Message}");
            }
        })
        
        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        // CALLBACK : PARTITIONS PERDUES
        // AppelÃ© en cas de perte non gracieuse (timeout, crash)
        // Les offsets ne peuvent pas Ãªtre committÃ©s
        // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        .SetPartitionsLostHandler((c, partitions) =>
        {
            var lost = partitions
                .Select(p => $"{p.Topic}-{p.Partition}")
                .ToList();
            
            Console.WriteLine($"[REBALANCE] Partitions lost: " +
                $"{string.Join(", ", lost)}");
        })
        
        .Build();

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // SOUSCRIPTION AU TOPIC
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    consumer.Subscribe(topic);
    Console.WriteLine($"[CONSUMER] Subscribed to topic: {topic}");
    Console.WriteLine($"[CONSUMER] Group ID: {groupId}");
    Console.WriteLine($"[CONSUMER] Bootstrap servers: {bootstrapServers}");

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // BOUCLE DE CONSOMMATION
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    while (!cancellationToken.IsCancellationRequested)
    {
        try
        {
            // Poll avec timeout de 1 seconde
            var consumeResult = consumer.Consume(TimeSpan.FromMilliseconds(1000));
            
            if (consumeResult == null) continue;

            // Log du message reÃ§u
            Console.WriteLine($"[MESSAGE] Key: {consumeResult.Message.Key}, " +
                            $"Partition: {consumeResult.Partition}, " +
                            $"Offset: {consumeResult.Offset}");

            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // TRAITEMENT DU MESSAGE
            // Simuler un traitement de 100ms
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            await Task.Delay(100, cancellationToken);

            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // COMMIT MANUEL
            // Committer aprÃ¨s traitement rÃ©ussi uniquement
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            consumer.Commit(consumeResult);
            Interlocked.Increment(ref messagesProcessed);
        }
        catch (ConsumeException ex)
        {
            Console.WriteLine($"[ERROR] Consume error: {ex.Error.Reason}");
        }
        catch (OperationCanceledException)
        {
            break;
        }
    }

    // Fermer proprement le consumer
    consumer.Close();
}
```

---

## ğŸ”„ Concepts clÃ©s expliquÃ©s

### StratÃ©gies d'assignation

```mermaid
flowchart TB
    subgraph range["RangeAssignor"]
        R1["C1: P0,P1,P2"]
        R2["C2: P3,P4,P5"]
    end
    
    subgraph sticky["CooperativeSticky âœ…"]
        S1["C1: P0,P1"]
        S2["C2: P2,P3"]
        S3["C3: P4,P5"]
    end
    
    range -->|"+ C3"| sticky
    
    style sticky fill:#e8f5e9
```

| StratÃ©gie | Rebalancing | Interruption |
|-----------|-------------|--------------|
| **Range** | Toutes partitions redistribuÃ©es | âš ï¸ Totale |
| **RoundRobin** | Toutes partitions redistribuÃ©es | âš ï¸ Totale |
| **CooperativeSticky** | IncrÃ©mental, minimise les mouvements | âœ… Minimale |

### Callbacks de Rebalancing

```mermaid
sequenceDiagram
    participant C as Consumer
    participant K as Kafka Coordinator
    
    K->>C: Rebalance triggered
    C->>C: onPartitionsRevoked()
    Note over C: Commit offsets!
    C-->>K: Revoke complete
    K->>K: Reassign partitions
    K->>C: New assignment
    C->>C: onPartitionsAssigned()
    Note over C: Initialize state
```

### Commit manuel vs auto-commit

| Mode | Avantages | InconvÃ©nients |
|------|-----------|---------------|
| **Auto-commit** | Simple, moins de code | Risque de perte ou duplication |
| **Manuel** âœ… | ContrÃ´le total, exactly-once possible | Plus de code, responsabilitÃ© |

---

## ğŸ³ Ã‰tape 4 : Dockerfile

### 4.1 CrÃ©er `Dockerfile`

```dockerfile
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 1 : BUILD
# Compile l'application .NET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build
WORKDIR /src

# Copier le fichier projet et restaurer les dÃ©pendances
COPY *.csproj .
RUN dotnet restore

# Copier le code source et publier
COPY . .
RUN dotnet publish -c Release -o /app/publish

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 2 : RUNTIME
# Image lÃ©gÃ¨re avec uniquement le runtime
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM mcr.microsoft.com/dotnet/aspnet:8.0-alpine
WORKDIR /app

# Copier l'application publiÃ©e
COPY --from=build /app/publish .

# Variables d'environnement par dÃ©faut
ENV KAFKA_BOOTSTRAP_SERVERS=kafka:29092
ENV KAFKA_TOPIC=orders
ENV KAFKA_GROUP_ID=orders-consumer-group
ENV KAFKA_AUTO_OFFSET_RESET=earliest
ENV ASPNETCORE_URLS=http://+:8080

EXPOSE 8080

ENTRYPOINT ["dotnet", "Module04Consumer.dll"]
```

---

## ğŸ§ª Ã‰tape 5 : Tests API

### 5.1 CrÃ©er `requests.http`

```http
### Variables
@baseUrl = http://localhost:8080

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### HEALTH CHECK
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GET {{baseUrl}}/health

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### STATISTIQUES DU CONSUMER
### Affiche : messages traitÃ©s, partitions, rebalances
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GET {{baseUrl}}/api/v1/stats

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### PARTITIONS ASSIGNÃ‰ES
### Liste des partitions actuellement consommÃ©es
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GET {{baseUrl}}/api/v1/partitions
```

---

## ï¿½ Ã‰tape 6 : Docker Compose - Build et DÃ©ploiement

### 6.1 DÃ©marrer l'infrastructure Kafka

```powershell
# Depuis la racine formation-v2/
cd infra

# DÃ©marrer Kafka single-node + Kafka UI
docker-compose -f docker-compose.single-node.yml up -d
```

### 6.2 CrÃ©er le topic

```powershell
docker exec -it kafka kafka-topics.sh --create \
  --topic orders \
  --partitions 6 \
  --bootstrap-server localhost:9092
```

### 6.3 Build et dÃ©marrer les APIs du module

```powershell
# Depuis le rÃ©pertoire du module
cd ../day-02-development/module-04-advanced-patterns

# Build et dÃ©marrer les APIs Java + .NET
docker-compose -f docker-compose.module.yml up -d --build

# VÃ©rifier les containers
docker-compose -f docker-compose.module.yml ps
```

### 6.4 Tester le .NET Consumer (port 18083)

```powershell
# Health check
curl http://localhost:18083/health

# VÃ©rifier les stats
curl http://localhost:18083/api/v1/stats

# VÃ©rifier les partitions assignÃ©es
curl http://localhost:18083/api/v1/partitions
```

### 6.5 Produire des messages de test

```powershell
# Via Java API (port 18082)
curl -X POST http://localhost:18082/api/v1/orders \
  -H "Content-Type: application/json" \
  -d '{"orderId":"ORD-001","amount":99.99,"status":"NEW"}'

# Ou via console producer
docker exec -it kafka kafka-console-producer.sh \
  --topic orders \
  --bootstrap-server localhost:9092 \
  --property "parse.key=true" \
  --property "key.separator=:"

# Taper : ORD-002:{"amount":50.00}
# Ctrl+C pour quitter
```

### 6.6 ArrÃªter les services

```powershell
docker-compose -f docker-compose.module.yml down
```

---

## ğŸ–¥ï¸ Alternative : ExÃ©cution locale (sans Docker)

```powershell
# S'assurer que Kafka tourne sur localhost:9092
dotnet run

# VÃ©rifier les stats
curl http://localhost:8080/api/v1/stats
```

---

## ğŸ”¬ Exercice : Tester le Rebalancing

### DÃ©marrer plusieurs instances

```powershell
# Terminal 1 : Instance 1 (port 8080)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092 dotnet run --urls=http://localhost:8080

# Terminal 2 : Instance 2 (port 8081)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092 dotnet run --urls=http://localhost:8081

# Terminal 3 : Instance 3 (port 8082)
KAFKA_BOOTSTRAP_SERVERS=localhost:9092 dotnet run --urls=http://localhost:8082
```

### Observer le rebalancing

```powershell
# VÃ©rifier les partitions de chaque instance
curl http://localhost:8080/api/v1/partitions
curl http://localhost:8081/api/v1/partitions
curl http://localhost:8082/api/v1/partitions
```

**RÃ©sultat attendu :**
- Avec 6 partitions et 3 consumers â†’ 2 partitions par consumer
- En arrÃªtant un consumer â†’ les 2 autres rÃ©cupÃ¨rent ses partitions

---

## ğŸ“š Ressources

| Sujet | Lien |
|-------|------|
| **Confluent.Kafka .NET** | [GitHub](https://github.com/confluentinc/confluent-kafka-dotnet) |
| **Documentation** | [docs.confluent.io](https://docs.confluent.io/kafka-clients/dotnet/current/overview.html) |
| **ASP.NET Minimal API** | [Microsoft Docs](https://learn.microsoft.com/en-us/aspnet/core/fundamentals/minimal-apis) |

---

## âœ… Checklist de validation

- [ ] Projet .NET crÃ©Ã© avec `dotnet new web`
- [ ] Package `Confluent.Kafka` installÃ©
- [ ] `Program.cs` avec consumer et handlers
- [ ] Dockerfile multi-stage crÃ©Ã©
- [ ] Consumer souscrit au topic
- [ ] Messages consommÃ©s et affichÃ©s dans les logs
- [ ] Commit manuel aprÃ¨s chaque message
- [ ] Endpoints REST fonctionnels (/health, /stats, /partitions)
- [ ] Rebalancing testÃ© avec plusieurs instances

---

**ğŸ‰ FÃ©licitations !** Vous avez implÃ©mentÃ© un Consumer Kafka .NET robuste avec gestion du rebalancing !
