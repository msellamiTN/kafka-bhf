# ğŸ“… Day 03 - IntÃ©gration, Tests & ObservabilitÃ©

> **DurÃ©e estimÃ©e** : 5-6 heures | **Niveau** : AvancÃ© â†’ Production

---

## ğŸ¯ Objectifs pÃ©dagogiques

Ã€ la fin de cette journÃ©e, vous serez capable de :

| # | Objectif | Module |
|---|----------|--------|
| 1 | DÃ©ployer un **connecteur Source** (fichier â†’ Kafka) | M06 |
| 2 | DÃ©ployer un **connecteur Sink** (Kafka â†’ fichier) | M06 |
| 3 | Configurer et gÃ©rer les connecteurs via **REST API** | M06 |
| 4 | Ã‰crire des **tests unitaires** avec MockProducer/MockConsumer | M07 |
| 5 | ImplÃ©menter des **tests d'intÃ©gration** avec Testcontainers | M07 |
| 6 | Collecter les **mÃ©triques JMX** de Kafka | M08 |
| 7 | Visualiser le **consumer lag** et les performances | M08 |
| 8 | Mettre en place le **traÃ§age distribuÃ©** des Ã©vÃ©nements | M08 |

---

## ğŸ“š Concepts fondamentaux

### Kafka Connect - Architecture

```mermaid
flowchart LR
    subgraph Sources["ğŸ“¥ Sources"]
        DB[("ğŸ—„ï¸ Database")]
        FILE["ğŸ“„ Files"]
        API["ğŸŒ REST API"]
    end
    
    subgraph Connect["ğŸ”Œ Kafka Connect"]
        SC["Source<br/>Connector"]
        SK["Sink<br/>Connector"]
        W1["Worker 1"]
        W2["Worker 2"]
    end
    
    subgraph Kafka["ğŸ“¦ Kafka"]
        T["Topics"]
    end
    
    subgraph Sinks["ğŸ“¤ Destinations"]
        ES[("ğŸ” Elasticsearch")]
        S3["â˜ï¸ S3"]
        DW[("ğŸ“Š Data Warehouse")]
    end
    
    DB --> SC --> T
    FILE --> SC
    T --> SK --> ES
    T --> SK --> S3
    
    W1 --- SC
    W2 --- SK
```

### Types de connecteurs

| Type | Direction | Exemples | Cas d'usage |
|------|-----------|----------|-------------|
| **Source** | Externe â†’ Kafka | JDBC, Debezium, FileStream | CDC, ingestion |
| **Sink** | Kafka â†’ Externe | Elasticsearch, S3, JDBC | Indexation, archivage |

### Testing Pyramid

```mermaid
flowchart TB
    subgraph Pyramid["ğŸ”º Pyramide de Tests Kafka"]
        E2E["ğŸ” E2E Tests<br/>(Testcontainers + Real Kafka)<br/>10%"]
        INT["ğŸ“¦ Integration Tests<br/>(EmbeddedKafka)<br/>30%"]
        UNIT["âš¡ Unit Tests<br/>(MockProducer/Consumer)<br/>60%"]
    end
    
    UNIT --> INT --> E2E
    
    style E2E fill:#ffcccc
    style INT fill:#ffffcc
    style UNIT fill:#ccffcc
```

### StratÃ©gies de test

| Niveau | Outil | Vitesse | FidÃ©litÃ© | Isolation |
|--------|-------|---------|----------|-----------|
| **Unit** | MockProducer | âš¡âš¡âš¡ | â­ | âœ… Total |
| **Integration** | EmbeddedKafka | âš¡âš¡ | â­â­ | âœ… Process |
| **E2E** | Testcontainers | âš¡ | â­â­â­ | âœ… Container |

### ObservabilitÃ© - Les 3 piliers

```mermaid
flowchart TB
    subgraph Observability["ğŸ“Š ObservabilitÃ© Kafka"]
        subgraph Metrics["ğŸ“ˆ MÃ©triques"]
            JMX["JMX Exporter"]
            PROM["Prometheus"]
            GRAF["Grafana"]
        end
        
        subgraph Logs["ğŸ“ Logs"]
            KL["Kafka Logs"]
            AL["App Logs"]
            ELK["ELK Stack"]
        end
        
        subgraph Traces["ğŸ”— Traces"]
            OT["OpenTelemetry"]
            JAEG["Jaeger"]
            CORR["Correlation IDs"]
        end
    end
    
    JMX --> PROM --> GRAF
    KL --> ELK
    AL --> ELK
    OT --> JAEG
```

### MÃ©triques clÃ©s Ã  surveiller

| MÃ©trique | Description | Seuil d'alerte |
|----------|-------------|----------------|
| **consumer_lag** | Messages non consommÃ©s | > 1000 |
| **request_latency_avg** | Latence moyenne | > 100ms |
| **bytes_in_per_sec** | DÃ©bit entrant | Selon capacitÃ© |
| **under_replicated_partitions** | Partitions sous-rÃ©pliquÃ©es | > 0 |
| **active_controller_count** | ContrÃ´leurs actifs | â‰  1 |

---

## ğŸ’¡ Tips & Best Practices

### Kafka Connect

> **ğŸ”Œ Toujours valider la configuration avant dÃ©ploiement**
> ```bash
> curl -X PUT http://localhost:8083/connector-plugins/FileStreamSource/config/validate \
>   -H "Content-Type: application/json" \
>   -d '{"connector.class": "FileStreamSource", "topic": "test"}'
> ```

> **ğŸ“Š Monitorer les connecteurs en production**
> ```bash
> # Status du connecteur
> curl http://localhost:8083/connectors/my-connector/status
> 
> # RedÃ©marrer une tÃ¢che en erreur
> curl -X POST http://localhost:8083/connectors/my-connector/tasks/0/restart
> ```

### Testing

> **âš¡ PrÃ©fÃ©rer MockProducer pour les tests unitaires**
> ```java
> MockProducer<String, String> producer = new MockProducer<>(
>     true, new StringSerializer(), new StringSerializer());
> 
> // VÃ©rifier les messages envoyÃ©s
> assertEquals(1, producer.history().size());
> ```

> **ğŸ³ Utiliser Testcontainers pour l'intÃ©gration**
> ```java
> @Container
> static KafkaContainer kafka = new KafkaContainer(
>     DockerImageName.parse("confluentinc/cp-kafka:7.5.0"));
> ```

### ObservabilitÃ©

> **ğŸ“ˆ Configurer des alertes sur le consumer lag**
> ```yaml
> # prometheus/alerts.yml
> - alert: HighConsumerLag
>   expr: kafka_consumer_group_lag > 1000
>   for: 5m
>   labels:
>     severity: warning
> ```

> **ğŸ”— Propager les correlation IDs dans les headers**
> ```java
> record.headers().add("correlation-id", 
>     UUID.randomUUID().toString().getBytes());
> ```

---

## ğŸ—ï¸ Architecture du Lab

```mermaid
flowchart TB
    subgraph Docker["ğŸ³ Docker Network: bhf-kafka-network"]
        subgraph Infra["Infrastructure"]
            K["ğŸ“¦ Kafka<br/>:29092"]
            UI["ğŸ–¥ï¸ Kafka UI<br/>:8080"]
        end
        
        subgraph M06["Module 06 - Connect"]
            KC["ğŸ”Œ Kafka Connect<br/>:8083"]
            SRC["ğŸ“„ Source Files"]
            SNK["ğŸ“„ Sink Files"]
        end
        
        subgraph M08["Module 08 - Observability"]
            JMX["ğŸ“Š JMX Exporter<br/>:9404"]
            PROM["ğŸ“ˆ Prometheus<br/>:9090"]
            GRAF["ğŸ“‰ Grafana<br/>:3000"]
        end
    end
    
    KC -->|"source"| K
    K -->|"sink"| KC
    SRC --> KC
    KC --> SNK
    
    JMX --> K
    PROM --> JMX
    GRAF --> PROM
    UI --> K
```

---

## ğŸ“¦ Modules

| Module | Titre | DurÃ©e | Description |
|--------|-------|-------|-------------|
| [**M06**](./module-06-kafka-connect/README.md) | Kafka Connect | 60-90 min | Source/Sink, REST API |
| [**M07**](./module-07-testing/README.md) | Testing | 60 min | Mock, Testcontainers |
| [**M08**](./module-08-observability/README.md) | ObservabilitÃ© | 60-90 min | JMX, Prometheus, Grafana |

---

## ğŸš€ Quick Start

### PrÃ©requis

- âœ… Day 01 & Day 02 complÃ©tÃ©s
- âœ… Kafka infrastructure running

### DÃ©marrer les modules

```powershell
# Depuis formation-v2/
cd infra
docker-compose -f docker-compose.single-node.yml up -d

# Module 06 - Kafka Connect
cd ../day-03-integration/module-06-kafka-connect
docker-compose -f docker-compose.module.yml up -d

# Module 07 - Tests (exÃ©cution locale)
cd ../module-07-testing/java
mvn test

# Module 08 - ObservabilitÃ©
cd ../module-08-observability
docker-compose -f docker-compose.module.yml up -d
```

### Ports

| Service | Port | Description |
|---------|------|-------------|
| Kafka Connect | 8083 | REST API |
| Prometheus | 9090 | Metrics store |
| Grafana | 3000 | Dashboards (admin/admin) |
| JMX Exporter | 9404 | Kafka metrics |

---

## âš ï¸ Erreurs courantes

| Erreur | Cause | Solution |
|--------|-------|----------|
| `Connector not found` | Plugin non installÃ© | VÃ©rifier `/usr/share/java/` |
| `No tasks assigned` | Configuration invalide | Valider avec PUT validate |
| `Testcontainers timeout` | Docker lent | Augmenter timeout startup |
| `Prometheus scrape failed` | JMX non exposÃ© | VÃ©rifier KAFKA_JMX_OPTS |

---

## â¡ï¸ Navigation

â¬…ï¸ **[Day 02 - DÃ©veloppement](../day-02-development/README.md)**

ğŸ  **[Overview](../00-overview/README.md)**
