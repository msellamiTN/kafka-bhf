# Module 02 - Fiabilit√© du Producteur Kafka (Idempotence) - Formation Auto-rythm√©e

## Dur√©e estim√©e

‚è±Ô∏è **60-90 minutes**

## Objectifs p√©dagogiques

√Ä la fin de ce module, vous serez capable de :

1. ‚úÖ Comprendre la diff√©rence entre un producer **idempotent** et **non-idempotent**
2. ‚úÖ Ma√Ætriser l'envoi **synchrone** vs **asynchrone** et les callbacks
3. ‚úÖ Configurer les **retries** et **timeouts** pour la fiabilit√©
4. ‚úÖ Comprendre l'impact des **cl√©s** sur le partitionnement
5. ‚úÖ Utiliser **Toxiproxy** pour simuler des pannes r√©seau
6. ‚úÖ Observer et d√©boguer les messages via **Kafka UI**
7. ‚úÖ Comprendre la **log compaction** et son utilit√©

---

## üìñ Concepts th√©oriques

### Qu'est-ce que l'idempotence ?

L'**idempotence** garantit qu'un message envoy√© plusieurs fois (√† cause de retries) n'est √©crit qu'**une seule fois** dans Kafka.

```
Sans idempotence (plain):
  Producer ‚Üí [retry] ‚Üí [retry] ‚Üí Kafka = 3 messages identiques ‚ùå

Avec idempotence:
  Producer ‚Üí [retry] ‚Üí [retry] ‚Üí Kafka = 1 message unique ‚úÖ
```

### Configuration de l'idempotence

```properties
enable.idempotence=true
acks=all
max.in.flight.requests.per.connection=5
```

### Envoi synchrone vs asynchrone

| Mode | Comportement | R√©ponse HTTP | Cas d'usage |
|------|--------------|--------------|-------------|
| **Synchrone** | Attend l'ACK Kafka | 200 + offset | Simple, fiable |
| **Asynchrone** | Retourne imm√©diatement | 202 + requestId | Haute performance |

### Retries et timeouts

| Param√®tre | Description | Valeur par d√©faut |
|-----------|-------------|-------------------|
| `retries` | Nombre max de tentatives | 2147483647 |
| `request.timeout.ms` | Timeout par requ√™te | 30000 |
| `delivery.timeout.ms` | Timeout total de livraison | 120000 |
| `retry.backoff.ms` | D√©lai entre retries | 100 |

### Partitionnement et cl√©s

- **Sans cl√©** : Round-robin sur les partitions
- **Avec cl√©** : Hash de la cl√© ‚Üí partition d√©terministe
- **Ordre garanti** : Uniquement au sein d'une m√™me partition

### Log compaction

La **compaction** conserve uniquement la derni√®re valeur pour chaque cl√© :

```
Avant compaction:
  key1 ‚Üí value1, key1 ‚Üí value2, key2 ‚Üí value3, key1 ‚Üí value4

Apr√®s compaction:
  key1 ‚Üí value4, key2 ‚Üí value3
```

---

## üèóÔ∏è Architecture du module

```mermaid
flowchart TB
    subgraph Client["Votre Machine"]
        curl["üñ•Ô∏è curl / Postman"]
    end
    
    subgraph Docker["Docker Environment"]
        Java["‚òï Java API<br/>Port: 18080"]
        DotNet["üî∑ .NET API<br/>Port: 18081"]
        Toxi["üíÄ Toxiproxy<br/>Port: 8474"]
        K["üì¶ Kafka Broker<br/>Port: 9092"]
        UI["üìä Kafka UI<br/>Port: 8080"]
    end
    
    curl --> Java
    curl --> DotNet
    Java -->|"via proxy"| Toxi
    DotNet -->|"via proxy"| Toxi
    Toxi -->|"injecte latence/erreurs"| K
    K --> UI
    
    style Toxi fill:#fff3e0
    style K fill:#e8f5e8
```

---

## üîå Ports et endpoints

### Services

| Service | Port | URL |
|---------|------|-----|
| Java API | 18080 | http://localhost:18080 |
| .NET API | 18081 | http://localhost:18081 |
| Toxiproxy | 8474 | http://localhost:8474 |
| Kafka UI | 8080 | http://localhost:8080 |

### Endpoints des APIs

| M√©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/health` | Health check |
| POST | `/api/v1/send` | Envoyer un message |
| GET | `/api/v1/status` | Statut d'un envoi async |

### Param√®tres de `/api/v1/send`

| Param√®tre | Valeurs | Description |
|-----------|---------|-------------|
| `mode` | `plain`, `idempotent` | Mode du producer |
| `sendMode` | `sync`, `async` | Synchrone ou asynchrone |
| `eventId` | string | Identifiant unique du message |
| `key` | string (optionnel) | Cl√© de partitionnement |
| `partition` | int (optionnel) | Partition cible |

---

## üìã Pr√©-requis

### Logiciels

- ‚úÖ Docker + Docker Compose
- ‚úÖ curl (ligne de commande)
- ‚úÖ Navigateur web

### Cluster Kafka d√©marr√©

```bash
cd formation-v2/
./scripts/up.sh
```

**V√©rification** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}' | grep kafka
```

**R√©sultat attendu** : `kafka` et `kafka-ui` sont `Up (healthy)`.

---

## üìö Lab 02.0 - D√©marrage du module

### Objectif

D√©marrer les services du module (APIs Java/.NET + Toxiproxy) et v√©rifier leur bon fonctionnement.

---

### √âtape 1 - Positionnement

**Objectif** : Se placer dans le bon r√©pertoire.

```bash
cd formation-v2/
```

---

### √âtape 2 - D√©marrage des services

**Objectif** : Lancer les conteneurs du module.

**Explication** : Cette commande lance :
- **Toxiproxy** : Proxy r√©seau pour injecter des pannes
- **toxiproxy-init** : Configuration initiale du proxy (one-shot)
- **m02-java-api** : API Spring Boot (Java)
- **m02-dotnet-api** : API ASP.NET (.NET)

**Commande** :

```bash
docker compose -f infra/docker-compose.single-node.yml \
  -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml \
  up -d --build
```

**‚è±Ô∏è Temps d'attente** : 2-3 minutes (build des images Java/.NET).

**R√©sultat attendu** :

```
[+] Running 5/5
 ‚úî Container toxiproxy        Started
 ‚úî Container toxiproxy-init   Started
 ‚úî Container m02-java-api     Started
 ‚úî Container m02-dotnet-api   Started
```

---

### √âtape 3 - V√©rification des conteneurs

**Objectif** : S'assurer que tous les services sont op√©rationnels.

**Commande** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'
```

**R√©sultat attendu** :

| Conteneur | Statut attendu |
|-----------|----------------|
| kafka | Up (healthy) |
| kafka-ui | Up (healthy) |
| toxiproxy | Up |
| toxiproxy-init | Exited (0) ‚úÖ normal |
| m02-java-api | Up |
| m02-dotnet-api | Up |

---

### √âtape 4 - Test de sant√© des APIs

**Objectif** : V√©rifier que les APIs r√©pondent.

**Commandes** :

```bash
# Test Java API
curl -fsS http://localhost:18080/health
# R√©sultat attendu: OK

# Test .NET API
curl -fsS http://localhost:18081/health
# R√©sultat attendu: OK
```

**‚úÖ Checkpoint 02.0** : Les deux APIs r√©pondent `OK`.

---

## üìö Lab 02.1 - Envoi synchrone (baseline)

### Objectif

Envoyer un message en mode **synchrone** et comprendre la r√©ponse avec l'offset.

---

### √âtape 5 - Envoi d'un message synchrone (Java API)

**Objectif** : Envoyer un message et recevoir l'ACK Kafka.

**Th√©orie** : En mode **synchrone**, l'API attend la confirmation de Kafka avant de r√©pondre. La r√©ponse contient :
- Le **topic** de destination
- La **partition** utilis√©e
- L'**offset** du message

**Commande** :

```bash
# G√©n√©rer un ID unique
EVENT_ID="JAVA-SYNC-$(date +%s)"
echo "EventId: $EVENT_ID"

# Envoyer le message
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**R√©sultat attendu** :

```json
{
  "status": "OK",
  "topic": "bhf-transactions",
  "partition": 0,
  "offset": 5,
  "eventId": "JAVA-SYNC-1706400000"
}
```

**Explication de la r√©ponse** :

| Champ | Description |
|-------|-------------|
| `status` | OK = message √©crit avec succ√®s |
| `topic` | Topic de destination |
| `partition` | Partition o√π le message est stock√© |
| `offset` | Position du message dans la partition |
| `eventId` | Identifiant unique envoy√© |

---

### √âtape 6 - Envoi avec l'API .NET

**Objectif** : V√©rifier que l'API .NET fonctionne de la m√™me mani√®re.

**Commande** :

```bash
EVENT_ID="DOTNET-SYNC-$(date +%s)"
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**‚úÖ Checkpoint 02.1** : Les deux APIs retournent un JSON avec `partition` et `offset`.

---

### √âtape 7 - Visualisation dans Kafka UI

**Objectif** : Observer les messages envoy√©s.

**Actions** :

1. Ouvrez **http://localhost:8080**
2. Cliquez sur le cluster **BHF-Training**
3. Menu **Topics** ‚Üí **bhf-transactions**
4. Onglet **Messages** ‚Üí **Fetch Messages**

**Ce que vous devez voir** :
- Vos messages avec les `eventId` envoy√©s
- La partition et l'offset de chaque message
- Le timestamp d'envoi

---

## üìö Lab 02.2 - Envoi asynchrone et callbacks

### Objectif

Comprendre le mode **asynchrone** et comment r√©cup√©rer le statut via polling.

---

### √âtape 8 - Envoi asynchrone (Java)

**Objectif** : Envoyer un message sans attendre l'ACK.

**Th√©orie** : En mode **asynchrone** :
1. L'API retourne imm√©diatement un `requestId`
2. Le message est envoy√© en arri√®re-plan
3. Vous consultez le statut via `/api/v1/status`

**Commande** :

```bash
EVENT_ID="JAVA-ASYNC-$(date +%s)"

# Envoyer en asynchrone
RESPONSE=$(curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=idempotent&sendMode=async&eventId=$EVENT_ID")
echo "R√©ponse: $RESPONSE"

# Extraire le requestId
REQ_ID=$(echo "$RESPONSE" | sed -n 's/.*"requestId":"\([^"]*\)".*/\1/p')
echo "RequestId: $REQ_ID"
```

**R√©sultat attendu** :

```json
{
  "status": "ACCEPTED",
  "requestId": "abc123-def456",
  "eventId": "JAVA-ASYNC-1706400000"
}
```

---

### √âtape 9 - Consultation du statut

**Objectif** : R√©cup√©rer le r√©sultat de l'envoi asynchrone.

**Commande** :

```bash
# Attendre 2 secondes pour que l'envoi se termine
sleep 2

# Consulter le statut
curl -fsS "http://localhost:18080/api/v1/status?requestId=$REQ_ID"
```

**R√©sultat attendu (succ√®s)** :

```json
{
  "state": "OK",
  "topic": "bhf-transactions",
  "partition": 1,
  "offset": 10
}
```

**R√©sultat possible (en cours)** :

```json
{
  "state": "PENDING"
}
```

**‚úÖ Checkpoint 02.2** : Vous savez envoyer en asynchrone et r√©cup√©rer le statut.

---

## üìö Lab 02.3 - Injection de pannes avec Toxiproxy

### Objectif

Simuler des probl√®mes r√©seau pour observer le comportement des retries.

---

### √âtape 10 - V√©rification du proxy Toxiproxy

**Objectif** : Confirmer que le proxy Kafka est configur√©.

**Commande** :

```bash
curl -fsS http://localhost:8474/proxies | python3 -m json.tool
```

**R√©sultat attendu** : Un proxy nomm√© `kafka` avec :
- `listen`: `0.0.0.0:29093`
- `upstream`: `kafka:29092`

---

### √âtape 11 - Injection de latence

**Objectif** : Ajouter 5 secondes de latence sur les r√©ponses Kafka.

**Th√©orie** : La latence peut provoquer des **timeouts** c√¥t√© producer, ce qui d√©clenche des **retries**.

**Commande pour ajouter la latence** :

```bash
curl -fsS -H 'Content-Type: application/json' \
  -X POST http://localhost:8474/proxies/kafka/toxics \
  -d '{
    "name": "latency",
    "type": "latency",
    "stream": "downstream",
    "attributes": {
      "latency": 5000,
      "jitter": 0
    }
  }'
```

**V√©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
```

---

### √âtape 12 - Test avec latence

**Objectif** : Observer le comportement avec la latence.

**Commande** :

```bash
EVENT_ID="LATENCY-TEST-$(date +%s)"
time curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**Observation** : La requ√™te prend ~5 secondes de plus que d'habitude.

---

### √âtape 13 - Suppression de la latence

**Objectif** : Retirer la latence pour continuer les tests.

**Commande** :

```bash
curl -fsS -X DELETE http://localhost:8474/proxies/kafka/toxics/latency
```

**V√©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
# R√©sultat: [] (liste vide)
```

---

## üìö Lab 02.4 - Idempotence vs Plain (test cl√©)

### Objectif

Prouver que l'idempotence √©vite les doublons lors des retries.

---

### √âtape 14 - Ex√©cution du test automatis√©

**Objectif** : Valider le comportement idempotent vs non-idempotent.

**Explication** : Le script `validate.sh` :
1. Injecte de la latence via Toxiproxy
2. Envoie des messages en mode `plain` et `idempotent`
3. Compte les messages dans Kafka
4. V√©rifie que `idempotent` = 1 message exactement

**Commande** :

```bash
./day-01-foundations/module-02-producer-reliability/scripts/validate.sh
```

**R√©sultat attendu** :

```
OK: java_idempotent=1 java_plain=1 dotnet_idempotent=1 dotnet_plain=1
```

**Note** : Si `java_plain` ou `dotnet_plain` > 1, c'est normal ! Cela prouve que les retries peuvent cr√©er des doublons sans idempotence.

**‚úÖ Checkpoint 02.4** : L'idempotence produit exactement 1 message.

---

## üìö Lab 02.5 - Partitionnement

### Objectif

Comprendre comment les cl√©s influencent le partitionnement.

---

### √âtape 15 - Envoi sur des partitions diff√©rentes

**Objectif** : Envoyer des messages sur des partitions sp√©cifiques.

**Commandes** :

```bash
# Message sur partition 0
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P0-$(date +%s)&partition=0"

# Message sur partition 1
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P1-$(date +%s)&partition=1"

# Message sur partition 2
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P2-$(date +%s)&partition=2"
```

---

### √âtape 16 - V√©rification des partitions

**Objectif** : Confirmer la distribution des messages.

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic bhf-transactions \
  --from-beginning \
  --timeout-ms 5000 \
  --property print.partition=true \
  --property print.offset=true
```

**R√©sultat attendu** : Messages sur diff√©rentes partitions (0, 1, 2).

---

## üìö Lab 02.6 - Log compaction

### Objectif

Comprendre la compaction et son utilit√© pour les √©tats.

---

### √âtape 17 - Cr√©ation d'un topic compact√©

**Objectif** : Cr√©er un topic avec la politique de compaction.

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic bhf-compact-demo \
  --partitions 1 \
  --replication-factor 1 \
  --config cleanup.policy=compact \
  --config segment.ms=1000 \
  --config min.cleanable.dirty.ratio=0.01
```

---

### √âtape 18 - Envoi de plusieurs versions

**Objectif** : Envoyer plusieurs valeurs pour la m√™me cl√©.

**Commande** :

```bash
KEY="customer-42"

# Version 1
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V1&key=$KEY"

# Version 2
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V2&key=$KEY"

# Version 3 (finale)
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V3&key=$KEY"
```

**Note** : Apr√®s compaction (asynchrone), seul `V3` sera conserv√© pour `customer-42`.

**‚úÖ Checkpoint 02.6** : Vous comprenez la log compaction.

---

## ‚úÖ R√©capitulatif des checkpoints

| # | Checkpoint | Statut |
|---|------------|--------|
| 02.0 | APIs Java et .NET r√©pondent OK | ‚òê |
| 02.1 | Envoi synchrone retourne partition/offset | ‚òê |
| 02.2 | Envoi asynchrone + r√©cup√©ration du statut | ‚òê |
| 02.3 | Injection de latence via Toxiproxy | ‚òê |
| 02.4 | Script validate.sh retourne OK | ‚òê |
| 02.5 | Messages sur diff√©rentes partitions | ‚òê |
| 02.6 | Compr√©hension de la log compaction | ‚òê |

---

## üîß Troubleshooting

### APIs ne d√©marrent pas

**Sympt√¥me** : `m02-java-api` ou `m02-dotnet-api` en erreur.

**Solution** :

```bash
# V√©rifier les logs
docker logs m02-java-api --tail 100
docker logs m02-dotnet-api --tail 100

# Reconstruire les images
docker compose -f infra/docker-compose.single-node.yml \
  -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml \
  up -d --build --force-recreate
```

### Toxiproxy ne r√©pond pas

**Sympt√¥me** : `curl: (7) Failed to connect to localhost port 8474`.

**Solution** :

```bash
docker logs toxiproxy
docker restart toxiproxy
```

### Messages non visibles dans Kafka UI

**Sympt√¥me** : Le topic existe mais pas de messages.

**Solution** :

1. Cliquez sur **Fetch Messages**
2. R√©glez le filtre sur **Earliest** (depuis le d√©but)
3. V√©rifiez le bon topic (`bhf-transactions`)

---

## üßπ Nettoyage

**Objectif** : Arr√™ter les services du module.

**Commande** :

```bash
docker compose -f infra/docker-compose.single-node.yml \
  -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml \
  down
```

---

## üìñ Pour aller plus loin

### Exercices suppl√©mentaires

1. **Modifiez les timeouts** dans `docker-compose.module.yml` et observez l'impact
2. **Injectez un timeout complet** avec Toxiproxy et observez les erreurs
3. **Testez avec diff√©rentes cl√©s** et observez la distribution sur les partitions

### Ressources

- [Kafka Producer Configuration](https://kafka.apache.org/documentation/#producerconfigs)
- [Idempotent Producer](https://kafka.apache.org/documentation/#semantics)
- [Toxiproxy Documentation](https://github.com/Shopify/toxiproxy)

---

## ‚û°Ô∏è Module suivant

Une fois ce module termin√©, passez au :

üëâ **[Module 03 - Consumer Read-Committed](../module-03-consumer-read-committed/README.md)**
