# ğŸ› ï¸ Tutorial VS Code : API Java - Patterns AvancÃ©s Kafka

## ğŸ“‹ Vue d'ensemble

Ce tutorial vous guide pas Ã  pas pour implÃ©menter une API REST Spring Boot avec :
- **Dead Letter Topic (DLT)** pour gÃ©rer les messages en erreur
- **Retry strategies** avec backoff exponentiel
- **Gestion d'erreurs** professionnelle (Transient vs Permanent)

```mermaid
flowchart LR
    API["ğŸŒ REST API"] --> SVC["âš™ï¸ OrderService"] --> K["ğŸ“¦ Kafka"]
    SVC -->|erreur| DLT["ğŸ’€ DLT Service"]
    DLT --> KDLT["ğŸ“¦ DLT Topic"]
```

---

## ğŸ¯ PrÃ©requis

### Outils requis

| Outil | Version | Installation |
|-------|---------|--------------|
| **VS Code** | Latest | [code.visualstudio.com](https://code.visualstudio.com) |
| **Java JDK** | 17+ | `winget install Microsoft.OpenJDK.17` |
| **Maven** | 3.8+ | `winget install Apache.Maven` |
| **Docker Desktop** | Latest | [docker.com](https://docker.com) |

### Extensions VS Code recommandÃ©es

Ouvrez VS Code et installez ces extensions (Ctrl+Shift+X) :

1. **Extension Pack for Java** (vscjava.vscode-java-pack)
2. **Spring Boot Extension Pack** (vmware.vscode-boot-dev-pack)
3. **Docker** (ms-azuretools.vscode-docker)
4. **REST Client** (humao.rest-client)

```bash
# Installation via CLI
code --install-extension vscjava.vscode-java-pack
code --install-extension vmware.vscode-boot-dev-pack
code --install-extension ms-azuretools.vscode-docker
code --install-extension humao.rest-client
```

---

## ğŸ“ Ã‰tape 1 : Structure du projet

### 1.1 CrÃ©er le dossier du projet

```powershell
# Ouvrir un terminal PowerShell
mkdir -p module04-java-api
cd module04-java-api
code .
```

### 1.2 Structure finale attendue

```
module04-java-api/
â”œâ”€â”€ pom.xml                          # Configuration Maven
â”œâ”€â”€ Dockerfile                       # Image Docker
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â”œâ”€â”€ java/
â”‚       â”‚   â””â”€â”€ com/data2ai/kafka/
â”‚       â”‚       â”œâ”€â”€ Application.java         # Point d'entrÃ©e
â”‚       â”‚       â”œâ”€â”€ config/
â”‚       â”‚       â”‚   â””â”€â”€ KafkaConfig.java     # Configuration Kafka
â”‚       â”‚       â”œâ”€â”€ controller/
â”‚       â”‚       â”‚   â””â”€â”€ OrderController.java # Endpoints REST
â”‚       â”‚       â”œâ”€â”€ model/
â”‚       â”‚       â”‚   â””â”€â”€ Order.java           # ModÃ¨le de donnÃ©es
â”‚       â”‚       â””â”€â”€ service/
â”‚       â”‚           â”œâ”€â”€ OrderService.java    # Logique mÃ©tier
â”‚       â”‚           â””â”€â”€ DltService.java      # Service DLT
â”‚       â””â”€â”€ resources/
â”‚           â””â”€â”€ application.properties       # Configuration
â””â”€â”€ requests.http                    # Tests API
```

---

## ğŸ“ Ã‰tape 2 : Configuration Maven (pom.xml)

### 2.1 CrÃ©er le fichier `pom.xml`

Dans VS Code, crÃ©ez un nouveau fichier `pom.xml` Ã  la racine :

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 
         https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    
    <!-- 
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ PARENT: Spring Boot Starter                               â•‘
    â•‘ Fournit les dÃ©pendances et plugins par dÃ©faut             â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    -->
    <parent>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-parent</artifactId>
        <version>3.2.0</version>
        <relativePath/>
    </parent>
    
    <!-- Identifiants du projet -->
    <groupId>com.data2ai.kafka</groupId>
    <artifactId>module04-advanced-patterns</artifactId>
    <version>1.0.0</version>
    <name>Module 04 - Advanced Patterns</name>
    <description>DLT, Retries, and Rebalancing patterns</description>
    
    <properties>
        <java.version>17</java.version>
    </properties>
    
    <!-- 
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘ DÃ‰PENDANCES                                               â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘ spring-boot-starter-web  â†’ API REST                       â•‘
    â•‘ spring-kafka             â†’ Client Kafka                   â•‘
    â•‘ spring-boot-actuator     â†’ Health checks                  â•‘
    â•‘ jackson-databind         â†’ SÃ©rialisation JSON             â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    -->
    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
        </dependency>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>
        <dependency>
            <groupId>com.fasterxml.jackson.core</groupId>
            <artifactId>jackson-databind</artifactId>
        </dependency>
    </dependencies>
    
    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
        </plugins>
    </build>
</project>
```

### 2.2 Concepts expliquÃ©s

| DÃ©pendance | RÃ´le | Documentation |
|------------|------|---------------|
| `spring-boot-starter-web` | Serveur Tomcat embarquÃ© + Spring MVC | [Spring Web](https://spring.io/guides/gs/rest-service/) |
| `spring-kafka` | Client Kafka avec KafkaTemplate | [Spring Kafka](https://spring.io/projects/spring-kafka) |
| `spring-boot-starter-actuator` | Endpoints de monitoring (/health) | [Actuator](https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html) |
| `jackson-databind` | Conversion Java â†” JSON | [Jackson](https://github.com/FasterXML/jackson-databind) |

---

## â˜• Ã‰tape 3 : Point d'entrÃ©e Application

### 3.1 CrÃ©er `src/main/java/com/data2ai/kafka/Application.java`

```java
package com.data2ai.kafka;

import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

/**
 * Point d'entrÃ©e de l'application Spring Boot.
 * 
 * @SpringBootApplication combine 3 annotations :
 * - @Configuration : Classe de configuration Spring
 * - @EnableAutoConfiguration : Configuration automatique basÃ©e sur les dÃ©pendances
 * - @ComponentScan : Scan des composants dans le package et sous-packages
 */
@SpringBootApplication
public class Application {
    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}
```

### 3.2 Concept : @SpringBootApplication

```mermaid
flowchart TD
    SBA["@SpringBootApplication"] --> C["@Configuration"]
    SBA --> EAC["@EnableAutoConfiguration"]
    SBA --> CS["@ComponentScan"]
    
    C --> |"Beans Spring"| BEANS["@Bean definitions"]
    EAC --> |"Auto-config"| AUTO["Kafka, Web, etc."]
    CS --> |"Trouve"| COMP["@Service, @Controller..."]
```

---

## âš™ï¸ Ã‰tape 4 : Configuration Kafka

### 4.1 CrÃ©er `src/main/java/com/data2ai/kafka/config/KafkaConfig.java`

```java
package com.data2ai.kafka.config;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.*;
import org.springframework.kafka.listener.ContainerProperties;
import org.springframework.kafka.listener.DefaultErrorHandler;
import org.springframework.util.backoff.ExponentialBackOff;

import java.util.HashMap;
import java.util.Map;

/**
 * Configuration Kafka pour Producer et Consumer.
 * 
 * Cette classe dÃ©finit :
 * - ProducerFactory : Comment crÃ©er des producteurs Kafka
 * - ConsumerFactory : Comment crÃ©er des consommateurs Kafka
 * - KafkaTemplate : API simplifiÃ©e pour envoyer des messages
 * - ErrorHandler : Gestion des erreurs avec retry exponentiel
 */
@Configuration
public class KafkaConfig {

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // VARIABLES D'ENVIRONNEMENT
    // Peuvent Ãªtre surchargÃ©es via Docker ou application.properties
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @Value("${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}")
    private String bootstrapServers;

    @Value("${MAX_RETRIES:3}")
    private int maxRetries;

    @Value("${RETRY_BACKOFF_MS:1000}")
    private long retryBackoffMs;

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // PRODUCER FACTORY
    // CrÃ©e des producteurs Kafka avec la configuration spÃ©cifiÃ©e
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> config = new HashMap<>();
        
        // Serveur(s) Kafka
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        
        // SÃ©rialiseurs : Comment convertir clÃ©/valeur en bytes
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        // CONFIGURATION FIABILITÃ‰
        // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        // acks=all : Attendre que TOUS les replicas confirment
        // Garantit la durabilitÃ© maximale
        config.put(ProducerConfig.ACKS_CONFIG, "all");
        
        // Idempotence : Ã‰vite les doublons en cas de retry rÃ©seau
        // Kafka attribue un ID sÃ©quentiel Ã  chaque message
        config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
        
        // Nombre de retries automatiques par le producer
        config.put(ProducerConfig.RETRIES_CONFIG, maxRetries);
        
        return new DefaultKafkaProducerFactory<>(config);
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // KAFKA TEMPLATE
    // API haut niveau pour envoyer des messages
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // CONSUMER FACTORY
    // CrÃ©e des consommateurs Kafka
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        
        // OÃ¹ commencer si pas d'offset existant
        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        
        // Commit manuel : Plus de contrÃ´le sur quand committer
        config.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        
        return new DefaultKafkaConsumerFactory<>(config);
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // LISTENER CONTAINER FACTORY
    // Configure comment les @KafkaListener fonctionnent
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory(
            DefaultErrorHandler errorHandler) {
        ConcurrentKafkaListenerContainerFactory<String, String> factory = 
            new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        
        // Commit manuel immÃ©diat aprÃ¨s chaque message traitÃ©
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE);
        
        // Gestionnaire d'erreurs personnalisÃ©
        factory.setCommonErrorHandler(errorHandler);
        
        return factory;
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // ERROR HANDLER avec BACKOFF EXPONENTIEL
    // 
    // Backoff exponentiel : 1s â†’ 2s â†’ 4s â†’ 8s â†’ ...
    // Ã‰vite de surcharger un service temporairement indisponible
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @Bean
    public DefaultErrorHandler errorHandler() {
        // Backoff exponentiel : dÃ©lai initial Ã— multiplier^attempt
        ExponentialBackOff backOff = new ExponentialBackOff(retryBackoffMs, 2.0);
        backOff.setMaxElapsedTime(60000L); // Max 60 secondes au total
        
        return new DefaultErrorHandler((record, exception) -> {
            // Callback quand max retries atteint â†’ Message va au DLT
            System.err.println("Max retries exceeded for record: " + record.key() + 
                ", sending to DLT. Error: " + exception.getMessage());
        }, backOff);
    }
}
```

### 4.2 Concepts clÃ©s expliquÃ©s

#### Idempotence Producer

```mermaid
sequenceDiagram
    participant P as Producer
    participant K as Kafka Broker
    
    P->>K: Send(msg, seq=1)
    K-->>P: ACK lost âŒ
    P->>K: Retry(msg, seq=1)
    K->>K: seq=1 already exists
    K-->>P: ACK (deduplicated)
    
    Note over K: Sans idempotence:<br/>2 messages identiques!
```

#### Backoff Exponentiel

```
Attempt 1: 1000ms  (1s)
Attempt 2: 2000ms  (2s)
Attempt 3: 4000ms  (4s)
Attempt 4: 8000ms  (8s)
... jusqu'Ã  maxElapsedTime (60s)
```

---

## ğŸ“¦ Ã‰tape 5 : ModÃ¨le Order

### 5.1 CrÃ©er `src/main/java/com/data2ai/kafka/model/Order.java`

```java
package com.data2ai.kafka.model;

import com.fasterxml.jackson.annotation.JsonProperty;

/**
 * ModÃ¨le reprÃ©sentant une commande.
 * 
 * @JsonProperty : Mappe les champs Java aux clÃ©s JSON
 * Exemple JSON : {"orderId": "ORD-001", "amount": 99.99, "status": "NEW"}
 */
public class Order {
    
    @JsonProperty("orderId")
    private String orderId;
    
    @JsonProperty("amount")
    private double amount;
    
    @JsonProperty("status")
    private String status;

    // Constructeur par dÃ©faut (requis pour Jackson)
    public Order() {}

    // Constructeur avec paramÃ¨tres
    public Order(String orderId, double amount, String status) {
        this.orderId = orderId;
        this.amount = amount;
        this.status = status;
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // GETTERS & SETTERS
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    public String getOrderId() { return orderId; }
    public void setOrderId(String orderId) { this.orderId = orderId; }

    public double getAmount() { return amount; }
    public void setAmount(double amount) { this.amount = amount; }

    public String getStatus() { return status; }
    public void setStatus(String status) { this.status = status; }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // VALIDATION MÃ‰TIER
    // LÃ¨ve IllegalArgumentException si invalide â†’ Envoi au DLT
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    public void validate() throws IllegalArgumentException {
        if (orderId == null || orderId.isEmpty()) {
            throw new IllegalArgumentException("Order ID is required");
        }
        if (amount < 0) {
            throw new IllegalArgumentException("Amount cannot be negative: " + amount);
        }
    }
}
```

### 5.2 Exemple de sÃ©rialisation

```
Java Object                          JSON String
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Order               â”‚   Jackson    â”‚ {                                â”‚
â”‚   orderId: "ORD-1"  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”‚   "orderId": "ORD-1",            â”‚
â”‚   amount: 99.99     â”‚              â”‚   "amount": 99.99,               â”‚
â”‚   status: "NEW"     â”‚              â”‚   "status": "NEW"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚ }                                â”‚
                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’€ Ã‰tape 6 : Service DLT (Dead Letter Topic)

### 6.1 CrÃ©er `src/main/java/com/data2ai/kafka/service/DltService.java`

```java
package com.data2ai.kafka.service;

import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

import java.time.Instant;
import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.atomic.AtomicLong;

/**
 * Service pour envoyer les messages en erreur au Dead Letter Topic.
 * 
 * DLT = Topic spÃ©cial pour les messages qui n'ont pas pu Ãªtre traitÃ©s
 * aprÃ¨s plusieurs tentatives. Permet :
 * - Analyse post-mortem des erreurs
 * - Replay manuel aprÃ¨s correction
 * - Audit et traÃ§abilitÃ©
 */
@Service
public class DltService {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final ObjectMapper objectMapper;

    // Topic DLT par convention : {topic}.DLT
    @Value("${KAFKA_DLT_TOPIC:orders.DLT}")
    private String dltTopic;

    // Compteur thread-safe pour les statistiques
    private final AtomicLong dltMessageCount = new AtomicLong(0);

    public DltService(KafkaTemplate<String, String> kafkaTemplate, 
                      ObjectMapper objectMapper) {
        this.kafkaTemplate = kafkaTemplate;
        this.objectMapper = objectMapper;
    }

    /**
     * Envoie un message au DLT avec mÃ©tadonnÃ©es enrichies.
     * 
     * @param originalMessage Le message original qui a Ã©chouÃ©
     * @param error L'exception qui a causÃ© l'Ã©chec
     * @param originalTopic Le topic source
     * @param retryCount Nombre de tentatives effectuÃ©es
     */
    public void sendToDlt(Object originalMessage, Throwable error, 
                          String originalTopic, int retryCount) {
        try {
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // STRUCTURE DU MESSAGE DLT
            // Enrichi avec contexte pour debugging
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            
            Map<String, Object> dltMessage = new HashMap<>();
            dltMessage.put("originalTopic", originalTopic);
            dltMessage.put("originalValue", objectMapper.writeValueAsString(originalMessage));
            dltMessage.put("errorMessage", error.getMessage());
            dltMessage.put("errorClass", error.getClass().getName());
            dltMessage.put("errorTimestamp", Instant.now().toString());
            dltMessage.put("retryCount", retryCount);
            
            // Stack trace (limitÃ© Ã  5 lignes pour lisibilitÃ©)
            StackTraceElement[] stackTrace = error.getStackTrace();
            if (stackTrace.length > 0) {
                StringBuilder sb = new StringBuilder();
                for (int i = 0; i < Math.min(5, stackTrace.length); i++) {
                    sb.append(stackTrace[i].toString()).append("\n");
                }
                dltMessage.put("stackTrace", sb.toString());
            }

            String dltValue = objectMapper.writeValueAsString(dltMessage);
            String key = "dlt-" + Instant.now().toEpochMilli();

            // Envoi asynchrone au DLT
            kafkaTemplate.send(dltTopic, key, dltValue)
                .whenComplete((result, ex) -> {
                    if (ex == null) {
                        dltMessageCount.incrementAndGet();
                        System.out.println("Message sent to DLT: " + key + 
                            " partition=" + result.getRecordMetadata().partition() +
                            " offset=" + result.getRecordMetadata().offset());
                    } else {
                        System.err.println("Failed to send to DLT: " + ex.getMessage());
                    }
                });

        } catch (Exception e) {
            System.err.println("Error creating DLT message: " + e.getMessage());
        }
    }

    public long getDltCount() {
        return dltMessageCount.get();
    }
}
```

### 6.2 Structure d'un message DLT

```json
{
  "originalTopic": "orders",
  "originalValue": "{\"orderId\":\"ORD-123\",\"amount\":-50,\"status\":\"NEW\"}",
  "errorMessage": "Amount cannot be negative: -50.0",
  "errorClass": "java.lang.IllegalArgumentException",
  "errorTimestamp": "2024-01-15T10:30:00.123Z",
  "retryCount": 0,
  "stackTrace": "com.data2ai.kafka.model.Order.validate(Order.java:38)\n..."
}
```

---

## ğŸ”„ Ã‰tape 7 : Service Order avec Retry Logic

### 7.1 CrÃ©er `src/main/java/com/data2ai/kafka/service/OrderService.java`

```java
package com.data2ai.kafka.service;

import com.data2ai.kafka.model.Order;
import com.fasterxml.jackson.databind.ObjectMapper;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.SendResult;
import org.springframework.stereotype.Service;

import java.util.concurrent.CompletableFuture;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicLong;

/**
 * Service de traitement des commandes avec gestion d'erreurs.
 * 
 * ImplÃ©mente le pattern :
 * - Erreur Transiente (temporaire) â†’ Retry avec backoff
 * - Erreur Permanente (validation) â†’ Envoi immÃ©diat au DLT
 */
@Service
public class OrderService {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final DltService dltService;
    private final ObjectMapper objectMapper;

    @Value("${KAFKA_TOPIC:orders}")
    private String topic;

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // SIMULATION D'ERREURS (pour les tests)
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    private final AtomicBoolean simulateTransientError = new AtomicBoolean(false);
    
    // Compteurs thread-safe
    private final AtomicLong successCount = new AtomicLong(0);
    private final AtomicLong errorCount = new AtomicLong(0);
    private final AtomicLong dltCount = new AtomicLong(0);

    public OrderService(KafkaTemplate<String, String> kafkaTemplate, 
                       DltService dltService,
                       ObjectMapper objectMapper) {
        this.kafkaTemplate = kafkaTemplate;
        this.dltService = dltService;
        this.objectMapper = objectMapper;
    }

    /**
     * Envoie une commande Ã  Kafka avec gestion d'erreurs.
     * 
     * Flow :
     * 1. Validation â†’ Si Ã©chec â†’ PermanentException â†’ DLT
     * 2. Simulation transient error â†’ TransientException â†’ Retry
     * 3. Envoi Kafka â†’ Async avec callback
     */
    public CompletableFuture<SendResult<String, String>> sendOrder(Order order) {
        try {
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // Ã‰TAPE 1 : VALIDATION
            // Erreur de validation = Permanente â†’ DLT immÃ©diat
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            order.validate();
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // Ã‰TAPE 2 : SIMULATION ERREUR TRANSIENTE
            // Utile pour tester le comportement de retry
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            if (simulateTransientError.get()) {
                throw new TransientException("Simulated transient error");
            }
            
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // Ã‰TAPE 3 : ENVOI Ã€ KAFKA
            // Asynchrone avec CompletableFuture
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            String value = objectMapper.writeValueAsString(order);
            System.out.println("Sending order: " + order.getOrderId());
            
            return kafkaTemplate.send(topic, order.getOrderId(), value)
                .whenComplete((result, ex) -> {
                    if (ex == null) {
                        successCount.incrementAndGet();
                        System.out.println("Order sent successfully: " + order.getOrderId() + 
                            " to partition " + result.getRecordMetadata().partition() + 
                            " offset " + result.getRecordMetadata().offset());
                    } else {
                        errorCount.incrementAndGet();
                        System.err.println("Failed to send order: " + order.getOrderId() + 
                            " - " + ex.getMessage());
                    }
                });
                
        } catch (IllegalArgumentException e) {
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // ERREUR PERMANENTE : Validation Ã©chouÃ©e
            // â†’ Envoi immÃ©diat au DLT, pas de retry
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            errorCount.incrementAndGet();
            dltCount.incrementAndGet();
            dltService.sendToDlt(order, e, topic, 0);
            throw new PermanentException("Validation failed: " + e.getMessage(), e);
            
        } catch (TransientException e) {
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            // ERREUR TRANSIENTE : ProblÃ¨me temporaire
            // â†’ Le caller devrait retry
            // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            errorCount.incrementAndGet();
            throw e;
            
        } catch (Exception e) {
            errorCount.incrementAndGet();
            throw new RuntimeException("Error processing order: " + e.getMessage(), e);
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // CONTRÃ”LE DE LA SIMULATION
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    public void setSimulateTransientError(boolean enabled) {
        simulateTransientError.set(enabled);
        System.out.println("Transient error simulation: " + (enabled ? "ENABLED" : "DISABLED"));
    }

    public boolean isSimulatingTransientError() {
        return simulateTransientError.get();
    }

    public Stats getStats() {
        return new Stats(successCount.get(), errorCount.get(), dltCount.get());
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // CLASSES D'EXCEPTION PERSONNALISÃ‰ES
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    public static class Stats {
        public final long success;
        public final long errors;
        public final long dlt;

        public Stats(long success, long errors, long dlt) {
            this.success = success;
            this.errors = errors;
            this.dlt = dlt;
        }
    }

    /**
     * Exception pour erreurs temporaires (rÃ©seau, timeout, etc.)
     * â†’ Devrait Ãªtre retryÃ©
     */
    public static class TransientException extends RuntimeException {
        public TransientException(String message) {
            super(message);
        }
    }

    /**
     * Exception pour erreurs permanentes (validation, format, etc.)
     * â†’ Ne pas retry, envoyer au DLT
     */
    public static class PermanentException extends RuntimeException {
        public PermanentException(String message, Throwable cause) {
            super(message, cause);
        }
    }
}
```

### 7.2 Diagramme du flow d'erreurs

```mermaid
flowchart TD
    REQ["ğŸ“¥ Order Request"] --> VAL{"Validation OK?"}
    VAL -->|âŒ Non| PERM["PermanentException"]
    PERM --> DLT["ğŸ’€ DLT Topic"]
    
    VAL -->|âœ… Oui| SIM{"Simulating Error?"}
    SIM -->|Oui| TRANS["TransientException"]
    TRANS --> RETRY["ğŸ”„ Retry (503)"]
    
    SIM -->|Non| KAFKA["ğŸ“¦ Kafka Send"]
    KAFKA -->|âœ…| SUCCESS["200 OK"]
    KAFKA -->|âŒ| ERROR["500 Error"]
```

---

## ğŸŒ Ã‰tape 8 : Controller REST

### 8.1 CrÃ©er `src/main/java/com/data2ai/kafka/controller/OrderController.java`

```java
package com.data2ai.kafka.controller;

import com.data2ai.kafka.model.Order;
import com.data2ai.kafka.service.DltService;
import com.data2ai.kafka.service.OrderService;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;

import java.util.Map;

/**
 * Controller REST pour l'API de gestion des commandes.
 * 
 * Endpoints :
 * - POST /api/v1/orders         : CrÃ©er une commande
 * - GET  /api/v1/stats          : Statistiques de traitement
 * - GET  /api/v1/dlt/count      : Compteur DLT
 * - POST /api/v1/config/...     : Configuration simulation
 * - GET  /api/v1/health         : Health check
 */
@RestController
@RequestMapping("/api/v1")
public class OrderController {

    private final OrderService orderService;
    private final DltService dltService;

    // Injection de dÃ©pendances via constructeur (recommandÃ©)
    public OrderController(OrderService orderService, DltService dltService) {
        this.orderService = orderService;
        this.dltService = dltService;
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // POST /api/v1/orders
    // CrÃ©e une nouvelle commande et l'envoie Ã  Kafka
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @PostMapping("/orders")
    public ResponseEntity<?> createOrder(@RequestBody Order order) {
        try {
            orderService.sendOrder(order);
            return ResponseEntity.ok(Map.of(
                "status", "ACCEPTED",
                "orderId", order.getOrderId(),
                "message", "Order sent to Kafka"
            ));
            
        } catch (OrderService.PermanentException e) {
            // Erreur de validation â†’ 400 Bad Request
            return ResponseEntity.badRequest().body(Map.of(
                "status", "REJECTED",
                "orderId", order.getOrderId(),
                "error", e.getMessage(),
                "action", "Sent to DLT"
            ));
            
        } catch (OrderService.TransientException e) {
            // Erreur temporaire â†’ 503 Service Unavailable
            // Le client devrait retry
            return ResponseEntity.status(503).body(Map.of(
                "status", "RETRY",
                "orderId", order.getOrderId(),
                "error", e.getMessage()
            ));
            
        } catch (Exception e) {
            // Erreur inattendue â†’ 500 Internal Server Error
            return ResponseEntity.internalServerError().body(Map.of(
                "status", "ERROR",
                "error", e.getMessage()
            ));
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // CONFIGURATION SIMULATION D'ERREURS
    // Pour tester le comportement de retry en dÃ©veloppement
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @PostMapping("/config/simulate-transient-error")
    public ResponseEntity<?> setTransientErrorSimulation(@RequestParam boolean enabled) {
        orderService.setSimulateTransientError(enabled);
        return ResponseEntity.ok(Map.of(
            "simulateTransientError", enabled,
            "message", enabled ? "Transient errors enabled" : "Transient errors disabled"
        ));
    }

    @GetMapping("/config/simulate-transient-error")
    public ResponseEntity<?> getTransientErrorSimulation() {
        return ResponseEntity.ok(Map.of(
            "simulateTransientError", orderService.isSimulatingTransientError()
        ));
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // MONITORING ET STATISTIQUES
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    @GetMapping("/stats")
    public ResponseEntity<?> getStats() {
        OrderService.Stats stats = orderService.getStats();
        return ResponseEntity.ok(Map.of(
            "success", stats.success,
            "errors", stats.errors,
            "dlt", stats.dlt
        ));
    }

    @GetMapping("/dlt/count")
    public ResponseEntity<?> getDltCount() {
        return ResponseEntity.ok(Map.of(
            "dltCount", dltService.getDltCount()
        ));
    }

    @GetMapping("/health")
    public ResponseEntity<?> health() {
        return ResponseEntity.ok(Map.of("status", "UP"));
    }
}
```

### 8.2 Table des codes HTTP

| Code | Signification | Quand |
|------|--------------|-------|
| **200** | OK | Commande acceptÃ©e |
| **400** | Bad Request | Validation Ã©chouÃ©e (â†’ DLT) |
| **503** | Service Unavailable | Erreur temporaire (â†’ Retry) |
| **500** | Internal Server Error | Erreur inattendue |

---

## ğŸ“„ Ã‰tape 9 : Configuration application.properties

### 9.1 CrÃ©er `src/main/resources/application.properties`

```properties
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SERVER CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
server.port=8080

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KAFKA CONFIGURATION
# Ces valeurs peuvent Ãªtre surchargÃ©es par variables d'environnement
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
spring.kafka.bootstrap-servers=${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ACTUATOR (Health checks)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
management.endpoints.web.exposure.include=health,info,metrics
management.endpoint.health.show-details=always

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LOGGING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
logging.level.org.apache.kafka=WARN
logging.level.com.data2ai.kafka=INFO
```

---

## ğŸ³ Ã‰tape 10 : Dockerfile

### 10.1 CrÃ©er `Dockerfile`

```dockerfile
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 1 : BUILD
# Compile l'application avec Maven
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM maven:3.9-eclipse-temurin-17 AS build

WORKDIR /app

# Copier d'abord le pom.xml pour cache des dÃ©pendances
COPY pom.xml .
RUN mvn dependency:go-offline -B

# Copier le code source et compiler
COPY src ./src
RUN mvn package -DskipTests -B

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 2 : RUNTIME
# Image lÃ©gÃ¨re avec uniquement le JAR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM eclipse-temurin:17-jre-alpine

WORKDIR /app

# Copier le JAR depuis le stage de build
COPY --from=build /app/target/*.jar app.jar

# Variables d'environnement par dÃ©faut
ENV KAFKA_BOOTSTRAP_SERVERS=kafka:29092
ENV KAFKA_TOPIC=orders
ENV KAFKA_DLT_TOPIC=orders.DLT

# Port exposÃ©
EXPOSE 8080

# Commande de dÃ©marrage
ENTRYPOINT ["java", "-jar", "app.jar"]
```

### 10.2 Multi-stage build expliquÃ©

```mermaid
flowchart LR
    subgraph stage1["Stage 1: BUILD (~800MB)"]
        M["Maven 3.9"] --> J["JDK 17"] --> JAR["app.jar"]
    end
    
    subgraph stage2["Stage 2: RUNTIME (~150MB)"]
        JRE["JRE 17 Alpine"] --> APP["app.jar"]
    end
    
    stage1 -->|"COPY --from=build"| stage2
```

---

## ğŸ§ª Ã‰tape 11 : Tester l'API

### 11.1 CrÃ©er `requests.http` (REST Client VS Code)

```http
### Variables
@baseUrl = http://localhost:8080/api/v1

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### HEALTH CHECK
### VÃ©rifie que l'API est en ligne
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GET {{baseUrl}}/health

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### CREATE ORDER - SuccÃ¨s
### Commande valide â†’ 200 OK
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POST {{baseUrl}}/orders
Content-Type: application/json

{
    "orderId": "ORD-001",
    "amount": 99.99,
    "status": "NEW"
}

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### CREATE ORDER - Validation Error â†’ DLT
### Amount nÃ©gatif â†’ 400 Bad Request + envoi au DLT
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POST {{baseUrl}}/orders
Content-Type: application/json

{
    "orderId": "ORD-BAD",
    "amount": -50.00,
    "status": "NEW"
}

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### CREATE ORDER - Missing ID â†’ DLT
### OrderId manquant â†’ 400 Bad Request + envoi au DLT
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POST {{baseUrl}}/orders
Content-Type: application/json

{
    "orderId": "",
    "amount": 25.00,
    "status": "NEW"
}

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### ENABLE TRANSIENT ERROR SIMULATION
### Active la simulation d'erreurs temporaires
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POST {{baseUrl}}/config/simulate-transient-error?enabled=true

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### CREATE ORDER with Transient Error
### Retourne 503 Service Unavailable
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POST {{baseUrl}}/orders
Content-Type: application/json

{
    "orderId": "ORD-RETRY",
    "amount": 50.00,
    "status": "NEW"
}

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### DISABLE TRANSIENT ERROR SIMULATION
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
POST {{baseUrl}}/config/simulate-transient-error?enabled=false

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### GET STATS
### Statistiques de traitement
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GET {{baseUrl}}/stats

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### GET DLT COUNT
### Nombre de messages envoyÃ©s au DLT
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GET {{baseUrl}}/dlt/count
```

---

## ï¿½ Ã‰tape 12 : Docker Compose - Build et DÃ©ploiement

### 12.1 Architecture Docker

```mermaid
flowchart TB
    subgraph "Docker Network: bhf-kafka-network"
        K["ğŸ“¦ Kafka<br/>:29092"]
        UI["ğŸ–¥ï¸ Kafka UI<br/>:8080"]
        JAVA["â˜• Java API<br/>:18082"]
        DOTNET["ğŸ”· .NET Consumer<br/>:18083"]
    end
    
    JAVA -->|produce| K
    K -->|consume| DOTNET
    UI --> K
```

### 12.2 DÃ©marrer l'infrastructure Kafka

```powershell
# Depuis la racine formation-v2/
cd infra

# DÃ©marrer Kafka single-node + Kafka UI
docker-compose -f docker-compose.single-node.yml up -d

# VÃ©rifier que Kafka est healthy
docker-compose -f docker-compose.single-node.yml ps
```

### 12.3 CrÃ©er les topics

```powershell
docker exec -it kafka kafka-topics.sh --create --topic orders --partitions 3 --bootstrap-server localhost:9092
docker exec -it kafka kafka-topics.sh --create --topic orders.DLT --partitions 1 --bootstrap-server localhost:9092
docker exec -it kafka kafka-topics.sh --create --topic orders.retry --partitions 1 --bootstrap-server localhost:9092
```

### 12.4 Build et dÃ©marrer les APIs du module

```powershell
# Depuis le rÃ©pertoire du module
cd ../day-02-development/module-04-advanced-patterns

# Build et dÃ©marrer les APIs Java + .NET
docker-compose -f docker-compose.module.yml up -d --build

# VÃ©rifier les containers
docker-compose -f docker-compose.module.yml ps
```

### 12.5 docker-compose.module.yml (rÃ©fÃ©rence)

```yaml
services:
  java-api:
    build:
      context: ./java
    container_name: m04-java-api
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: orders
      KAFKA_DLT_TOPIC: orders.DLT
      KAFKA_RETRY_TOPIC: orders.retry
      MAX_RETRIES: 3
    ports:
      - "18082:8080"
    networks:
      - bhf-kafka-network

  dotnet-consumer:
    build:
      context: ./dotnet
    container_name: m04-dotnet-consumer
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      KAFKA_TOPIC: orders
      KAFKA_GROUP_ID: orders-consumer-group
    ports:
      - "18083:8080"
    networks:
      - bhf-kafka-network

networks:
  bhf-kafka-network:
    external: true
```

### 12.6 Tester les APIs

```powershell
# Java API (port 18082) - Health check
curl http://localhost:18082/health

# Java API - CrÃ©er une commande
curl -X POST http://localhost:18082/api/v1/orders \
  -H "Content-Type: application/json" \
  -d '{"orderId":"TEST-001","amount":99.99,"status":"NEW"}'

# Java API - Voir les stats
curl http://localhost:18082/api/v1/stats

# .NET Consumer (port 18083) - Health check
curl http://localhost:18083/health

# Consulter Kafka UI
# Ouvrir http://localhost:8080
```

### 12.7 ArrÃªter les services

```powershell
docker-compose -f docker-compose.module.yml down
```

---

## ğŸ–¥ï¸ Alternative : ExÃ©cution locale (sans Docker)

### Lancer l'application

```powershell
# S'assurer que Kafka tourne sur localhost:9092
mvn spring-boot:run
```

### Tester localement

```powershell
# Health check
curl http://localhost:8080/api/v1/health

# CrÃ©er une commande
curl -X POST http://localhost:8080/api/v1/orders \
  -H "Content-Type: application/json" \
  -d '{"orderId":"TEST-001","amount":99.99,"status":"NEW"}'

# Voir les stats
curl http://localhost:8080/api/v1/stats
```

---

## ğŸ“š Ressources et documentation

| Sujet | Lien |
|-------|------|
| **Spring Kafka** | [Documentation officielle](https://docs.spring.io/spring-kafka/reference/html/) |
| **Apache Kafka** | [kafka.apache.org](https://kafka.apache.org/documentation/) |
| **Spring Boot** | [spring.io/guides](https://spring.io/guides) |
| **Jackson JSON** | [GitHub FasterXML](https://github.com/FasterXML/jackson) |
| **VS Code Java** | [code.visualstudio.com/docs/java](https://code.visualstudio.com/docs/java/java-tutorial) |

---

## âœ… Checklist de validation

- [ ] `pom.xml` crÃ©Ã© avec toutes les dÃ©pendances
- [ ] Structure des packages Java crÃ©Ã©e
- [ ] `Application.java` point d'entrÃ©e crÃ©Ã©
- [ ] `KafkaConfig.java` avec Producer/Consumer configurÃ©s
- [ ] `Order.java` modÃ¨le avec validation
- [ ] `DltService.java` pour Dead Letter Topic
- [ ] `OrderService.java` avec gestion d'erreurs
- [ ] `OrderController.java` avec tous les endpoints
- [ ] `application.properties` configurÃ©
- [ ] `Dockerfile` multi-stage crÃ©Ã©
- [ ] `requests.http` pour tests REST Client
- [ ] API testÃ©e avec commandes valides et invalides
- [ ] Messages DLT vÃ©rifiÃ©s dans Kafka

---

**ğŸ‰ FÃ©licitations !** Vous avez implÃ©mentÃ© une API Kafka robuste avec gestion des erreurs, retry et DLT !
