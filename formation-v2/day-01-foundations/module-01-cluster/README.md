# Module 01 - Architecture du Cluster Kafka (KRaft) - Formation Auto-rythm√©e

## Dur√©e estim√©e

‚è±Ô∏è **30-45 minutes**

## Objectifs p√©dagogiques

√Ä la fin de ce module, vous serez capable de :

1. ‚úÖ Comprendre l'architecture d'un cluster Kafka avec KRaft (sans ZooKeeper)
2. ‚úÖ D√©marrer et arr√™ter un cluster Kafka local via Docker Compose
3. ‚úÖ V√©rifier l'√©tat de sant√© du cluster
4. ‚úÖ Cr√©er un topic avec plusieurs partitions
5. ‚úÖ Produire et consommer des messages via la ligne de commande
6. ‚úÖ Naviguer dans Kafka UI pour visualiser les messages

---

## üìñ Partie Th√©orique

### 1. Qu'est-ce que Apache Kafka ?

**Apache Kafka** est une plateforme de streaming distribu√©e open-source, initialement d√©velopp√©e par LinkedIn et maintenant maintenue par la Apache Software Foundation.

#### Cas d'usage principaux

```mermaid
mindmap
  root((Apache Kafka))
    Messaging
      File d'attente de messages
      Pub/Sub
      D√©couplage des syst√®mes
    Streaming
      Traitement temps r√©el
      ETL en continu
      Agr√©gation de donn√©es
    Stockage
      Log distribu√©
      Event Sourcing
      Audit trail
    Int√©gration
      Microservices
      CDC (Change Data Capture)
      Data Pipeline
```

#### Caract√©ristiques cl√©s

| Caract√©ristique | Description |
|-----------------|-------------|
| **Haute performance** | Millions de messages/seconde avec latence < 10ms |
| **Scalabilit√© horizontale** | Ajout de brokers sans interruption |
| **Durabilit√©** | Messages persist√©s sur disque, r√©pliqu√©s |
| **Tol√©rance aux pannes** | R√©plication automatique, failover |
| **Ordre garanti** | Au sein d'une partition |

---

### 2. Architecture de Kafka

#### Vue d'ensemble

```mermaid
flowchart TB
    subgraph Producers["üì§ Producers"]
        P1["Application A"]
        P2["Application B"]
        P3["Service C"]
    end
    
    subgraph Cluster["üî∑ Kafka Cluster"]
        subgraph B1["Broker 1"]
            T1P0["Topic1-P0<br/>Leader"]
            T1P1["Topic1-P1<br/>Follower"]
        end
        subgraph B2["Broker 2"]
            T1P0F["Topic1-P0<br/>Follower"]
            T1P1L["Topic1-P1<br/>Leader"]
        end
        subgraph B3["Broker 3"]
            T1P2["Topic1-P2<br/>Leader"]
        end
    end
    
    subgraph Consumers["üì• Consumers"]
        CG1["Consumer Group A"]
        CG2["Consumer Group B"]
    end
    
    P1 --> B1
    P2 --> B2
    P3 --> B3
    
    B1 --> CG1
    B2 --> CG1
    B3 --> CG2
    
    style Cluster fill:#e8f5e8
```

#### Composants fondamentaux

| Composant | Ic√¥ne | Description |
|-----------|-------|-------------|
| **Broker** | üñ•Ô∏è | Serveur Kafka qui stocke les messages et sert les clients |
| **Topic** | üìÅ | Cat√©gorie logique pour organiser les messages |
| **Partition** | üìä | Subdivision d'un topic pour la parall√©lisation |
| **Producer** | üì§ | Application qui envoie des messages |
| **Consumer** | üì• | Application qui lit des messages |
| **Consumer Group** | üë• | Ensemble de consumers qui se partagent la lecture |

---

### 3. Topics et Partitions

#### Concept de Topic

Un **Topic** est un flux de messages nomm√©. C'est la cat√©gorie dans laquelle les messages sont publi√©s.

```mermaid
flowchart LR
    subgraph Topic["üìÅ Topic: orders"]
        P0["Partition 0<br/>‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"]
        P1["Partition 1<br/>‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"]
        P2["Partition 2<br/>‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"]
    end
    
    Producer["üì§ Producer"] --> Topic
    Topic --> Consumer["üì• Consumer"]
```

#### Anatomie d'une Partition

Une **Partition** est un log ordonn√© et immuable de messages :

```
Partition 0:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  0  ‚îÇ  1  ‚îÇ  2  ‚îÇ  3  ‚îÇ  4  ‚îÇ  5  ‚îÇ  6  ‚îÇ  7  ‚îÇ  ‚Üê Offsets
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ  ‚Üê Messages
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚Üë
                                         Nouveaux messages
                                         (append-only)
```

#### Pourquoi plusieurs partitions ?

```mermaid
flowchart TB
    subgraph Single["‚ùå 1 Partition = Goulot d'√©tranglement"]
        S1["Consumer 1"] --> SP["Partition 0"]
        S2["Consumer 2"] -.->|"attend"| SP
        S3["Consumer 3"] -.->|"attend"| SP
    end
    
    subgraph Multi["‚úÖ 3 Partitions = Parall√©lisme"]
        M1["Consumer 1"] --> MP0["Partition 0"]
        M2["Consumer 2"] --> MP1["Partition 1"]
        M3["Consumer 3"] --> MP2["Partition 2"]
    end
```

| Nombre de partitions | Avantages | Inconv√©nients |
|----------------------|-----------|---------------|
| **1** | Ordre global garanti | Pas de parall√©lisme |
| **3-10** | Bon √©quilibre | Standard pour la plupart des cas |
| **100+** | Tr√®s haut d√©bit | Plus de ressources, latence accrue |

---

### 4. Offsets et Consommation

#### Qu'est-ce qu'un Offset ?

L'**Offset** est la position unique d'un message dans une partition. C'est un entier croissant.

```mermaid
flowchart LR
    subgraph Partition["Partition 0"]
        O0["Offset 0<br/>Message A"]
        O1["Offset 1<br/>Message B"]
        O2["Offset 2<br/>Message C"]
        O3["Offset 3<br/>Message D"]
        O4["Offset 4<br/>Message E"]
    end
    
    O0 --> O1 --> O2 --> O3 --> O4
    
    Consumer["üì• Consumer<br/>Position: Offset 3"]
    Consumer -.->|"Lit"| O3
```

#### Gestion des Offsets

| Mode | Description | Cas d'usage |
|------|-------------|-------------|
| **Earliest** | Lire depuis le d√©but | Retraitement complet |
| **Latest** | Lire les nouveaux messages uniquement | Temps r√©el |
| **Specific** | Lire depuis un offset pr√©cis | Reprise apr√®s erreur |

---

### 5. Mode KRaft vs ZooKeeper

#### √âvolution de l'architecture

```mermaid
timeline
    title √âvolution de Kafka
    2011 : Kafka cr√©√© par LinkedIn avec ZooKeeper
    2017 : KIP-500 propos√© (suppression ZooKeeper)
    2022 : KRaft en production (Kafka 3.3)
    2024 : ZooKeeper d√©pr√©ci√© (Kafka 4.0)
```

#### Comparaison

```mermaid
flowchart TB
    subgraph Old["‚ùå Ancienne Architecture (ZooKeeper)"]
        ZK["üî∑ ZooKeeper<br/>Coordination"]
        KB1["Kafka Broker 1"]
        KB2["Kafka Broker 2"]
        KB3["Kafka Broker 3"]
        
        ZK <--> KB1
        ZK <--> KB2
        ZK <--> KB3
    end
    
    subgraph New["‚úÖ Nouvelle Architecture (KRaft)"]
        KC1["Kafka 1<br/>Broker + Controller"]
        KC2["Kafka 2<br/>Broker + Controller"]
        KC3["Kafka 3<br/>Broker + Controller"]
        
        KC1 <-->|"Raft"| KC2
        KC2 <-->|"Raft"| KC3
        KC3 <-->|"Raft"| KC1
    end
```

| Aspect | ZooKeeper | KRaft |
|--------|-----------|-------|
| **Composants** | Kafka + ZooKeeper | Kafka seul |
| **Complexit√©** | √âlev√©e | R√©duite |
| **Performances** | Bonnes | Meilleures |
| **Scalabilit√©** | Limit√©e par ZK | Am√©lior√©e |
| **D√©marrage** | Lent | Rapide |

---

### 6. Producer et Consumer

#### Le Producer

```mermaid
sequenceDiagram
    participant App as Application
    participant P as Producer
    participant K as Kafka Broker
    
    App->>P: send(topic, message)
    P->>P: S√©rialisation
    P->>P: Partitionnement
    P->>K: Envoi au leader
    K->>K: √âcriture sur disque
    K->>K: R√©plication
    K-->>P: ACK (acknowledgment)
    P-->>App: Confirmation
```

#### Le Consumer

```mermaid
sequenceDiagram
    participant C as Consumer
    participant K as Kafka Broker
    participant App as Application
    
    C->>K: subscribe(topic)
    loop Polling
        C->>K: poll()
        K-->>C: Messages (batch)
        C->>App: Traitement
        C->>K: commit(offset)
    end
```

---

### 7. Diagramme d'architecture du Lab

```mermaid
flowchart TB
    subgraph Docker["üê≥ Docker Environment"]
        subgraph KafkaContainer["Container: kafka"]
            KB["Apache Kafka<br/>Mode: KRaft<br/>Image: apache/kafka:latest"]
            KData[("üìÅ Volume<br/>kafka-data")]
        end
        
        subgraph UIContainer["Container: kafka-ui"]
            UI["Kafka UI<br/>Image: provectuslabs/kafka-ui"]
        end
        
        Network["üåê Network: bhf-kafka-network"]
    end
    
    subgraph Host["üíª Votre Machine"]
        Terminal["üñ•Ô∏è Terminal<br/>kafka-console-*"]
        Browser["üåê Navigateur"]
    end
    
    Terminal -->|"Port 9092"| KB
    Browser -->|"Port 8080"| UI
    UI -->|"Port 29092<br/>(interne)"| KB
    KB --> KData
    
    KB --- Network
    UI --- Network
    
    style Docker fill:#e3f2fd
    style KafkaContainer fill:#e8f5e8
    style UIContainer fill:#fff3e0
```

## Ports et URLs

| Service | Port | URL |
|---------|------|-----|
| Kafka (externe) | 9092 | `localhost:9092` |
| Kafka (interne Docker) | 29092 | `kafka:29092` |
| Kafka UI | 8080 | http://localhost:8080 |

## Pr√©-requis

### Logiciels n√©cessaires

- ‚úÖ **Docker Desktop** ou **Docker Engine** (version 20.10+)
- ‚úÖ **Docker Compose** plugin (`docker compose` - pas `docker-compose`)
- ‚úÖ **Terminal** (Bash, PowerShell, ou autre)
- ‚úÖ **Navigateur web** (Chrome, Firefox, Edge)

### V√©rification des pr√©-requis

```bash
# V√©rifier Docker
docker --version
# Attendu: Docker version 20.10+ ou sup√©rieur

# V√©rifier Docker Compose
docker compose version
# Attendu: Docker Compose version v2.x.x
```

---

## üìö Guide pas √† pas

### √âtape 0 - Positionnement dans le r√©pertoire

**Objectif** : Se placer dans le bon r√©pertoire de travail.

```bash
cd formation-v2/
```

**V√©rification** :

```bash
ls -la scripts/
```

**R√©sultat attendu** : Vous devez voir les fichiers `up.sh`, `down.sh`, `start.sh`, `stop.sh`.

---

### √âtape 1 - D√©marrage du cluster Kafka

**Objectif** : Lancer le cluster Kafka en mode KRaft avec Kafka UI.

**Explication** : Le script `up.sh` va :
1. T√©l√©charger l'image `apache/kafka:latest` (si n√©cessaire)
2. Cr√©er le r√©seau Docker `bhf-kafka-network`
3. D√©marrer le conteneur Kafka en mode KRaft
4. D√©marrer Kafka UI pour la visualisation

**Commande** :

```bash
./scripts/up.sh
```

**R√©sultat attendu** :

```
Starting Kafka KRaft SINGLE NODE...
Checking for existing containers...
[+] Running 3/3
 ‚úî Network bhf-kafka-network  Created
 ‚úî Container kafka            Started
 ‚úî Container kafka-ui         Started
‚úÖ Kafka KRaft single-node is ready!
Kafka UI: http://localhost:8080
```

**‚è±Ô∏è Temps d'attente** : 30-60 secondes pour le premier d√©marrage.

**üí° Astuce** : Si vous voyez des erreurs, attendez 30 secondes et passez √† l'√©tape suivante pour v√©rifier l'√©tat.

---

### √âtape 2 - V√©rification de l'√©tat du cluster

**Objectif** : S'assurer que tous les conteneurs sont en fonctionnement.

**Commande** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'
```

**R√©sultat attendu** :

```
NAMES       STATUS                   PORTS
kafka-ui    Up X minutes (healthy)   0.0.0.0:8080->8080/tcp
kafka       Up X minutes (healthy)   0.0.0.0:9092->9092/tcp, 0.0.0.0:29092->29092/tcp
```

**‚úÖ Checkpoint 1** : Les deux conteneurs affichent `(healthy)`.

**‚ö†Ô∏è Si "unhealthy" ou "starting"** : Attendez 30 secondes suppl√©mentaires et relancez la commande.

---

### √âtape 3 - Acc√®s √† Kafka UI

**Objectif** : V√©rifier que l'interface web est accessible.

**Action** : Ouvrez votre navigateur et acc√©dez √† :

üëâ **http://localhost:8080**

**Ce que vous devez voir** :

1. Page d'accueil de Kafka UI
2. Cluster nomm√© `BHF-Training` dans la liste
3. Statut du cluster : **Online**

**Navigation dans Kafka UI** :

| Menu | Description |
|------|-------------|
| **Dashboard** | Vue d'ensemble du cluster |
| **Brokers** | Liste des brokers (1 dans notre cas) |
| **Topics** | Liste des topics existants |
| **Consumers** | Groupes de consommateurs |

**‚úÖ Checkpoint 2** : Kafka UI est accessible et affiche le cluster.

---

### √âtape 4 - Lister les topics existants

**Objectif** : Utiliser la CLI Kafka pour lister les topics.

**Explication** : Nous ex√©cutons la commande `kafka-topics.sh` √† l'int√©rieur du conteneur Kafka.

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --list
```

**R√©sultat attendu** : Liste vide ou quelques topics internes (commen√ßant par `__`).

**Explication des param√®tres** :

| Param√®tre | Description |
|-----------|-------------|
| `docker exec kafka` | Ex√©cute une commande dans le conteneur `kafka` |
| `/opt/kafka/bin/kafka-topics.sh` | Script de gestion des topics |
| `--bootstrap-server localhost:9092` | Adresse du broker Kafka |
| `--list` | Action : lister les topics |

---

### √âtape 5 - Cr√©ation d'un topic avec 3 partitions

**Objectif** : Cr√©er un topic nomm√© `bhf-demo` avec 3 partitions.

**Th√©orie** : Les partitions permettent :
- **Parall√©lisme** : Plusieurs consommateurs peuvent lire en parall√®le
- **Scalabilit√©** : Les donn√©es sont distribu√©es sur plusieurs partitions
- **Ordre** : L'ordre est garanti uniquement au sein d'une partition

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create \
  --if-not-exists \
  --topic bhf-demo \
  --partitions 3 \
  --replication-factor 1
```

**R√©sultat attendu** :

```
Created topic bhf-demo.
```

**Explication des param√®tres** :

| Param√®tre | Description |
|-----------|-------------|
| `--create` | Action : cr√©er un topic |
| `--if-not-exists` | Ne pas √©chouer si le topic existe d√©j√† |
| `--topic bhf-demo` | Nom du topic |
| `--partitions 3` | Nombre de partitions |
| `--replication-factor 1` | Facteur de r√©plication (1 car cluster single-node) |

---

### √âtape 6 - Description du topic

**Objectif** : V√©rifier la configuration du topic cr√©√©.

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe \
  --topic bhf-demo
```

**R√©sultat attendu** :

```
Topic: bhf-demo	TopicId: xxxxx	PartitionCount: 3	ReplicationFactor: 1	Configs: 
	Topic: bhf-demo	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
	Topic: bhf-demo	Partition: 1	Leader: 1	Replicas: 1	Isr: 1
	Topic: bhf-demo	Partition: 2	Leader: 1	Replicas: 1	Isr: 1
```

**Explication de la sortie** :

| Champ | Description |
|-------|-------------|
| `PartitionCount: 3` | Le topic a bien 3 partitions |
| `Leader: 1` | Le broker 1 est leader de chaque partition |
| `Replicas: 1` | Une seule r√©plique (cluster single-node) |
| `Isr: 1` | In-Sync Replicas : r√©pliques synchronis√©es |

**‚úÖ Checkpoint 3** : Le topic `bhf-demo` existe avec 3 partitions.

---

### √âtape 7 - Production d'un message

**Objectif** : Envoyer un message dans le topic `bhf-demo`.

**Th√©orie** : Le **Producer** est responsable de :
- S√©rialiser les messages
- D√©terminer la partition de destination
- Envoyer les messages au broker

**Commande** :

```bash
# G√©n√©rer un message unique avec timestamp
MSG="hello-bhf-$(date +%s)"
echo "Message √† envoyer: $MSG"

# Envoyer le message
echo "$MSG" | docker exec -i kafka /opt/kafka/bin/kafka-console-producer.sh \
  --bootstrap-server localhost:9092 \
  --topic bhf-demo
```

**R√©sultat attendu** : Pas de message d'erreur (la commande se termine silencieusement).

**üí° Note** : Le flag `-i` permet de passer l'entr√©e standard au conteneur.

---

### √âtape 8 - Consommation du message

**Objectif** : Lire le message envoy√© depuis le topic.

**Th√©orie** : Le **Consumer** est responsable de :
- Souscrire √† un ou plusieurs topics
- Lire les messages depuis les partitions
- G√©rer les offsets (position de lecture)

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic bhf-demo \
  --from-beginning \
  --timeout-ms 10000
```

**R√©sultat attendu** :

```
hello-bhf-1706390000
```

**Explication des param√®tres** :

| Param√®tre | Description |
|-----------|-------------|
| `--from-beginning` | Lire depuis le d√©but du topic |
| `--timeout-ms 10000` | Timeout de 10 secondes si pas de nouveaux messages |

**‚úÖ Checkpoint 4** : Le message produit a √©t√© consomm√© avec succ√®s.

---

### √âtape 9 - Visualisation dans Kafka UI

**Objectif** : Observer les messages via l'interface graphique.

**Actions** :

1. Ouvrez **http://localhost:8080** dans votre navigateur
2. Cliquez sur le cluster **BHF-Training**
3. Dans le menu, cliquez sur **Topics**
4. Cliquez sur le topic **bhf-demo**
5. Cliquez sur l'onglet **Messages**
6. Cliquez sur le bouton **‚ñ∂ Fetch Messages** ou r√©glez sur **Live mode**

**Ce que vous devez voir** :

- Le message `hello-bhf-XXXX` appara√Æt dans la liste
- La partition d'affectation (0, 1 ou 2)
- L'offset du message
- Le timestamp

**üí° Exploration suppl√©mentaire** :

- Onglet **Overview** : statistiques du topic
- Onglet **Partitions** : r√©partition des partitions
- Onglet **Settings** : configuration du topic

**‚úÖ Checkpoint 5** : Le message est visible dans Kafka UI.

---

### √âtape 10 - Validation automatis√©e

**Objectif** : Ex√©cuter le script de validation pour confirmer que tout fonctionne.

**Commande** :

```bash
./day-01-foundations/module-01-cluster/scripts/validate.sh
```

**R√©sultat attendu** :

```
OK
```

**Ce que le script v√©rifie** :
1. ‚úÖ Le conteneur `kafka` est en cours d'ex√©cution
2. ‚úÖ Le conteneur `kafka-ui` est en cours d'ex√©cution
3. ‚úÖ Kafka UI r√©pond sur le port 8080
4. ‚úÖ Le topic `bhf-demo` existe avec 3 partitions
5. ‚úÖ Un message peut √™tre produit et consomm√©

---

## ‚úÖ R√©capitulatif des checkpoints

| # | Checkpoint | Statut |
|---|------------|--------|
| 1 | Conteneurs `kafka` et `kafka-ui` sont healthy | ‚òê |
| 2 | Kafka UI accessible sur http://localhost:8080 | ‚òê |
| 3 | Topic `bhf-demo` cr√©√© avec 3 partitions | ‚òê |
| 4 | Message produit et consomm√© via CLI | ‚òê |
| 5 | Message visible dans Kafka UI | ‚òê |
| 6 | Script `validate.sh` retourne OK | ‚òê |

---

## üîß Troubleshooting

### Probl√®me : Kafka ne d√©marre pas

**Sympt√¥me** : Le conteneur `kafka` reste en `starting` ou `unhealthy`.

**Solutions** :

1. **V√©rifiez les logs** :
   ```bash
   docker logs kafka --tail 50
   ```

2. **Red√©marrez le cluster** :
   ```bash
   ./scripts/down.sh
   ./scripts/up.sh
   ```

3. **Nettoyez les volumes** (perte de donn√©es) :
   ```bash
   docker volume rm bhf-kafka_kafka-data
   ```

### Probl√®me : Kafka UI non accessible

**Sympt√¥me** : http://localhost:8080 ne r√©pond pas.

**Solutions** :

1. **V√©rifiez que kafka-ui est running** :
   ```bash
   docker ps | grep kafka-ui
   ```

2. **V√©rifiez les logs** :
   ```bash
   docker logs kafka-ui --tail 50
   ```

3. **V√©rifiez qu'un autre service n'utilise pas le port 8080** :
   ```bash
   # Linux/Mac
   lsof -i :8080
   # Windows
   netstat -ano | findstr :8080
   ```

### Probl√®me : Commande kafka-topics.sh non trouv√©e

**Sympt√¥me** : `kafka-topics: command not found`

**Solution** : Utilisez le chemin complet `/opt/kafka/bin/kafka-topics.sh`.

---

## üßπ Nettoyage

**Objectif** : Arr√™ter et supprimer les conteneurs.

**Commande** :

```bash
./scripts/down.sh
```

**R√©sultat attendu** :

```
Stopping Kafka KRaft SINGLE NODE...
[+] Running 3/3
 ‚úî Container kafka-ui         Removed
 ‚úî Container kafka            Removed
 ‚úî Volume bhf-kafka_kafka-data Removed
‚úÖ Kafka KRaft single-node stopped and cleaned up!
```

---

## üìñ Pour aller plus loin

### Exercices suppl√©mentaires

1. **Cr√©ez un topic avec 5 partitions** et observez la distribution dans Kafka UI
2. **Produisez 10 messages** et observez comment ils sont r√©partis sur les partitions
3. **Utilisez une cl√©** lors de la production pour garantir l'ordre :
   ```bash
   echo "key1:message1" | docker exec -i kafka /opt/kafka/bin/kafka-console-producer.sh \
     --bootstrap-server localhost:9092 \
     --topic bhf-demo \
     --property "parse.key=true" \
     --property "key.separator=:"
   ```

### Ressources

- [Documentation officielle Apache Kafka](https://kafka.apache.org/documentation/)
- [KRaft Mode Documentation](https://kafka.apache.org/documentation/#kraft)
- [Kafka UI GitHub](https://github.com/provectus/kafka-ui)

---

## ‚û°Ô∏è Module suivant

Une fois ce module termin√©, passez au :

üëâ **[Module 02 - Fiabilit√© du Producteur](../module-02-producer-reliability/README.md)**
