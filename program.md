Data2AI – Programme de
formation Apache Kafka (3 jours)
Niveau : Développeurs &amp; Ingénieurs Data
Format : présentiel / distanciel – 70% pratique, 30% théorie
Durée : 3 jours (21 heures)
�� Objectifs pédagogiques
À l’issue des 3 jours, les participants seront capables de :
 Comprendre l’architecture interne de Kafka et ses garanties.
 Développer des producteurs et consommateurs robustes.
 Implémenter des modèles de streaming avec Kafka Streams.
 Intégrer Kafka avec d’autres systèmes via Kafka Connect.
 Tester et monitorer une application Kafka professionnelle.
�� Jour 1 — Fondamentaux et Développement d’applications Kafka
Module 1 – Fondamentaux d’Apache Kafka
Contenu
 Pourquoi Kafka ?
 Cas d’usage modernes : microservices, data streaming, ETL temps réel.
 Architecture interne : log distribué, cluster, brokers.
 Concepts : topics, partitions, réplication, offsets.
 Rôle des producers, consumers et consumer groups.
 Durée de rétention, compactage, ordering, garanties de livraison.
Atelier pratique
 Installation locale ou Docker compose/K8s.
 Création d’un topic + envoi/réception de premiers messages.
�� Jour 2 — Développement avancé &amp; Kafka Streams
Module 2 – Développement d&#39;applications
API Producer
 Messages clé/valeur.

 Acks, retries, idempotence.
 Gestion du partitionnement (clé, hash, manuel).
API Consumer
 Souscription.
 Poll loop, gestion avancée des offsets.
 Rebalancing et consumer group rejoin.
Patterns professionnels
 Dead-letter topics (DLT).
 Retries applicatifs.
 Gestion d’erreurs, timeouts, exceptions.
Atelier pratique
 Implémentation d’un pipeline Producer → Kafka → Consumer.
 Simulation d’erreurs et gestion via DLT.
Module 3 – Kafka Streams (12%)
Concepts
 Stream vs table.
 KStream / KTable.
 Operations : map, filter, join, aggregation.
Cas d’usage typiques
 Enrichissement de données.
 Agrégations par clé.
 Comptage d’événements.
Atelier pratique
 Création d’une application Kafka Streams (Java/Scala).
 Agrégation temps réel d’événements.
�� Jour 3 — Kafka Connect, Tests &amp; Observabilité
Module 4 – Kafka Connect (15%)
Concepts clés
 Principe source/sink.
 Connecteurs prêts à l’emploi (DB, fichiers, REST, S3…).

 Gestion de la configuration d’un connecteur.
 Offsets de Connect, gestion des erreurs.
Atelier pratique
 Déploiement d’un connecteur source + sink.
 Test d’un mini-ETL temps réel.
Module 5 – Tests d’applications Kafka (8%)
Tests unitaires
 Mocking des producers/consumers.
 Testing du poll loop.
Environnements de test
 Embedded Kafka (Testcontainers).
 Tests d’intégration bout-en-bout.
Atelier pratique
 Mise en place d’un pipeline Kafka + test d’intégration.
Module 6 – Observabilité &amp; Monitoring
Logs &amp; métriques
 Logs client Kafka.
 Latency, throughput, consumer lag.
Traçage distribué
 Propagation des contextes.
 Corrélation des événements.
Atelier pratique
 Visualisation du consumer lag.
 Mise en place de métriques via JMX.
Population
Confirmé Senior .Net Core
Micro services  (1 ou plusieurs)
Monlitiques vers micro services API
Skilled 
Sans aucune info sur Kafka
Envionnement
OpenShift
C# .Net  CoreEntity FrameworkOpenShiftTroublesihts of logs
Messaging (MQ)
Concepts Event Based applications
Micro services API/ Monolithiques vers Micro services.
Cartographies architectures 
Event Based applications
Architectures Simples/
Change Data Capture(concepts/Réalisation) Data Rentention
Uses Cases
IDE/ VS code/ Visual Studio 2022/ Github Copilot
Postgress Kafka Connect/SQL Server
 



