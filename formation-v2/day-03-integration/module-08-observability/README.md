# ğŸ“Š Module 08 - ObservabilitÃ© & Monitoring

| DurÃ©e | Niveau | PrÃ©requis |
|-------|--------|-----------|
| 2 heures | IntermÃ©diaire | Modules 01-07 complÃ©tÃ©s |

## ğŸ¯ Objectifs d'apprentissage

Ã€ la fin de ce module, vous serez capable de :

- âœ… Collecter les mÃ©triques Kafka via JMX
- âœ… Monitorer le consumer lag
- âœ… Configurer des alertes
- âœ… Mettre en place le tracing distribuÃ©

---

## ğŸ“š Partie ThÃ©orique (30%)

### 1. MÃ©triques clÃ©s Kafka

```mermaid
flowchart TB
    subgraph broker["ğŸ–¥ï¸ BROKER METRICS"]
        B1["UnderReplicatedPartitions"]
        B2["OfflinePartitionsCount"]
        B3["BytesIn/OutPerSec"]
    end
    
    subgraph producer["ğŸ“¤ PRODUCER METRICS"]
        P1["record-send-rate"]
        P2["record-error-rate"]
        P3["request-latency-avg"]
    end
    
    subgraph consumer["ğŸ“¥ CONSUMER METRICS"]
        C1["records-consumed-rate"]
        C2["ğŸ”¥ records-lag (LAG)"]
        C3["fetch-latency-avg"]
    end
    
    style consumer fill:#ffcccc
    style C2 fill:#ff6b6b,color:#fff
```

---

### 2. Consumer Lag - La mÃ©trique critique

```mermaid
flowchart LR
    subgraph topic["Topic: orders (partition 0)"]
        direction LR
        O0["â–ˆ 0"] --> O1["â–ˆ 1"] --> O2["â–ˆ 2"] --> O3["â–ˆ 3"] --> O4["â–ˆ 4"] --> O5["â–ˆ 5"] --> O6["â–ˆ 6"] --> O7["â–ˆ 7"] --> O8["â–ˆ 8"]
        O8 -.-> O9["â–‘ 9"] -.-> O10["â–‘ 10"] -.-> O11["â–‘ 11"] -.-> O12["â–‘ 12"]
    end
    
    CO["Consumer Offset<br/>(8)"] --> O8
    LEO["Log End Offset<br/>(12)"] --> O12
    
    style O9 fill:#ffcccc
    style O10 fill:#ffcccc
    style O11 fill:#ffcccc
    style O12 fill:#ffcccc
```

> **LAG = Log End Offset - Consumer Committed Offset = 4**

| LAG | Status |
|-----|--------|
| **= 0** | âœ… Parfait, consumer Ã  jour |
| **< 100** | ğŸŸ¡ Normal, lÃ©gÃ¨re latence |
| **> 1000** | âš ï¸ Attention, consumer lent |
| **croissant** | ğŸ”¥ ALERTE, consumer ne suit pas |

#### Causes du lag Ã©levÃ©

| Cause | SymptÃ´me | Solution |
|-------|----------|----------|
| Consumer lent | Lag croissant constant | Optimiser le traitement |
| Pas assez de consumers | Lag sur toutes partitions | Ajouter des consumers |
| Rebalancing frÃ©quent | Pics de lag | Optimiser session.timeout |
| GC pauses | Lag intermittent | Tuner la JVM |

---

### 3. Architecture de monitoring

```mermaid
flowchart LR
    subgraph sources["Sources"]
        K["ğŸ–¥ï¸ Kafka Brokers"]
        A["ğŸ“¦ Apps (Producer/Consumer)"]
    end
    
    subgraph export["Export"]
        JMX["ğŸ”Œ JMX Exporter"]
        MIC["ğŸ“Š Micrometer/Actuator"]
    end
    
    subgraph monitoring["Monitoring"]
        PROM[("ğŸ“ˆ Prometheus")]
        GRAF["ğŸ“Š Grafana Dashboards"]
        ALERT["ğŸš¨ Alerting<br/>(Slack, PagerDuty)"]
    end
    
    K --> JMX --> PROM
    A --> MIC --> PROM
    PROM --> GRAF --> ALERT
    
    style PROM fill:#e8f5e9
    style GRAF fill:#e3f2fd
    style ALERT fill:#ffcccc
```

---

### 4. Tracing distribuÃ©

```mermaid
flowchart LR
    subgraph svcA["Service A"]
        SA["Span 1<br/>TraceID: abc"]
    end
    
    subgraph kafka["Kafka"]
        KT["Topic<br/>Headers: abc"]
    end
    
    subgraph svcB["Service B"]
        SB["Span 2<br/>TraceID: abc"]
    end
    
    SA -->|"ğŸ“¨ Produce"| KT -->|"ğŸ“¥ Consume"| SB
    
    style SA fill:#e8f5e9
    style KT fill:#fff3cd
    style SB fill:#e3f2fd
```

**Headers Kafka transportent le contexte de trace:**
```
traceparent: 00-abc123-def456-01
tracestate: vendor=value
```

---

## ğŸ”Œ Ports et Services

| Service | Port | Description |
|---------|------|-------------|
| Prometheus | 9090 | MÃ©triques |
| Grafana | 3000 | Dashboards |
| JMX Exporter | 9404 | Export mÃ©triques Kafka |
| Jaeger | 16686 | Tracing UI |

---

## ğŸ› ï¸ Partie Pratique (70%)

### PrÃ©requis

```bash
cd formation-v2/
./scripts/up.sh
```

---

### Ã‰tape 1 - DÃ©marrer le stack de monitoring

```bash
docker compose -f day-03-integration/module-08-observability/docker-compose.module.yml up -d
```

**VÃ©rification** :

```bash
# Prometheus
curl -s http://localhost:9090/-/healthy

# Grafana
curl -s http://localhost:3000/api/health
```

---

### Ã‰tape 2 - Lab 1 : Explorer les mÃ©triques Kafka

#### 2.1 Via Kafka CLI

```bash
# Consumer lag pour un groupe
docker exec kafka kafka-consumer-groups \
  --describe \
  --group orders-consumer-group \
  --bootstrap-server localhost:9092
```

**RÃ©sultat attendu** :

```
GROUP                TOPIC      PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
orders-consumer-group orders    0          100             105             5
orders-consumer-group orders    1          200             200             0
```

#### 2.2 Via JMX

```bash
# Lister les MBeans Kafka
docker exec kafka kafka-run-class kafka.tools.JmxTool \
  --jmx-url service:jmx:rmi:///jndi/rmi://localhost:9999/jmxrmi \
  --object-name 'kafka.server:type=BrokerTopicMetrics,name=*'
```

---

### Ã‰tape 3 - Lab 2 : Configurer Prometheus

#### 3.1 VÃ©rifier les targets

Ouvrez http://localhost:9090/targets

**Targets attendus** :
- `kafka-jmx-exporter` : UP
- `kafka-ui` : UP (si configurÃ©)

#### 3.2 ExÃ©cuter des requÃªtes PromQL

```promql
# Messages produits par seconde
rate(kafka_server_brokertopicmetrics_messagesin_total[5m])

# Consumer lag
kafka_consumer_consumer_fetch_manager_metrics_records_lag

# Bytes in/out
rate(kafka_server_brokertopicmetrics_bytesin_total[5m])
```

---

### Ã‰tape 4 - Lab 3 : Dashboard Grafana

#### 4.1 AccÃ©der Ã  Grafana

1. Ouvrez http://localhost:3000
2. Login: `admin` / `admin`
3. Changez le mot de passe si demandÃ©

#### 4.2 Importer un dashboard

1. Cliquez sur **+** â†’ **Import**
2. Entrez l'ID du dashboard Kafka : `7589`
3. SÃ©lectionnez la datasource Prometheus
4. Cliquez sur **Import**

#### 4.3 Explorer les mÃ©triques

- **Throughput** : Messages/sec, Bytes/sec
- **Latency** : Request latency percentiles
- **Consumer Lag** : Par topic et partition
- **Resources** : CPU, Memory, Disk

---

### Ã‰tape 5 - Lab 4 : Simuler du lag et observer

#### 5.1 CrÃ©er du lag artificiellement

```bash
# Produire beaucoup de messages
for i in {1..1000}; do
  echo "message-$i" | docker exec -i kafka kafka-console-producer \
    --topic test-lag \
    --bootstrap-server localhost:9092
done
```

#### 5.2 Observer le lag dans Grafana

1. Allez sur le dashboard Kafka
2. Trouvez le panel "Consumer Lag"
3. Observez le lag augmenter puis diminuer quand le consumer rattrape

---

### Ã‰tape 6 - Lab 5 : Configurer une alerte

#### 6.1 CrÃ©er une rÃ¨gle d'alerte dans Grafana

1. Allez dans **Alerting** â†’ **Alert rules**
2. Cliquez sur **New alert rule**
3. Configurez :
   - **Name** : High Consumer Lag
   - **Query** : `kafka_consumergroup_lag > 1000`
   - **Condition** : Is above 1000
   - **Evaluation** : Every 1m for 5m
4. Sauvegardez

#### 6.2 Tester l'alerte

Reproduisez du lag et vÃ©rifiez que l'alerte se dÃ©clenche.

---

## âœ… Checkpoint de validation

- [ ] Stack de monitoring dÃ©marrÃ©
- [ ] MÃ©triques Kafka visibles dans Prometheus
- [ ] Dashboard Grafana importÃ© et fonctionnel
- [ ] Consumer lag visible et compris
- [ ] Alerte configurÃ©e et testÃ©e

---

## ğŸ”§ Troubleshooting

### Prometheus ne collecte pas les mÃ©triques

```bash
# VÃ©rifier JMX Exporter
curl -s http://localhost:9404/metrics | head -20
```

### Grafana ne montre pas de donnÃ©es

1. VÃ©rifiez la datasource Prometheus
2. Testez une requÃªte simple : `up`
3. VÃ©rifiez les time ranges

---

## ğŸ§¹ Nettoyage

```bash
docker compose -f day-03-integration/module-08-observability/docker-compose.module.yml down -v
```

---

## ğŸ“– Pour aller plus loin

### Exercices supplÃ©mentaires

1. **Configurez des alertes Slack** via Grafana
2. **Ajoutez le tracing** avec Jaeger
3. **CrÃ©ez un dashboard custom** pour votre application

### Ressources

- [Kafka Monitoring Documentation](https://kafka.apache.org/documentation/#monitoring)
- [Prometheus + Kafka](https://prometheus.io/docs/instrumenting/exporters/)
- [Grafana Kafka Dashboards](https://grafana.com/grafana/dashboards/)
