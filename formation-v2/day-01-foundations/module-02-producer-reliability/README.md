# Module 02 - FiabilitÃ© du Producteur Kafka (Idempotence) - Formation Auto-rythmÃ©e

## ğŸ¯ Objectifs PÃ©dagogiques Complets

Ce module vous offre une **formation acadÃ©mique complÃ¨te** allant de la thÃ©orie fondamentale Ã  la pratique avancÃ©e, en passant par le dÃ©veloppement pas Ã  pas et le dÃ©ploiement production.

### ğŸ“š Parcours d'Apprentissage StructurÃ©

```mermaid
flowchart TB
    subgraph THEORY["ğŸ“š Phase 1: Fondements ThÃ©oriques"]
        T1["ğŸ“– Concepts Kafka de Base"]
        T2["ğŸ§® Architecture Producer"]
        T3["ğŸ” Idempotence & FiabilitÃ©"]
        T4["ğŸ“Š ACK Levels"]
        T5["âš¡ Performance"]
    end
    
    subgraph DEVELOP["ğŸ’» Phase 2: DÃ©veloppement .NET"]
        D1["ğŸ“ Tutoriel Complet"]
        D2["Code IncrÃ©mental"]
        D3["Patterns AvancÃ©s"]
        D4["Tests Unitaires"]
        D5["Debugging"]
    end
    
    subgraph PRACTICE["ğŸ§ª Phase 3: Pratique & Tests"]
        P1["Tests Locaux"]
        P2["Validation Kafka"]
        P3["Tests de Charge"]
        P4["Injection Pannes"]
        P5["Monitoring"]
    end
    
    subgraph DEPLOY["ğŸš€ Phase 4: DÃ©ploiement"]
        D1["ğŸ³ Docker"]
        D2["â˜¸ï¸ Kubernetes"]
        D3["CI/CD"]
        D4["Production"]
        D5["Monitoring"]
    end
    
    THEORY --> DEVELOP --> PRACTICE --> DEPLOY
    
    style THEORY fill:#e3f2fd
    style DEVELOP fill:#f3e5f5
    style PRACTICE fill:#e8f5e8
    style DEPLOY fill:#fff3e0
```

### ğŸ¯ Objectifs SpÃ©cifiques

Ã€ la fin de ce module, vous serez capable de :

1. âœ… **MaÃ®triser les concepts thÃ©oriques** du Producer Kafka
2. âœ… **DÃ©velopper** un Producer .NET fiable avec idempotence
3. âœ… **Comprendre** les patterns de fiabilitÃ© distribuÃ©e
4. âœ… **Tester** et dÃ©boguer les messages Kafka
5. **DÃ©ployer** en production avec Docker et Kubernetes
6. **Monitorer** et optimiser les performances

---

## ğŸ“– Partie ThÃ©orique Approfondie

### 1. Le Producteur Kafka en dÃ©tail

#### 1.1 Cycle de vie d'un message

```mermaid
sequenceDiagram
    participant App as Application
    participant Prod as Producer
    participant Ser as Serializer
    participant Part as Partitioner
    participant Batch as RecordAccumulator
    participant Net as NetworkClient
    participant Broker as Kafka Broker
    
    App->>Prod: send(record)
    Prod->>Ser: serialize(key, value)
    Ser-->>Prod: byte[]
    Prod->>Part: partition(topic, key)
    Part-->>Prod: partition number
    Prod->>Batch: append to batch
    Note over Batch: Attend linger.ms ou batch.size
    Batch->>Net: send batch
    Net->>Broker: ProduceRequest
    Broker->>Broker: Write to log
    Broker->>Broker: Replicate
    Broker-->>Net: ProduceResponse (offset)
    Net-->>Prod: RecordMetadata
    Prod-->>App: Future/Callback
```

#### 1.2 Composants internes du Producer

```mermaid
flowchart TB
    subgraph Producer["ğŸ“¤ Kafka Producer"]
        subgraph Config["Configuration"]
            BS["batch.size<br/>16KB"]
            LI["linger.ms<br/>0ms"]
            AC["acks<br/>all"]
            RE["retries<br/>âˆ"]
        end
        
        subgraph Pipeline["Pipeline d'envoi"]
            SER["ğŸ”„ Serializer<br/>Key + Value"]
            PAR["ğŸ“Š Partitioner<br/>Round-robin / Hash"]
            ACC["ğŸ“¦ RecordAccumulator<br/>Batching"]
            SND["ğŸŒ Sender Thread<br/>Network I/O"]
        end
        
        SER --> PAR --> ACC --> SND
    end
    
    SND -->|"ProduceRequest"| K["ğŸ“¦ Kafka Broker"]
    K -->|"ACK"| SND
```

#### 1.3 Points ClÃ©s de Performance

| Composant | Impact | Configuration | Tips |
|-----------|---------|-------------|------|
| **Batch Size** | Throughput | `batch.size=16KB` | Augmenter pour haute charge |
| **Linger** | Latence | `linger.ms=5-10` | Compromis latence/dÃ©bit |
| **Compression** | RÃ©seau | `compression.type=snappy` | RÃ©duit bande passante |
| **Buffer Pool** | MÃ©moire | `buffer.memory=32MB` | Ã‰vite allocations |

---

### 2. Les Acknowledgments (ACKs)

#### 2.1 Niveaux d'ACK et SÃ©mantique

```mermaid
flowchart TB
    subgraph acks0["acks=0 (Fire & Forget)"]
        P0["Producer"] -->|"Envoie"| B0["Broker"]
        P0 -.->|"N'attend pas"| X0["âŒ"]
    end
    
    subgraph acks1["acks=1 (Leader Only)"]
        P1["Producer"] -->|"Envoie"| L1["Leader"]
        L1 -->|"ACK"| P1
        L1 -.->|"RÃ©plique aprÃ¨s"| F1["Follower"]
    end
    
    subgraph acksAll["acks=all (Toutes les ISR)"]
        P2["Producer"] -->|"Envoie"| L2["Leader"]
        L2 -->|"RÃ©plique"| F2["Follower 1"]
        L2 -->|"RÃ©plique"| F3["Follower 2"]
        F2 -->|"ACK"| L2
        F3 -->|"ACK"| L2
        L2 -->|"ACK"| P2
    end
    
    style acks0 fill:#ffebee
    style acks1 fill:#fff3e0
    style acksAll fill:#e8f5e8
```

#### 2.2 Trade-offs Performance vs FiabilitÃ©

| ACK Level | Latence | FiabilitÃ© | Cas d'usage | Risques |
|-----------|----------|-----------|-------------|--------|
| **acks=0** | âš¡ Minimal | âŒ Aucune | Logs, mÃ©triques | Perte de donnÃ©es |
| **acks=1** | âš¡ Faible | âš ï¸ Moyenne | DonnÃ©es non critiques | Perte en cas de crash leader |
| **acks=all** | ğŸ¥ Ã‰levÃ©e | âœ… Maximale | Transactions critiques | Performance rÃ©duite |

#### 2.3 Impact sur le Producteur

```yaml
# Configuration selon niveau de fiabilitÃ© souhaitÃ©
producer:
  enable.idempotence: true  # Requis pour exactly-once
  acks: all              # Requis pour exactly-once
  max.in.flight.requests: 5  # Requis pour idempotence
  retries: INT_MAX
  delivery.timeout.ms: 120000
  request.timeout.ms: 30000
```

---

### 3. Idempotence : Garantie d'Exact-Once

#### 3.1 Principe MathÃ©matique

```
f(f(x)) = f(x)
```

#### 3.2 ImplÃ©mentation dans Kafka

```mermaid
sequenceDiagram
    participant P as Producer
    participant K as Kafka Broker
    participant R as Replica
    
    Note over P: Envoi Message (PID:123, Seq:1)
    P->>K: Envoi Message (PID:123, Seq:1)
    K->>R: Replication
    R-->>K: ACK
    
    Note over P: Timeout ! RÃ©essai
    P->>K: Envoi Message (PID:123, Seq:1)
    K->>K: DÃ©tection duplicata
    K-->>P: ACK (sans duplication)
```

#### 3.3 MÃ©canismes Techniques

| MÃ©canisme | RÃ´le | Configuration .NET |
|-----------|------|----------------------|
| **Producer ID (PID)** | Identifiant unique du producer | `EnableIdempotence = true` |
| **Sequence Number** | Ordre des messages par partition | GÃ©rÃ© automatiquement |
| **Deduplication Buffer** | Cache des messages envoyÃ©s | CÃ´tÃ© broker |
| **Max In Flight** | Limite requÃªtes simultanÃ©es | `max.in.flight.requests = 5` |

#### 3.4 Configuration .NET pour Idempotence

```csharp
var config = new ProducerConfig
{
    // ğŸ”‘ Activation de l'idempotence
    EnableIdempotence = true,
    
    // ğŸ“¡ Confirmation maximale
    Acks = Acks.All,
    
    // ğŸš¦ ContrÃ´le du pipeline
    MaxInFlight = 5,
    
    // â±ï¸ Timeouts et retries
    RequestTimeoutMs = 1000,
    MessageTimeoutMs = 120000,
    MessageSendMaxRetries = 10,
    RetryBackoffMs = 100
};
```

---

### 4. Patterns de FiabilitÃ© DistribuÃ©e

#### 4.1 Retry Pattern

```mermaid
stateDiagram-v2
    [*] --> Send
    Send --> Success: ACK reÃ§u
    Send --> Retry: Timeout/Network Error
    Retry --> Send: Backoff exponentiel
    Retry --> Failed: Max retries atteint
    Success --> [*]
    Failed --> [*]
    
    note right of Retry
        RetryBackoffMs = 100ms
        MessageSendMaxRetries = 10
        Exponential backoff optionnel
    end note
```

#### 4.2 Circuit Breaker Pattern

```csharp
public class CircuitBreakerProducer
{
    private int _failureCount = 0;
    private DateTime _lastFailure = DateTime.MinValue;
    private readonly int _threshold = 5;
    private readonly TimeSpan _timeout = TimeSpan.FromMinutes(1);
    
    public async Task<DeliveryResult<string, string>> SendAsync(
        IProducer<string, string> producer, 
        Message<string, string> message)
    {
        if (IsCircuitOpen())
            throw new InvalidOperationException("Circuit breaker is open");
            
        try
        {
            var result = await producer.ProduceAsync(message);
            ResetCircuit();
            return result;
        }
        catch (Exception ex)
        {
            RecordFailure();
            throw;
        }
    }
}
```

---

### 5. Performance et Optimisation

#### 5.1 Mesures ClÃ©s

| MÃ©trique | Objectif | Cible | Optimisation |
|----------|---------|------|---------------|
| **Throughput** | Messages/seconde | `producer.send()` | `batch.size`, `linger.ms` |
| **Latence** | Temps de rÃ©ponse | `delivery.timeout.ms` | `request.timeout.ms` |
| **Perte** | Messages perdus | `acks` level | `retries` configuration |
| **MÃ©moire** | Utilisation heap | `buffer.memory` | `buffer.pool.max.size` |

#### 5.2 Optimisations AvancÃ©es

```csharp
// Optimisation haute performance
var config = new ProducerConfig
{
    // ğŸš€ Batch size pour haute charge
    BatchSize = 32768,
    
    // âš¡ Linger pour batching
    LingerMs = 5,
    
    // ğŸ—œï¸ Compression
    CompressionType = CompressionType.Snappy,
    
    // ğŸ“Š Buffer pool
    BufferMemory = 67108864, // 64MB
    
    // ğŸ”§ Socket buffer
    SocketSendBufferSizeBytes = 102400,
    ReceiveBufferSizeBytes = 102400
};
```

#### Comparaison des modes ACK

| Mode | DurabilitÃ© | Performance | Risque de perte |
|------|------------|-------------|-----------------|
| `acks=0` | âŒ Aucune | âš¡âš¡âš¡ Maximale | Ã‰levÃ© |
| `acks=1` | âš ï¸ Partielle | âš¡âš¡ Bonne | Moyen |
| `acks=all` | âœ… ComplÃ¨te | âš¡ ModÃ©rÃ©e | Minimal |

---

### 3. L'Idempotence en profondeur

#### Le problÃ¨me des doublons

```mermaid
sequenceDiagram
    participant P as Producer
    participant B as Broker
    
    P->>B: Message "order-123"
    B->>B: Write OK
    B--xP: ACK perdu (rÃ©seau)
    Note over P: Timeout â†’ Retry
    P->>B: Message "order-123" (retry)
    B->>B: Write OK (DOUBLON !)
    B-->>P: ACK
    
    Note over B: âŒ 2 messages identiques
```

#### Solution : Producer Idempotent

```mermaid
sequenceDiagram
    participant P as Producer (PID=42)
    participant B as Broker
    
    P->>B: Message "order-123" (seq=0)
    B->>B: Write OK, store seq=0
    B--xP: ACK perdu
    Note over P: Timeout â†’ Retry
    P->>B: Message "order-123" (seq=0, retry)
    B->>B: Check: seq=0 dÃ©jÃ  vu â†’ SKIP
    B-->>P: ACK (avec offset original)
    
    Note over B: âœ… 1 seul message
```

#### MÃ©canisme interne

| Concept | Description |
|---------|-------------|
| **PID** (Producer ID) | Identifiant unique du producer (assignÃ© au dÃ©marrage) |
| **Epoch** | Version du producer (incrÃ©mentÃ© si redÃ©marrage) |
| **Sequence Number** | NumÃ©ro sÃ©quentiel par partition (0, 1, 2, ...) |

```
Message format avec idempotence:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PID: 42 â”‚ Epoch: 0 â”‚ SeqNum: 5 â”‚ Partition: 0  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Payload                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4. Retries et Gestion des erreurs

#### Timeline des retries

```mermaid
gantt
    title ScÃ©nario de retry avec succÃ¨s
    dateFormat X
    axisFormat %s
    
    section Request 1
    Envoi initial        :a1, 0, 1
    Attente ACK         :a2, 1, 2
    Timeout             :crit, a3, 2, 3
    
    section Retry 1
    Backoff (100ms)     :b1, 3, 4
    Retry               :b2, 4, 5
    Attente ACK         :b3, 5, 6
    Timeout             :crit, b4, 6, 7
    
    section Retry 2
    Backoff (200ms)     :c1, 7, 9
    Retry               :c2, 9, 10
    ACK reÃ§u            :done, c3, 10, 11
```

#### ParamÃ¨tres de retry

```mermaid
flowchart LR
    subgraph Timeouts["â±ï¸ Timeouts"]
        RT["request.timeout.ms<br/>30s"]
        DT["delivery.timeout.ms<br/>120s"]
    end
    
    subgraph Retries["ğŸ”„ Retries"]
        R["retries<br/>2147483647"]
        RB["retry.backoff.ms<br/>100ms"]
    end
    
    subgraph Constraint["âš ï¸ Contrainte"]
        C["delivery.timeout.ms â‰¥<br/>request.timeout.ms +<br/>linger.ms"]
    end
```

#### Erreurs rÃ©cupÃ©rables vs non-rÃ©cupÃ©rables

| Type | Exemples | Action |
|------|----------|--------|
| **RÃ©cupÃ©rable** | NetworkException, LeaderNotAvailable | Retry automatique |
| **Non-rÃ©cupÃ©rable** | InvalidTopicException, AuthorizationException | Ã‰chec immÃ©diat |
| **Fatal** | ProducerFenced, OutOfMemory | ArrÃªt du producer |

---

### 5. Synchrone vs Asynchrone

#### Mode Synchrone

```mermaid
sequenceDiagram
    participant C as Client HTTP
    participant A as API
    participant P as Producer
    participant K as Kafka
    
    C->>A: POST /send (sync)
    A->>P: send()
    P->>K: ProduceRequest
    K-->>P: ProduceResponse
    P-->>A: RecordMetadata
    A-->>C: 200 OK + offset
    
    Note over C,A: â±ï¸ Client bloquÃ© pendant l'envoi
```

#### Mode Asynchrone

```mermaid
sequenceDiagram
    participant C as Client HTTP
    participant A as API
    participant P as Producer
    participant K as Kafka
    participant S as StatusStore
    
    C->>A: POST /send (async)
    A->>P: send() + callback
    A->>S: Store requestId=PENDING
    A-->>C: 202 Accepted + requestId
    
    Note over C: Client libÃ©rÃ© immÃ©diatement
    
    P->>K: ProduceRequest
    K-->>P: ProduceResponse
    P->>S: Update requestId=OK
    
    C->>A: GET /status?requestId=...
    A->>S: Get status
    A-->>C: 200 OK + offset
```

#### Comparaison

| Aspect | Synchrone | Asynchrone |
|--------|-----------|------------|
| **Latence perÃ§ue** | Haute | Basse |
| **ComplexitÃ©** | Simple | Plus complexe |
| **Gestion d'erreur** | ImmÃ©diate | DiffÃ©rÃ©e (polling) |
| **DÃ©bit** | LimitÃ© | Ã‰levÃ© |
| **Cas d'usage** | APIs critiques | Haute performance |

---

### 6. Partitionnement et ClÃ©s

#### StratÃ©gies de partitionnement

```mermaid
flowchart TB
    subgraph NoKey["Sans clÃ© (Round-Robin)"]
        M1["Msg 1"] --> P0a["Partition 0"]
        M2["Msg 2"] --> P1a["Partition 1"]
        M3["Msg 3"] --> P2a["Partition 2"]
        M4["Msg 4"] --> P0a
    end
    
    subgraph WithKey["Avec clÃ© (Hash)"]
        K1["key=A"] --> Hash1["hash('A') % 3 = 1"]
        K2["key=B"] --> Hash2["hash('B') % 3 = 0"]
        K3["key=A"] --> Hash3["hash('A') % 3 = 1"]
        
        Hash1 --> P1b["Partition 1"]
        Hash2 --> P0b["Partition 0"]
        Hash3 --> P1b
    end
    
    style NoKey fill:#fff3e0
    style WithKey fill:#e8f5e9
```

#### Garantie d'ordre avec les clÃ©s

```
Topic: orders (3 partitions)

key="customer-42":
  Partition 1: [order-1] â†’ [order-2] â†’ [order-3] âœ… Ordre garanti

key="customer-99":
  Partition 0: [order-A] â†’ [order-B] â†’ [order-C] âœ… Ordre garanti

âš ï¸ Pas d'ordre garanti ENTRE les partitions
```

---

### 7. Log Compaction

#### Principe

```mermaid
flowchart LR
    subgraph Before["Avant Compaction"]
        B1["k1:v1"]
        B2["k2:v1"]
        B3["k1:v2"]
        B4["k3:v1"]
        B5["k1:v3"]
        B6["k2:v2"]
    end
    
    Compact["ğŸ”„ Compaction"]
    
    subgraph After["AprÃ¨s Compaction"]
        A1["k3:v1"]
        A2["k1:v3"]
        A3["k2:v2"]
    end
    
    Before --> Compact --> After
```

#### Cas d'usage

| ScÃ©nario | Exemple | ClÃ© | Valeur |
|----------|---------|-----|--------|
| **Ã‰tat utilisateur** | Profil client | userId | JSON profil |
| **Position GPS** | Flotte vÃ©hicules | vehicleId | lat/long |
| **Configuration** | Feature flags | featureName | enabled/disabled |
| **Inventaire** | Stock produits | productId | quantitÃ© |

---

### 8. Toxiproxy : Simulation de pannes

#### Architecture avec Toxiproxy

```mermaid
flowchart LR
    subgraph Normal["Mode Normal"]
        A1["API"] -->|"29092"| K1["Kafka"]
    end
    
    subgraph Proxy["Mode Proxy"]
        A2["API"] -->|"29093"| T["ğŸ’€ Toxiproxy"]
        T -->|"29092"| K2["Kafka"]
        
        subgraph Toxics["Effets injectables"]
            L["â±ï¸ Latency"]
            TO["â¹ï¸ Timeout"]
            BW["ğŸ“‰ Bandwidth"]
            SL["ğŸ”€ Slicer"]
        end
    end
    
    style T fill:#fff3e0
```

#### Types de pannes simulables

| Toxic | Effet | ParamÃ¨tres |
|-------|-------|------------|
| **latency** | Ajoute un dÃ©lai | `latency`, `jitter` |
| **timeout** | Coupe la connexion aprÃ¨s N ms | `timeout` |
| **bandwidth** | Limite le dÃ©bit | `rate` (KB/s) |
| **slicer** | Fragmente les paquets | `average_size`, `delay` |
| **slow_close** | Fermeture lente | `delay` |

```json
// Exemple : ajouter 5 secondes de latence
{
  "name": "latency",
  "type": "latency",
  "stream": "downstream",
  "attributes": {
    "latency": 5000,
    "jitter": 500
  }
}
```

---

## ğŸ—ï¸ Architecture du module

```mermaid
flowchart TB
    subgraph Client["Votre Machine"]
        curl["ğŸ–¥ï¸ curl / Postman"]
    end
    
    subgraph Docker["Docker Environment"]
        Java["â˜• Java API<br/>Port: 18080"]
        DotNet["ğŸ”· .NET API<br/>Port: 18081"]
        Toxi["ğŸ’€ Toxiproxy<br/>Port: 8474<br/>(tests de pannes)"]
        K["ğŸ“¦ Kafka Broker<br/>Port: 29092"]
        UI["ğŸ“Š Kafka UI<br/>Port: 8080"]
    end
    
    curl --> Java
    curl --> DotNet
    Java -->|"kafka:29092"| K
    DotNet -->|"kafka:29092"| K
    Toxi -.->|"proxy disponible<br/>sur :29093"| K
    K --> UI
    
    style Toxi fill:#fff3e0
    style K fill:#e8f5e8
```

> **Note** : Les APIs se connectent directement Ã  Kafka. Toxiproxy est disponible sur le port 29093 pour les tests d'injection de pannes manuels.

---

## ğŸ”Œ Ports et endpoints

### Services

| Service | Port Docker | Port K8s | URL |
|---------|-------------|----------|-----|
| Java API | 18080 | 31080 | http://localhost:18080 (Docker) / http://localhost:31080 (K8s) |
| .NET API | 18081 | 31081 | http://localhost:18081 (Docker) / http://localhost:31081 (K8s) |
| Toxiproxy | 8474 | 31474 | http://localhost:8474 (Docker) / http://localhost:31474 (K8s) |
| Kafka UI | 8080 | 30808 | http://localhost:8080 (Docker) / http://localhost:30808 (K8s) |

### Endpoints des APIs

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/health` | Health check |
| POST | `/api/v1/send` | Envoyer un message |
| GET | `/api/v1/status` | Statut d'un envoi async |

### ParamÃ¨tres de `/api/v1/send`

| ParamÃ¨tre | Valeurs | Description |
|-----------|---------|-------------|
| `mode` | `plain`, `idempotent` | Mode du producer |
| `sendMode` | `sync`, `async` | Synchrone ou asynchrone |
| `eventId` | string | Identifiant unique du message |
| `key` | string (optionnel) | ClÃ© de partitionnement |
| `partition` | int (optionnel) | Partition cible |

---

## ğŸ“‹ PrÃ©-requis

### Logiciels

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

- âœ… Docker + Docker Compose
- âœ… curl (ligne de commande)
- âœ… Navigateur web

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

- âœ… Cluster Kubernetes (K3s, OKD, ou OpenShift)
- âœ… kubectl configurÃ©
- âœ… Strimzi Operator installÃ©
- âœ… curl (ligne de commande)

</details>

### Cluster Kafka dÃ©marrÃ©

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
cd formation-v2/
./scripts/up.sh   # Mode single-node par dÃ©faut
# ou: ./scripts/up.sh cluster   # Mode cluster 3 brokers
```

**VÃ©rification** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}' | grep kafka
```

**RÃ©sultat attendu** : `kafka` et `kafka-ui` sont `Up (healthy)`.

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# VÃ©rifier que le cluster Kafka est prÃªt
kubectl get kafka -n kafka

# RÃ©sultat attendu:
# NAME        DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   ...
# bhf-kafka   3                                              True    ...
```

**VÃ©rification des pods** :

```bash
kubectl get pods -n kafka -l strimzi.io/cluster=bhf-kafka
```

</details>

---

## ğŸ› ï¸ Phase de DÃ©veloppement .NET avec Kafka

### ğŸ¯ Objectif

Ce module est conÃ§u pour les **dÃ©veloppeurs .NET BHF** souhaitant maÃ®triser l'intÃ©gration Kafka dans leurs applications. Vous apprendrez Ã  dÃ©velopper un Producer Kafka fiable, puis Ã  le dÃ©ployer et tester dans des environnements Docker et Kubernetes.

> **Note** : Cette phase est **recommandÃ©e** pour comprendre en profondeur l'intÃ©gration Kafka. Si vous voulez simplement dÃ©ployer et tester, passez directement au [Lab 02.0](#-lab-020---dÃ©marrage-du-module).

### ğŸ“š Parcours d'Apprentissage IntÃ©grÃ©

**Ã‰tape 1 â†’ Ã‰tape 2 â†’ Ã‰tape 3 â†’ Ã‰tape 4 â†’ Ã‰tape 5**

```mermaid
flowchart TB
    subgraph DEV["ğŸ’» DÃ©veloppement .NET"]
        D1["ğŸ“– ThÃ©orie"]
        D2["ğŸ“ Tutoriel"]
        D3["ğŸ’» Code"]
        D4["ğŸ§ª Tests"]
    end
    subgraph BUILD["ğŸ³ Build"]
        B1["Dockerfile"]
        B2["Image"]
        B3["Scan SÃ©curitÃ©"]
    end
    
    subgraph DEPLOY["ğŸš€ DÃ©ploiement"]
        K1["Kubernetes"]
        K2["Services"]
        K3["Monitoring"]
    end
    
    DEV --> BUILD --> DEPLOY
    
    style DEV fill:#e3f2fd
    style BUILD fill:#f3e5f5
    style DEPLOY fill:#e8f5e8
```

---

### ğŸ¯ Focus .NET : Cycle de DÃ©veloppement avec Kafka

#### Ã‰tape 1 : PrÃ©requis .NET

| Outil | Version | Installation |
|-------|---------|--------------|
| **VS Code** | Latest | [code.visualstudio.com](https://code.visualstudio.com) |
| **.NET SDK** | 8.0+ | `winget install Microsoft.DotNet.SDK.8` |
| **Docker** | Latest | Pour Kafka et dÃ©ploiement |
| **kubectl** | Latest | Pour dÃ©ploiement K8s |

**Extensions VS Code pour .NET** :

```bash
code --install-extension ms-dotnettools.csharp
code --install-extension ms-dotnettools.csdevkit
code --install-extension humao.rest-client
```

#### Ã‰tape 2 : CrÃ©ation du Projet .NET Kafka

```bash
# CrÃ©er la structure du projet
mkdir dotnet && cd dotnet
dotnet new web -n M02ProducerReliability
cd M02ProducerReliability

# Ajouter Confluent.Kafka (client officiel)
dotnet add package Confluent.Kafka

# Ouvrir dans VS Code
code .
```

#### Ã‰tape 3 : DÃ©veloppement du Producer Kafka

**Tutoriel complet** : [`TUTORIAL-DOTNET.md`](./TUTORIAL-DOTNET.md)

Ce tutoriel vous guidera Ã  travers :

| Phase | Description | Focus Kafka | Temps |
|-------|-------------|-------------|-------|
| **Configuration** | `Program.cs` avec Confluent.Kafka | ProducerConfig, Acks, Idempotence | 20 min |
| **Endpoints** | API REST Minimal | Send, Status, Health | 15 min |
| **Modes Producer** | Plain vs Idempotent | `EnableIdempotence`, retries | 15 min |
| **Tests** | REST Client | Validation envoi synchrone/asynchrone | 10 min |
| **Dockerfile** | Multi-stage build | Optimisation pour production | 5 min |

**Concepts Kafka maÃ®trisÃ©s** :

```mermaid
flowchart LR
    DEV["ğŸ”· DÃ©veloppeur .NET"] --> KAFKA["ğŸ“¦ Kafka"]
    
    subgraph KAFKA_CONCEPTS["Concepts Kafka Appris"]
        P1["Producer Configuration"]
        P2["Acks (0/1/all)"]
        P3["Idempotence"]
        P4["Retries & Timeouts"]
        P5["Partitionnement"]
    end
    
    KAFKA --> KAFKA_CONCEPTS
```

#### Ã‰tape 4 : Build et Test Local

```bash
# Build et run local (dÃ©veloppement)
dotnet build
dotnet run

# Test des endpoints (dans un autre terminal)
curl http://localhost:8080/health

# Test envoi message
curl -X POST "http://localhost:8080/api/v1/send?mode=idempotent&eventId=TEST-001&sendMode=sync"
```

#### Ã‰tape 5 : Dockerisation

```bash
# Build image Docker
docker build -t m02-dotnet-api:latest -f Dockerfile .

# Test en Docker
docker run -p 8080:8080 -e KAFKA_BOOTSTRAP_SERVERS=kafka:29092 m02-dotnet-api:latest
```

---

### ğŸš€ Phase de DÃ©ploiement et Test

AprÃ¨s avoir dÃ©veloppÃ© votre API .NET Kafka, vous apprendrez Ã  :

#### 1. **DÃ©ploiement Docker**
- Docker Compose avec Kafka
- Variables d'environnement
- RÃ©seaux et ports

#### 2. **DÃ©ploiement Kubernetes**
- Manifestes YAML
- K3s containerd
- Services NodePort

#### 3. **Tests de FiabilitÃ©**
- Tests synchrones/asynchrones
- Injection de pannes avec Toxiproxy
- Validation idempotence

---

### ğŸ“Š Workflow .NET Complet

```mermaid
flowchart TB
    START["ğŸ¯ DÃ©veloppeur .NET BHF"]
    
    subgraph DEV["ğŸ› ï¸ DÃ©veloppement .NET + Kafka"]
        D1["ğŸ“¦ CrÃ©er projet .NET"]
        D2["âš™ï¸ Configurer Confluent.Kafka"]
        D3["ğŸ”· ImplÃ©menter Producer"]
        D4["ğŸ§ª Tests locaux"]
        D5["ğŸ³ Dockeriser"]
        
        D1 --> D2 --> D3 --> D4 --> D5
    end
    
    subgraph DEPLOY["ğŸš€ DÃ©ploiement & Tests"]
        L1["ğŸ“¦ Docker Compose"]
        L2["â˜¸ï¸ Kubernetes"]
        L3["ğŸ§ª Tests de fiabilitÃ©"]
        L4["ğŸ“Š Validation idempotence"]
        
        L1 --> L2 --> L3 --> L4
    end
    
    START --> DEV
    DEV --> DEPLOY
    
    style DEV fill:#e3f2fd
    style DEPLOY fill:#f3e5f5
```

---

### ğŸ“ CompÃ©tences .NET + Kafka Acquises

Ã€ la fin de ce module, vous maÃ®triserez :

| CompÃ©tence | Description | Application .NET |
|------------|-------------|-------------------|
| **Producer Kafka** | Configuration avancÃ©e | `ProducerConfig`, `EnableIdempotence` |
| **FiabilitÃ©** | Gestion des erreurs | Retries, timeouts, callbacks |
| **DÃ©ploiement** | Docker & K8s | Dockerfile, manifests YAML |
| **Monitoring** | Tests et validation | Health checks, logs |
| **Production** | Best practices | Idempotence, exactly-once |

---

### ğŸ“š Ressources .NET

| Ressource | Description | Lien |
|-----------|-------------|------|
| **Tutoriel complet** | Guide pas Ã  pas | [`TUTORIAL-DOTNET.md`](./TUTORIAL-DOTNET.md) |
| **Code source** | ImplÃ©mentation complÃ¨te | [`dotnet/`](./dotnet/) |
| **Confluent.Kafka** | Documentation officielle | [github.com/confluentinc/confluent-kafka-dotnet](https://github.com/confluentinc/confluent-kafka-dotnet) |
| **.NET 8** | Documentation Minimal API | [learn.microsoft.com/aspnet/core](https://learn.microsoft.com/aspnet/core) |

---

### ğŸ Alternative : API Java (RÃ©fÃ©rence)

Pour comparaison, une implÃ©mentation Java est disponible :
- **Tutoriel** : [`TUTORIAL-JAVA.md`](./TUTORIAL-JAVA.md)
- **Code** : [`java/`](./java/)

Cette version utilise Spring Boot et les mÃªmes concepts Kafka pour rÃ©fÃ©rence.

---

### ğŸ“ Structure du Projet .NET

```text
module-02-producer-reliability/
â”œâ”€â”€ dotnet/                        # ğŸ”· API .NET (FOCUS PRINCIPAL)
â”‚   â”œâ”€â”€ M02ProducerReliability/
â”‚   â”‚   â”œâ”€â”€ Program.cs             # Producer Kafka + API REST
â”‚   â”‚   â”œâ”€â”€ M02ProducerReliability.csproj
â”‚   â”‚   â””â”€â”€ Dockerfile             # Multi-stage build
â”‚   â””â”€â”€ requests.http              # Tests REST Client
â”œâ”€â”€ java/                          # ğŸ API Java (rÃ©fÃ©rence)
â”‚   â”œâ”€â”€ src/main/java/com/bhf/m02/
â”‚   â”‚   â”œâ”€â”€ M02ProducerReliabilityApplication.java
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ ProducerController.java
â”‚   â”‚   â”‚   â””â”€â”€ HealthController.java
â”‚   â”‚   â””â”€â”€ kafka/
â”‚   â”‚       â””â”€â”€ ProducerService.java
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ TUTORIAL-DOTNET.md            # ğŸ“– Guide .NET complet
â”œâ”€â”€ TUTORIAL-JAVA.md              # ğŸ“– Guide Java (rÃ©fÃ©rence)
â”œâ”€â”€ scripts/k8s/                  # â˜¸ï¸ Scripts K8s pour .NET
â”‚   â”œâ”€â”€ 00-full-deploy.sh          # Pipeline complet
â”‚   â”œâ”€â”€ 01-build-images.sh         # Build .NET image
â”‚   â”œâ”€â”€ 02-import-images.sh        # Import K3s
â”‚   â”œâ”€â”€ 03-deploy.sh               # Deploy manifests
â”‚   â”œâ”€â”€ 04-validate.sh             # Validation pods
â”‚   â”œâ”€â”€ 05-test-apis.sh            # Tests .NET APIs
â”‚   â””â”€â”€ README.md                  # Documentation K8s
â”œâ”€â”€ k8s/                          # â˜¸ï¸ Manifestes Kubernetes
â”‚   â”œâ”€â”€ m02-dotnet-api.yaml        # Deployment .NET
â”‚   â”œâ”€â”€ m02-java-api.yaml          # Deployment Java (rÃ©fÃ©rence)
â”‚   â”œâ”€â”€ toxiproxy.yaml            # Toxiproxy pour tests
â”‚   â””â”€â”€ toxiproxy-init.yaml       # Configuration proxy
â””â”€â”€ README.md                     # ğŸ“– Ce fichier
```

---

## ï¿½ï¿½ Lab 02.0 - DÃ©marrage du module

### Objectif

DÃ©marrer les services du module (APIs Java/.NET + Toxiproxy) et vÃ©rifier leur bon fonctionnement.

> **PrÃ©requis** : Si vous avez suivi la phase de dÃ©veloppement, assurez-vous que vos images Docker sont construites. Sinon, les images seront construites automatiquement lors du dÃ©ploiement.

---

### Ã‰tape 1 - Positionnement

**Objectif** : Se placer dans le bon rÃ©pertoire.

```bash
cd formation-v2/
```

---

### Ã‰tape 2 - DÃ©marrage des services

**Objectif** : Lancer les conteneurs du module.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Explication** : Cette commande lance :

- **Toxiproxy** : Proxy rÃ©seau pour injecter des pannes
- **toxiproxy-init** : Configuration initiale du proxy (one-shot)
- **m02-java-api** : API Spring Boot (Java)
- **m02-dotnet-api** : API ASP.NET (.NET)

**Commande** :

```bash
# Si le cluster Kafka est dÃ©jÃ  dÃ©marrÃ© via ./scripts/up.sh :
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml up -d --build
```

**â±ï¸ Temps d'attente** : 2-3 minutes (build des images Java/.NET).

**RÃ©sultat attendu** :

```text
[+] Running 4/4
 âœ” Container toxiproxy        Healthy
 âœ” Container toxiproxy-init   Started
 âœ” Container m02-java-api     Started
 âœ” Container m02-dotnet-api   Started
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Explication** : En mode K8s, les APIs sont dÃ©ployÃ©es comme des Deployments avec des Services NodePort. Les manifests YAML sont prÃ©-configurÃ©s dans le dossier `k8s/`.

#### Architecture K8s du Module

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Namespace: kafka                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Java API      â”‚  â”‚   .NET API      â”‚  â”‚  Toxiproxy  â”‚  â”‚
â”‚  â”‚   NodePort:     â”‚  â”‚   NodePort:     â”‚  â”‚  NodePort:  â”‚  â”‚
â”‚  â”‚   31080         â”‚  â”‚   31081         â”‚  â”‚  31474      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                    â”‚                   â”‚         â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                â”‚                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚                    â”‚   Kafka Bootstrap     â”‚                 â”‚
â”‚                    â”‚   bhf-kafka:9092      â”‚                 â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Option A : DÃ©ploiement automatisÃ© (RecommandÃ©)

Des scripts automatisÃ©s sont disponibles pour simplifier le dÃ©ploiement :

```bash
cd day-01-foundations/module-02-producer-reliability/scripts/k8s
chmod +x *.sh

# Pipeline complet (build + import + deploy + test)
sudo ./00-full-deploy.sh
```

**Ce script exÃ©cute automatiquement** :
1. Construction des images Docker
2. Import des images dans K3s containerd
3. DÃ©ploiement des manifests Kubernetes
4. Validation des pods et services
5. Tests des APIs

#### Option B : DÃ©ploiement manuel Ã©tape par Ã©tape

**Ã‰tape 2.1 - Construction des images Docker**

```bash
cd formation-v2/day-01-foundations/module-02-producer-reliability

# Build Java API
docker build -t m02-java-api:latest -f java/Dockerfile java/

# Build .NET API  
docker build -t m02-dotnet-api:latest -f dotnet/Dockerfile dotnet/

# VÃ©rifier les images
docker images | grep m02
```

**RÃ©sultat attendu** :

```text
m02-java-api      latest    xxxxx    xx seconds ago    438MB
m02-dotnet-api    latest    xxxxx    xx seconds ago    425MB
```

**Ã‰tape 2.2 - Import des images dans K3s**

> **Important** : K3s utilise **containerd** comme runtime, pas Docker. Les images doivent Ãªtre exportÃ©es puis importÃ©es dans containerd.

```bash
# Exporter les images Docker
sudo docker save m02-java-api:latest -o /tmp/m02-java-api.tar
sudo docker save m02-dotnet-api:latest -o /tmp/m02-dotnet-api.tar

# Importer dans K3s containerd
sudo k3s ctr images import /tmp/m02-java-api.tar
sudo k3s ctr images import /tmp/m02-dotnet-api.tar

# VÃ©rifier les images importÃ©es
sudo k3s ctr images list | grep m02
```

**RÃ©sultat attendu** :

```text
docker.io/library/m02-java-api:latest      application/vnd.oci.image.index.v1+json   sha256:xxx   119.5 MiB
docker.io/library/m02-dotnet-api:latest    application/vnd.oci.image.index.v1+json   sha256:xxx   115.4 MiB
```

**Ã‰tape 2.3 - DÃ©ploiement des manifests**

```bash
# DÃ©ployer tous les services
kubectl apply -f k8s/

# Ou dÃ©ployer individuellement :
kubectl apply -f k8s/toxiproxy.yaml
kubectl apply -f k8s/toxiproxy-init.yaml
kubectl apply -f k8s/m02-java-api.yaml
kubectl apply -f k8s/m02-dotnet-api.yaml
```

**RÃ©sultat attendu** :

```text
deployment.apps/toxiproxy created
service/toxiproxy created
job.batch/toxiproxy-init created
deployment.apps/m02-java-api created
service/m02-java-api created
deployment.apps/m02-dotnet-api created
service/m02-dotnet-api created
```

**Ã‰tape 2.4 - VÃ©rification des dÃ©ploiements**

```bash
# VÃ©rifier les pods
kubectl get pods -n kafka -l 'app in (toxiproxy,m02-java-api,m02-dotnet-api)'

# VÃ©rifier les services
kubectl get svc -n kafka | grep -E "m02|toxiproxy"
```

**RÃ©sultat attendu** :

```text
NAME                       READY   STATUS    RESTARTS   AGE
toxiproxy-xxxxx            1/1     Running   0          Xs
m02-java-api-xxxxx         1/1     Running   0          Xs
m02-dotnet-api-xxxxx       1/1     Running   0          Xs

NAME             TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                         AGE
m02-java-api     NodePort   10.x.x.x        <none>        8080:31080/TCP                  Xs
m02-dotnet-api   NodePort   10.x.x.x        <none>        8080:31081/TCP                  Xs
toxiproxy        NodePort   10.x.x.x        <none>        8474:31474/TCP,29093:32093/TCP  Xs
```

#### Tableau des ports K8s

| Service | Port interne | NodePort | Description |
| ------- | ------------ | -------- | ----------- |
| m02-java-api | 8080 | 31080 | API Java Spring Boot |
| m02-dotnet-api | 8080 | 31081 | API .NET ASP.NET |
| toxiproxy (API) | 8474 | 31474 | API de gestion Toxiproxy |
| toxiproxy (Proxy) | 29093 | 32093 | Proxy Kafka avec injection de latence |

#### DÃ©pannage K8s

**ProblÃ¨me : ImagePullBackOff**

```bash
# VÃ©rifier que les images sont dans containerd
sudo k3s ctr images list | grep m02

# Si absent, rÃ©importer
sudo ./scripts/k8s/02-import-images.sh
```

**ProblÃ¨me : Toxiproxy CrashLoopBackOff**

```bash
# VÃ©rifier les logs
kubectl logs -n kafka -l app=toxiproxy

# Le manifest utilise /version pour les health checks
# Si problÃ¨me persiste, redÃ©ployer
kubectl delete deployment toxiproxy -n kafka
kubectl apply -f k8s/toxiproxy.yaml
```

**ProblÃ¨me : API ne rÃ©pond pas**

```bash
# Tester depuis l'intÃ©rieur du cluster
kubectl run curl --rm -it --image=curlimages/curl:8.5.0 -n kafka -- \
  curl http://m02-java-api:8080/health
```

</details>

---

### Ã‰tape 3 - VÃ©rification des conteneurs

**Objectif** : S'assurer que tous les services sont opÃ©rationnels.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Commande** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'
```

**RÃ©sultat attendu** :

| Conteneur | Statut attendu |
|-----------|----------------|
| kafka | Up (healthy) |
| kafka-ui | Up (healthy) |
| toxiproxy | Up |
| toxiproxy-init | Exited (0) âœ… normal |
| m02-java-api | Up |
| m02-dotnet-api | Up |

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
kubectl get pods -n kafka
```

**RÃ©sultat attendu** :

| Pod | Statut attendu |
|-----|----------------|
| bhf-kafka-* | Running |
| m02-java-api-* | Running |
| m02-dotnet-api-* | Running (si dÃ©ployÃ©) |

</details>

---

### Ã‰tape 4 - Test de santÃ© des APIs

**Objectif** : VÃ©rifier que les APIs rÃ©pondent.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
# Test Java API
curl -fsS http://localhost:18080/health
# RÃ©sultat attendu: OK

# Test .NET API
curl -fsS http://localhost:18081/health
# RÃ©sultat attendu: OK
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# Test Java API (NodePort 31080)
curl -fsS http://localhost:31080/health
# RÃ©sultat attendu: OK

# Test .NET API (NodePort 31081)
curl -fsS http://localhost:31081/health
# RÃ©sultat attendu: OK

# Si localhost ne fonctionne pas, utilisez l'IP du node:
curl -fsS http://$(hostname -I | awk '{print $1}'):31080/health
```

</details>

**âœ… Checkpoint 02.0** : Les deux APIs rÃ©pondent `OK`.

---

## ğŸ“š Lab 02.1 - Envoi synchrone (baseline)

### Objectif

Envoyer un message en mode **synchrone** et comprendre la rÃ©ponse avec l'offset.

---

### Ã‰tape 5 - Envoi d'un message synchrone (Java API)

**Objectif** : Envoyer un message et recevoir l'ACK Kafka.

**ThÃ©orie** : En mode **synchrone**, l'API attend la confirmation de Kafka avant de rÃ©pondre. La rÃ©ponse contient :
- Le **topic** de destination
- La **partition** utilisÃ©e
- L'**offset** du message

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
# GÃ©nÃ©rer un ID unique
EVENT_ID="JAVA-SYNC-$(date +%s)"
echo "EventId: $EVENT_ID"

# Envoyer le message
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# GÃ©nÃ©rer un ID unique
EVENT_ID="JAVA-SYNC-$(date +%s)"
echo "EventId: $EVENT_ID"

# Envoyer le message (NodePort 31080)
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

**RÃ©sultat attendu** :

```json
{
  "status": "OK",
  "topic": "bhf-transactions",
  "partition": 0,
  "offset": 5,
  "eventId": "JAVA-SYNC-1706400000"
}
```

**Explication de la rÃ©ponse** :

| Champ | Description |
|-------|-------------|
| `status` | OK = message Ã©crit avec succÃ¨s |
| `topic` | Topic de destination |
| `partition` | Partition oÃ¹ le message est stockÃ© |
| `offset` | Position du message dans la partition |
| `eventId` | Identifiant unique envoyÃ© |

---

### Ã‰tape 6 - Envoi avec l'API .NET

**Objectif** : VÃ©rifier que l'API .NET fonctionne de la mÃªme maniÃ¨re.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
EVENT_ID="DOTNET-SYNC-$(date +%s)"
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
EVENT_ID="DOTNET-SYNC-$(date +%s)"
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

**âœ… Checkpoint 02.1** : Les deux APIs retournent un JSON avec `partition` et `offset`.

---

### Ã‰tape 7 - Visualisation dans Kafka UI

**Objectif** : Observer les messages envoyÃ©s.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Actions** :

1. Ouvrez **http://localhost:8080**
2. Cliquez sur le cluster **BHF-Training**
3. Menu **Topics** â†’ **bhf-transactions**
4. Onglet **Messages** â†’ **Fetch Messages**

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Via kubectl** :

```bash
# Consommer les messages directement
kubectl run kafka-consumer --rm -it --restart=Never \
  --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  -n kafka -- bin/kafka-console-consumer.sh \
  --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic bhf-transactions --from-beginning --max-messages 5
```

**Via Kafka UI (si dÃ©ployÃ©)** : AccÃ©dez via le NodePort ou Route configurÃ©.

</details>

**Ce que vous devez voir** :
- Vos messages avec les `eventId` envoyÃ©s
- La partition et l'offset de chaque message
- Le timestamp d'envoi

---

## ğŸ“š Lab 02.2 - Envoi asynchrone et callbacks

### Objectif

Comprendre le mode **asynchrone** et comment rÃ©cupÃ©rer le statut via polling.

---

### Ã‰tape 8 - Envoi asynchrone (Java)

**Objectif** : Envoyer un message sans attendre l'ACK.

**ThÃ©orie** : En mode **asynchrone** :
1. L'API retourne immÃ©diatement un `requestId`
2. Le message est envoyÃ© en arriÃ¨re-plan
3. Vous consultez le statut via `/api/v1/status`

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
EVENT_ID="JAVA-ASYNC-$(date +%s)"

# Envoyer en asynchrone
RESPONSE=$(curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=idempotent&sendMode=async&eventId=$EVENT_ID")
echo "RÃ©ponse: $RESPONSE"

# Extraire le requestId
REQ_ID=$(echo "$RESPONSE" | sed -n 's/.*"requestId":"\([^"]*\)".*/\1/p')
echo "RequestId: $REQ_ID"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
EVENT_ID="JAVA-ASYNC-$(date +%s)"

# Envoyer en asynchrone (NodePort 31080)
RESPONSE=$(curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=idempotent&sendMode=async&eventId=$EVENT_ID")
echo "RÃ©ponse: $RESPONSE"

# Extraire le requestId
REQ_ID=$(echo "$RESPONSE" | sed -n 's/.*"requestId":"\([^"]*\)".*/\1/p')
echo "RequestId: $REQ_ID"
```

</details>

**RÃ©sultat attendu** :

```json
{
  "status": "ACCEPTED",
  "requestId": "abc123-def456",
  "eventId": "JAVA-ASYNC-1706400000"
}
```

---

### Ã‰tape 9 - Consultation du statut

**Objectif** : RÃ©cupÃ©rer le rÃ©sultat de l'envoi asynchrone.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
# Attendre 2 secondes pour que l'envoi se termine
sleep 2

# Consulter le statut
curl -fsS "http://localhost:18080/api/v1/status?requestId=$REQ_ID"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# Attendre 2 secondes pour que l'envoi se termine
sleep 2

# Consulter le statut (NodePort 31080)
curl -fsS "http://localhost:31080/api/v1/status?requestId=$REQ_ID"
```

</details>

**RÃ©sultat attendu (succÃ¨s)** :

```json
{
  "state": "OK",
  "topic": "bhf-transactions",
  "partition": 1,
  "offset": 10
}
```

**RÃ©sultat possible (en cours)** :

```json
{
  "state": "PENDING"
}
```

**âœ… Checkpoint 02.2** : Vous savez envoyer en asynchrone et rÃ©cupÃ©rer le statut.

---

## ğŸ“š Lab 02.3 - Injection de pannes avec Toxiproxy

### Objectif

Simuler des problÃ¨mes rÃ©seau pour observer le comportement des retries.

---

### Ã‰tape 10 - VÃ©rification du proxy Toxiproxy

**Objectif** : Confirmer que le proxy Kafka est configurÃ©.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Commande** :

```bash
curl -fsS http://localhost:8474/proxies | python3 -m json.tool
```

**RÃ©sultat attendu** : Un proxy nommÃ© `kafka` avec :
- `listen`: `0.0.0.0:29093`
- `upstream`: `kafka:29092`

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
# Obtenir l'IP du node
NODE_IP=$(hostname -I | awk '{print $1}')

# VÃ©rifier la version de Toxiproxy
curl -fsS http://${NODE_IP}:31474/version

# Lister les proxies configurÃ©s
curl -fsS http://${NODE_IP}:31474/proxies | python3 -m json.tool
```

**RÃ©sultat attendu** :

```json
{
    "version": "2.9.0"
}
```

Et un proxy nommÃ© `kafka` avec :
- `listen`: `0.0.0.0:29093`
- `upstream`: `bhf-kafka-kafka-bootstrap:9092`

</details>

---

### Ã‰tape 11 - Injection de latence

**Objectif** : Ajouter 5 secondes de latence sur les rÃ©ponses Kafka.

**ThÃ©orie** : La latence peut provoquer des **timeouts** cÃ´tÃ© producer, ce qui dÃ©clenche des **retries**.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Commande pour ajouter la latence** :

```bash
curl -fsS -H 'Content-Type: application/json' \
  -X POST http://localhost:8474/proxies/kafka/toxics \
  -d '{
    "name": "latency",
    "type": "latency",
    "stream": "downstream",
    "attributes": {
      "latency": 5000,
      "jitter": 0
    }
  }'
```

**VÃ©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Commande pour ajouter la latence** :

```bash
NODE_IP=$(hostname -I | awk '{print $1}')

curl -fsS -H 'Content-Type: application/json' \
  -X POST http://${NODE_IP}:31474/proxies/kafka/toxics \
  -d '{
    "name": "latency",
    "type": "latency",
    "stream": "downstream",
    "attributes": {
      "latency": 5000,
      "jitter": 0
    }
  }'
```

**VÃ©rification** :

```bash
curl -fsS http://${NODE_IP}:31474/proxies/kafka/toxics
```

</details>

---

### Ã‰tape 12 - Test avec latence

**Objectif** : Observer le comportement avec la latence.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Commande** :

```bash
EVENT_ID="LATENCY-TEST-$(date +%s)"
time curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**Observation** : La requÃªte prend ~5 secondes de plus que d'habitude.

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
NODE_IP=$(hostname -I | awk '{print $1}')
EVENT_ID="LATENCY-TEST-$(date +%s)"

time curl -fsS -X POST "http://${NODE_IP}:31080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**Observation** : La requÃªte prend ~5 secondes de plus que d'habitude.

> **Note** : Pour que les APIs utilisent Toxiproxy, elles doivent Ãªtre configurÃ©es pour se connecter via le proxy (port 29093/32093) au lieu de directement Ã  Kafka. Par dÃ©faut, les manifests K8s connectent les APIs directement Ã  Kafka.

</details>

---

### Ã‰tape 13 - Suppression de la latence

**Objectif** : Retirer la latence pour continuer les tests.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Commande** :

```bash
curl -fsS -X DELETE http://localhost:8474/proxies/kafka/toxics/latency
```

**VÃ©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
# RÃ©sultat: [] (liste vide)
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
NODE_IP=$(hostname -I | awk '{print $1}')

curl -fsS -X DELETE http://${NODE_IP}:31474/proxies/kafka/toxics/latency
```

**VÃ©rification** :

```bash
curl -fsS http://${NODE_IP}:31474/proxies/kafka/toxics
# RÃ©sultat: [] (liste vide)
```

</details>

---

### Alternatives K8s pour simuler des pannes

En mode Kubernetes, vous pouvez Ã©galement utiliser ces mÃ©thodes natives pour simuler des pannes :

#### MÃ©thode 1 : Suppression de pod (simule un crash)

```bash
# Supprimer un pod Kafka pour simuler un crash
kubectl delete pod -n kafka -l strimzi.io/name=bhf-kafka-kafka --wait=false

# Observer la rÃ©cupÃ©ration automatique
kubectl get pods -n kafka -w
```

#### MÃ©thode 2 : NetworkPolicy (simule une partition rÃ©seau)

```bash
# CrÃ©er une NetworkPolicy pour bloquer le trafic
kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: block-kafka-traffic
  namespace: kafka
spec:
  podSelector:
    matchLabels:
      app: m02-java-api
  policyTypes:
  - Egress
  egress: []
EOF

# Tester l'envoi (devrait Ã©chouer)
curl -X POST "http://${NODE_IP}:31080/api/v1/send?mode=plain&sendMode=sync&eventId=TEST"

# Supprimer la NetworkPolicy
kubectl delete networkpolicy block-kafka-traffic -n kafka
```

#### MÃ©thode 3 : Chaos Engineering avec Litmus ou Chaos Mesh

Pour des tests de chaos plus avancÃ©s, considÃ©rez :
- **Litmus Chaos** : https://litmuschaos.io/
- **Chaos Mesh** : https://chaos-mesh.org/

---

## ğŸ“š Lab 02.4 - Idempotence vs Plain (test clÃ©)

### Objectif

Prouver que l'idempotence Ã©vite les doublons lors des retries.

---

### Ã‰tape 14 - ExÃ©cution du test automatisÃ©

**Objectif** : Valider le comportement idempotent vs non-idempotent.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Explication** : Le script `validate.sh` :

1. Injecte de la latence via Toxiproxy
2. Envoie des messages en mode `plain` et `idempotent`
3. Compte les messages dans Kafka
4. VÃ©rifie que `idempotent` = 1 message exactement

**Commande** :

```bash
./day-01-foundations/module-02-producer-reliability/scripts/validate.sh
```

**RÃ©sultat attendu** :

```text
OK: java_idempotent=1 java_plain=1 dotnet_idempotent=1 dotnet_plain=1
```

**Note** : Si `java_plain` ou `dotnet_plain` > 1, c'est normal ! Cela prouve que les retries peuvent crÃ©er des doublons sans idempotence.

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Explication** : En mode K8s, le script valide le producteur idempotent sans injection de latence Toxiproxy.

**Commande** :

```bash
./day-01-foundations/module-02-producer-reliability/scripts/validate.sh --k8s
```

**RÃ©sultat attendu** :

```text
Running validation in K8s mode...
NOTE: K8s mode tests idempotent producer without Toxiproxy latency injection
OK: java_idempotent=1 (K8s mode - no latency injection)
```

> **Note** : Si les APIs ne sont pas dÃ©ployÃ©es sur K8s, le script validera uniquement le cluster Kafka.

</details>

**âœ… Checkpoint 02.4** : L'idempotence produit exactement 1 message.

---

## ğŸ“š Lab 02.5 - Partitionnement

### Objectif

Comprendre comment les clÃ©s influencent le partitionnement.

---

### Ã‰tape 15 - Envoi sur des partitions diffÃ©rentes

**Objectif** : Envoyer des messages sur des partitions spÃ©cifiques.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
# Message sur partition 0
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P0-$(date +%s)&partition=0"

# Message sur partition 1
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P1-$(date +%s)&partition=1"

# Message sur partition 2
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P2-$(date +%s)&partition=2"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# Message sur partition 0 (NodePort 31080)
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=P0-$(date +%s)&partition=0"

# Message sur partition 1
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=P1-$(date +%s)&partition=1"

# Message sur partition 2
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=P2-$(date +%s)&partition=2"
```

</details>

---

### Ã‰tape 16 - VÃ©rification des partitions

**Objectif** : Confirmer la distribution des messages.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic bhf-transactions \
  --from-beginning \
  --timeout-ms 5000 \
  --property print.partition=true \
  --property print.offset=true
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
kubectl run kafka-consumer --rm -it --restart=Never \
  --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  -n kafka -- bin/kafka-console-consumer.sh \
  --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic bhf-transactions --from-beginning \
  --timeout-ms 5000 \
  --property print.partition=true \
  --property print.offset=true
```

</details>

**RÃ©sultat attendu** : Messages sur diffÃ©rentes partitions (0, 1, 2).

---

## ğŸ“š Lab 02.6 - Log compaction

### Objectif

Comprendre la compaction et son utilitÃ© pour les Ã©tats.

---

### Ã‰tape 17 - CrÃ©ation d'un topic compactÃ©

**Objectif** : CrÃ©er un topic avec la politique de compaction.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic bhf-compact-demo \
  --partitions 1 \
  --replication-factor 1 \
  --config cleanup.policy=compact \
  --config segment.ms=1000 \
  --config min.cleanable.dirty.ratio=0.01
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
cat <<EOF | kubectl apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: bhf-compact-demo
  namespace: kafka
  labels:
    strimzi.io/cluster: bhf-kafka
spec:
  partitions: 1
  replicas: 3
  config:
    cleanup.policy: compact
    segment.ms: "1000"
    min.cleanable.dirty.ratio: "0.01"
EOF
```

</details>

---

### Ã‰tape 18 - Envoi de plusieurs versions

**Objectif** : Envoyer plusieurs valeurs pour la mÃªme clÃ©.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
KEY="customer-42"

# Version 1
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V1&key=$KEY"

# Version 2
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V2&key=$KEY"

# Version 3 (finale)
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V3&key=$KEY"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
KEY="customer-42"

# Version 1 (NodePort 31081)
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V1&key=$KEY"

# Version 2
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V2&key=$KEY"

# Version 3 (finale)
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V3&key=$KEY"
```

</details>

**Note** : AprÃ¨s compaction (asynchrone), seul `V3` sera conservÃ© pour `customer-42`.

**âœ… Checkpoint 02.6** : Vous comprenez la log compaction.

---

## âœ… RÃ©capitulatif des checkpoints

| # | Checkpoint | Statut |
|---|------------|--------|
| 02.0 | APIs Java et .NET rÃ©pondent OK | â˜ |
| 02.1 | Envoi synchrone retourne partition/offset | â˜ |
| 02.2 | Envoi asynchrone + rÃ©cupÃ©ration du statut | â˜ |
| 02.3 | Injection de latence via Toxiproxy | â˜ |
| 02.4 | Script validate.sh retourne OK | â˜ |
| 02.5 | Messages sur diffÃ©rentes partitions | â˜ |
| 02.6 | ComprÃ©hension de la log compaction | â˜ |

---

## ğŸ”§ Troubleshooting

### APIs ne dÃ©marrent pas

**SymptÃ´me** : `m02-java-api` ou `m02-dotnet-api` en erreur.

**Solution** :

```bash
# VÃ©rifier les logs
docker logs m02-java-api --tail 100
docker logs m02-dotnet-api --tail 100

# Reconstruire les images
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml \
  up -d --build --force-recreate
```

### Toxiproxy ne rÃ©pond pas

**SymptÃ´me** : `curl: (7) Failed to connect to localhost port 8474`.

**Solution** :

```bash
# VÃ©rifier les logs
docker logs toxiproxy

# VÃ©rifier le healthcheck
docker inspect toxiproxy --format='{{.State.Health.Status}}'

# RedÃ©marrer si nÃ©cessaire
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml restart toxiproxy

# RecrÃ©er le proxy aprÃ¨s redÃ©marrage
curl -fsS -X POST http://localhost:8474/proxies \
  -H 'Content-Type: application/json' \
  -d '{"name":"kafka","listen":"0.0.0.0:29093","upstream":"kafka:29092"}'
```

### Messages non visibles dans Kafka UI

**SymptÃ´me** : Le topic existe mais pas de messages.

**Solution** :

1. Cliquez sur **Fetch Messages**
2. RÃ©glez le filtre sur **Earliest** (depuis le dÃ©but)
3. VÃ©rifiez le bon topic (`bhf-transactions`)

---

## ğŸ§¹ Nettoyage

**Objectif** : ArrÃªter les services du module.

**Commande** :

```bash
# ArrÃªter uniquement le module
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml down

# ArrÃªter tout (module + cluster Kafka)
./scripts/down.sh
```

---

## ğŸ“– Pour aller plus loin

### Exercices supplÃ©mentaires

1. **Modifiez les timeouts** dans `docker-compose.module.yml` et observez l'impact
2. **Injectez un timeout complet** avec Toxiproxy et observez les erreurs
3. **Testez avec diffÃ©rentes clÃ©s** et observez la distribution sur les partitions

### Ressources

- [Kafka Producer Configuration](https://kafka.apache.org/documentation/#producerconfigs)
- [Idempotent Producer](https://kafka.apache.org/documentation/#semantics)
- [Toxiproxy Documentation](https://github.com/Shopify/toxiproxy)

---

## ğŸ› ï¸ Tutorials pas-Ã -pas

| IDE | Tutorial | Description |
|-----|----------|-------------|
| **VS Code** | [TUTORIAL-DOTNET.md](./TUTORIAL-DOTNET.md) | Minimal API avec Confluent.Kafka |
| **Visual Studio 2022** | [TUTORIAL-VS2022.md](./TUTORIAL-VS2022.md) | Projet complet avec debugging, tests, Swagger |
| **IntelliJ / VS Code** | [TUTORIAL-JAVA.md](./TUTORIAL-JAVA.md) | Spring Boot avec kafka-clients |

---

## â¡ï¸ Module suivant

Une fois ce module terminÃ©, passez au :

ğŸ‘‰ **[Module 03 - Consumer Read-Committed](../module-03-consumer-read-committed/README.md)**
