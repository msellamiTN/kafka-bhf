# Module 01 - Architecture Kafka & Cluster Local

## ğŸ“š ThÃ©orie (30%) - Architecture Kafka

### 1.1 Vue d'ensemble de l'architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer   â”‚â”€â”€â”€â–¶â”‚   Broker     â”‚â—€â”€â”€â”€â”‚   Consumer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  (Leader)    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Zookeeper   â”‚
                   â”‚  (Metadata)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Concepts fondamentaux

#### ğŸ¯ **Topic**
- Flux de donnÃ©es catÃ©gorisÃ©
- Exemple BHF : `transactions-paiements`, `comptes-clients`, `audit-traces`

#### ğŸ“¦ **Partition**
- UnitÃ© de parallÃ©lisme et d'ordonnancement
- 1 partition = 1 thread de consommation maximum
- Distribution basÃ©e sur la clÃ© du message

#### ğŸ“ **Offset**
- Position unique dans une partition
- Permet reprise aprÃ¨s crash
- Gestion manuelle pour exactly-once

#### ğŸ”„ **Replica**
- Redondance des donnÃ©es
- 1 leader + N followers
- Failover automatique

### 1.3 Pourquoi Kafka chez BHF ?

- **FiabilitÃ©** : Garanties exactly-once pour transactions financiÃ¨res
- **ScalabilitÃ©** : Millions d'Ã©vÃ©nements/secondes
- **DurabilitÃ©** : DonnÃ©es persistÃ©es, rejeu possible
- **RÃ©glementation** : Audit trails immuables

---

## ğŸ› ï¸ Pratique (70%) - Cluster Local Docker

### Lab 01.1 - DÃ©ploiement Cluster Kafka

#### Ã‰tape 1 : PrÃ©paration de l'environnement

```powershell
# 1. VÃ©rifier Docker Desktop
docker --version
docker-compose --version

# 2. CrÃ©er workspace de formation
mkdir C:\kafka-formation-bhf
cd C:\kafka-formation-bhf

# 3. CrÃ©er structure des dossiers
mkdir jour-01, logs, scripts
```

#### Ã‰tape 2 : Configuration Docker Compose

CrÃ©er le fichier `docker-compose.yml` :

```yaml
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - kafka-network

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    networks:
      - kafka-network

networks:
  kafka-network:
    driver: bridge
```

#### Ã‰tape 3 : DÃ©marrage du cluster

```powershell
# DÃ©marrer les services
docker-compose up -d

# VÃ©rifier que les containers sont up
docker ps

# Attendre 30 secondes pour le dÃ©marrage complet
Start-Sleep 30
```

**RÃ©sultat attendu :**
```
CONTAINER ID   IMAGE                              COMMAND                  CREATED         STATUS         PORTS
a1b2c3d4e5f6   confluentinc/cp-kafka:7.4.0      "/etc/confluent/dockâ€¦"   2 minutes ago   Up 2 minutes   0.0.0.0:9092->9092/tcp
f6e5d4c3b2a1   confluentinc/cp-zookeeper:7.4.0   "/etc/confluent/dockâ€¦"   2 minutes ago   Up 2 minutes   2181/tcp
```

#### Ã‰tape 4 : Validation du cluster

```powershell
# 1. CrÃ©er un topic de test BHF
docker exec kafka kafka-topics --create --topic bhf-transactions --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1

# 2. Lister les topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# 3. DÃ©crire le topic
docker exec kafka kafka-topics --describe --topic bhf-transactions --bootstrap-server localhost:9092
```

**RÃ©sultat attendu :**
```
Topic: bhf-transactions
PartitionCount: 3
ReplicationFactor: 1
Configs:
    Topic: bhf-transactions
    Partition: 0  Leader: 1  Replicas: 1  Isr: 1
    Partition: 1  Leader: 1  Replicas: 1  Isr: 1
    Partition: 2  Leader: 1  Replicas: 1  Isr: 1
```

#### Ã‰tape 5 : Test de production/consommation

```powershell
# Terminal 1 : Consumer
docker exec -it kafka kafka-console-consumer --topic bhf-transactions --bootstrap-server localhost:9092 --from-beginning

# Terminal 2 : Producer
docker exec -it kafka kafka-console-producer --topic bhf-transactions --bootstrap-server localhost:9092

# Envoyer des messages de test BHF
> transaction-001:{"id":"txn001","montant":1500.00,"devise":"EUR","statut":"EN_COURS"}
> transaction-002:{"id":"txn002","montant":250.50,"devise":"EUR","statut":"VALIDE"}
```

**VÃ©rification dans le consumer :**
```
transaction-001	{"id":"txn001","montant":1500.00,"devise":"EUR","statut":"EN_COURS"}
transaction-002	{"id":"txn002","montant":250.50,"devise":"EUR","statut":"VALIDE"}
```

---

## ğŸ¯ Checkpoint Module 01

### âœ… Validation des compÃ©tences

- [ ] Cluster Kafka dÃ©marrÃ© avec Docker Compose
- [ ] Topic BHF crÃ©Ã© avec 3 partitions
- [ ] Messages produits et consommÃ©s avec succÃ¨s
- [ ] Architecture comprise (Producer/Broker/Consumer/Zookeeper)

### ğŸ“ Questions de checkpoint

1. **Pourquoi 3 partitions pour le topic `bhf-transactions` ?**
   - ParallÃ©lisme : 3 consumers peuvent traiter en parallÃ¨le
   - ScalabilitÃ© horizontale

2. **Que se passe-t-il si le container Kafka crash ?**
   - DonnÃ©es persistÃ©es dans volumes Docker
   - RedÃ©marrage automatique avec `docker-compose up -d`

3. **Comment BHF utilise-t-il Kafka en production ?**
   - Transactions financiÃ¨res en temps rÃ©el
   - Audit trails immuables
   - IntÃ©gration entre systÃ¨mes hÃ©tÃ©rogÃ¨nes

---

## ğŸš€ Prochain module

**Module 02** : Producer Idempotent - Configuration avancÃ©e pour garantir l'unicitÃ© des messages dans un contexte bancaire.
