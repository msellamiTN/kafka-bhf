# Module 02 - FiabilitÃ© du Producteur Kafka (Idempotence) - Formation Auto-rythmÃ©e

## DurÃ©e estimÃ©e

â±ï¸ **60-90 minutes**

## Objectifs pÃ©dagogiques

Ã€ la fin de ce module, vous serez capable de :

1. âœ… Comprendre la diffÃ©rence entre un producer **idempotent** et **non-idempotent**
2. âœ… MaÃ®triser l'envoi **synchrone** vs **asynchrone** et les callbacks
3. âœ… Configurer les **retries** et **timeouts** pour la fiabilitÃ©
4. âœ… Comprendre l'impact des **clÃ©s** sur le partitionnement
5. âœ… Utiliser **Toxiproxy** pour simuler des pannes rÃ©seau
6. âœ… Observer et dÃ©boguer les messages via **Kafka UI**
7. âœ… Comprendre la **log compaction** et son utilitÃ©

---

## ğŸ“– Partie ThÃ©orique Approfondie

### 1. Le Producteur Kafka en dÃ©tail

#### Cycle de vie d'un message

```mermaid
sequenceDiagram
    participant App as Application
    participant Prod as Producer
    participant Ser as Serializer
    participant Part as Partitioner
    participant Batch as RecordAccumulator
    participant Net as NetworkClient
    participant Broker as Kafka Broker
    
    App->>Prod: send(record)
    Prod->>Ser: serialize(key, value)
    Ser-->>Prod: byte[]
    Prod->>Part: partition(topic, key)
    Part-->>Prod: partition number
    Prod->>Batch: append to batch
    Note over Batch: Attend linger.ms ou batch.size
    Batch->>Net: send batch
    Net->>Broker: ProduceRequest
    Broker->>Broker: Write to log
    Broker->>Broker: Replicate
    Broker-->>Net: ProduceResponse (offset)
    Net-->>Prod: RecordMetadata
    Prod-->>App: Future/Callback
```

#### Composants internes du Producer

```mermaid
flowchart TB
    subgraph Producer["ğŸ“¤ Kafka Producer"]
        subgraph Config["Configuration"]
            BS["batch.size<br/>16KB"]
            LI["linger.ms<br/>0ms"]
            AC["acks<br/>all"]
            RE["retries<br/>âˆ"]
        end
        
        subgraph Pipeline["Pipeline d'envoi"]
            SER["ğŸ”„ Serializer<br/>Key + Value"]
            PAR["ğŸ“Š Partitioner<br/>Round-robin / Hash"]
            ACC["ğŸ“¦ RecordAccumulator<br/>Batching"]
            SND["ğŸŒ Sender Thread<br/>Network I/O"]
        end
        
        SER --> PAR --> ACC --> SND
    end
    
    SND -->|"ProduceRequest"| K["ğŸ“¦ Kafka Broker"]
    K -->|"ACK"| SND
```

---

### 2. Les Acknowledgments (ACKs)

#### Niveaux d'ACK

```mermaid
flowchart TB
    subgraph acks0["acks=0 (Fire & Forget)"]
        P0["Producer"] -->|"Envoie"| B0["Broker"]
        P0 -.->|"N'attend pas"| X0["âŒ"]
    end
    
    subgraph acks1["acks=1 (Leader Only)"]
        P1["Producer"] -->|"Envoie"| L1["Leader"]
        L1 -->|"ACK"| P1
        L1 -.->|"RÃ©plique aprÃ¨s"| F1["Follower"]
    end
    
    subgraph acksAll["acks=all (Toutes les ISR)"]
        P2["Producer"] -->|"Envoie"| L2["Leader"]
        L2 -->|"RÃ©plique"| F2["Follower 1"]
        L2 -->|"RÃ©plique"| F3["Follower 2"]
        F2 -->|"ACK"| L2
        F3 -->|"ACK"| L2
        L2 -->|"ACK"| P2
    end
    
    style acks0 fill:#ffebee
    style acks1 fill:#fff3e0
    style acksAll fill:#e8f5e9
```

#### Comparaison des modes ACK

| Mode | DurabilitÃ© | Performance | Risque de perte |
|------|------------|-------------|-----------------|
| `acks=0` | âŒ Aucune | âš¡âš¡âš¡ Maximale | Ã‰levÃ© |
| `acks=1` | âš ï¸ Partielle | âš¡âš¡ Bonne | Moyen |
| `acks=all` | âœ… ComplÃ¨te | âš¡ ModÃ©rÃ©e | Minimal |

---

### 3. L'Idempotence en profondeur

#### Le problÃ¨me des doublons

```mermaid
sequenceDiagram
    participant P as Producer
    participant B as Broker
    
    P->>B: Message "order-123"
    B->>B: Write OK
    B--xP: ACK perdu (rÃ©seau)
    Note over P: Timeout â†’ Retry
    P->>B: Message "order-123" (retry)
    B->>B: Write OK (DOUBLON !)
    B-->>P: ACK
    
    Note over B: âŒ 2 messages identiques
```

#### Solution : Producer Idempotent

```mermaid
sequenceDiagram
    participant P as Producer (PID=42)
    participant B as Broker
    
    P->>B: Message "order-123" (seq=0)
    B->>B: Write OK, store seq=0
    B--xP: ACK perdu
    Note over P: Timeout â†’ Retry
    P->>B: Message "order-123" (seq=0, retry)
    B->>B: Check: seq=0 dÃ©jÃ  vu â†’ SKIP
    B-->>P: ACK (avec offset original)
    
    Note over B: âœ… 1 seul message
```

#### MÃ©canisme interne

| Concept | Description |
|---------|-------------|
| **PID** (Producer ID) | Identifiant unique du producer (assignÃ© au dÃ©marrage) |
| **Epoch** | Version du producer (incrÃ©mentÃ© si redÃ©marrage) |
| **Sequence Number** | NumÃ©ro sÃ©quentiel par partition (0, 1, 2, ...) |

```
Message format avec idempotence:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PID: 42 â”‚ Epoch: 0 â”‚ SeqNum: 5 â”‚ Partition: 0  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Payload                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4. Retries et Gestion des erreurs

#### Timeline des retries

```mermaid
gantt
    title ScÃ©nario de retry avec succÃ¨s
    dateFormat X
    axisFormat %s
    
    section Request 1
    Envoi initial        :a1, 0, 1
    Attente ACK         :a2, 1, 2
    Timeout             :crit, a3, 2, 3
    
    section Retry 1
    Backoff (100ms)     :b1, 3, 4
    Retry               :b2, 4, 5
    Attente ACK         :b3, 5, 6
    Timeout             :crit, b4, 6, 7
    
    section Retry 2
    Backoff (200ms)     :c1, 7, 9
    Retry               :c2, 9, 10
    ACK reÃ§u            :done, c3, 10, 11
```

#### ParamÃ¨tres de retry

```mermaid
flowchart LR
    subgraph Timeouts["â±ï¸ Timeouts"]
        RT["request.timeout.ms<br/>30s"]
        DT["delivery.timeout.ms<br/>120s"]
    end
    
    subgraph Retries["ğŸ”„ Retries"]
        R["retries<br/>2147483647"]
        RB["retry.backoff.ms<br/>100ms"]
    end
    
    subgraph Constraint["âš ï¸ Contrainte"]
        C["delivery.timeout.ms â‰¥<br/>request.timeout.ms +<br/>linger.ms"]
    end
```

#### Erreurs rÃ©cupÃ©rables vs non-rÃ©cupÃ©rables

| Type | Exemples | Action |
|------|----------|--------|
| **RÃ©cupÃ©rable** | NetworkException, LeaderNotAvailable | Retry automatique |
| **Non-rÃ©cupÃ©rable** | InvalidTopicException, AuthorizationException | Ã‰chec immÃ©diat |
| **Fatal** | ProducerFenced, OutOfMemory | ArrÃªt du producer |

---

### 5. Synchrone vs Asynchrone

#### Mode Synchrone

```mermaid
sequenceDiagram
    participant C as Client HTTP
    participant A as API
    participant P as Producer
    participant K as Kafka
    
    C->>A: POST /send (sync)
    A->>P: send()
    P->>K: ProduceRequest
    K-->>P: ProduceResponse
    P-->>A: RecordMetadata
    A-->>C: 200 OK + offset
    
    Note over C,A: â±ï¸ Client bloquÃ© pendant l'envoi
```

#### Mode Asynchrone

```mermaid
sequenceDiagram
    participant C as Client HTTP
    participant A as API
    participant P as Producer
    participant K as Kafka
    participant S as StatusStore
    
    C->>A: POST /send (async)
    A->>P: send() + callback
    A->>S: Store requestId=PENDING
    A-->>C: 202 Accepted + requestId
    
    Note over C: Client libÃ©rÃ© immÃ©diatement
    
    P->>K: ProduceRequest
    K-->>P: ProduceResponse
    P->>S: Update requestId=OK
    
    C->>A: GET /status?requestId=...
    A->>S: Get status
    A-->>C: 200 OK + offset
```

#### Comparaison

| Aspect | Synchrone | Asynchrone |
|--------|-----------|------------|
| **Latence perÃ§ue** | Haute | Basse |
| **ComplexitÃ©** | Simple | Plus complexe |
| **Gestion d'erreur** | ImmÃ©diate | DiffÃ©rÃ©e (polling) |
| **DÃ©bit** | LimitÃ© | Ã‰levÃ© |
| **Cas d'usage** | APIs critiques | Haute performance |

---

### 6. Partitionnement et ClÃ©s

#### StratÃ©gies de partitionnement

```mermaid
flowchart TB
    subgraph NoKey["Sans clÃ© (Round-Robin)"]
        M1["Msg 1"] --> P0a["Partition 0"]
        M2["Msg 2"] --> P1a["Partition 1"]
        M3["Msg 3"] --> P2a["Partition 2"]
        M4["Msg 4"] --> P0a
    end
    
    subgraph WithKey["Avec clÃ© (Hash)"]
        K1["key=A"] --> Hash1["hash('A') % 3 = 1"]
        K2["key=B"] --> Hash2["hash('B') % 3 = 0"]
        K3["key=A"] --> Hash3["hash('A') % 3 = 1"]
        
        Hash1 --> P1b["Partition 1"]
        Hash2 --> P0b["Partition 0"]
        Hash3 --> P1b
    end
    
    style NoKey fill:#fff3e0
    style WithKey fill:#e8f5e9
```

#### Garantie d'ordre avec les clÃ©s

```
Topic: orders (3 partitions)

key="customer-42":
  Partition 1: [order-1] â†’ [order-2] â†’ [order-3] âœ… Ordre garanti

key="customer-99":
  Partition 0: [order-A] â†’ [order-B] â†’ [order-C] âœ… Ordre garanti

âš ï¸ Pas d'ordre garanti ENTRE les partitions
```

---

### 7. Log Compaction

#### Principe

```mermaid
flowchart LR
    subgraph Before["Avant Compaction"]
        B1["k1:v1"]
        B2["k2:v1"]
        B3["k1:v2"]
        B4["k3:v1"]
        B5["k1:v3"]
        B6["k2:v2"]
    end
    
    Compact["ğŸ”„ Compaction"]
    
    subgraph After["AprÃ¨s Compaction"]
        A1["k3:v1"]
        A2["k1:v3"]
        A3["k2:v2"]
    end
    
    Before --> Compact --> After
```

#### Cas d'usage

| ScÃ©nario | Exemple | ClÃ© | Valeur |
|----------|---------|-----|--------|
| **Ã‰tat utilisateur** | Profil client | userId | JSON profil |
| **Position GPS** | Flotte vÃ©hicules | vehicleId | lat/long |
| **Configuration** | Feature flags | featureName | enabled/disabled |
| **Inventaire** | Stock produits | productId | quantitÃ© |

---

### 8. Toxiproxy : Simulation de pannes

#### Architecture avec Toxiproxy

```mermaid
flowchart LR
    subgraph Normal["Mode Normal"]
        A1["API"] -->|"29092"| K1["Kafka"]
    end
    
    subgraph Proxy["Mode Proxy"]
        A2["API"] -->|"29093"| T["ğŸ’€ Toxiproxy"]
        T -->|"29092"| K2["Kafka"]
        
        subgraph Toxics["Effets injectables"]
            L["â±ï¸ Latency"]
            TO["â¹ï¸ Timeout"]
            BW["ğŸ“‰ Bandwidth"]
            SL["ğŸ”€ Slicer"]
        end
    end
    
    style T fill:#fff3e0
```

#### Types de pannes simulables

| Toxic | Effet | ParamÃ¨tres |
|-------|-------|------------|
| **latency** | Ajoute un dÃ©lai | `latency`, `jitter` |
| **timeout** | Coupe la connexion aprÃ¨s N ms | `timeout` |
| **bandwidth** | Limite le dÃ©bit | `rate` (KB/s) |
| **slicer** | Fragmente les paquets | `average_size`, `delay` |
| **slow_close** | Fermeture lente | `delay` |

```json
// Exemple : ajouter 5 secondes de latence
{
  "name": "latency",
  "type": "latency",
  "stream": "downstream",
  "attributes": {
    "latency": 5000,
    "jitter": 500
  }
}
```

---

## ğŸ—ï¸ Architecture du module

```mermaid
flowchart TB
    subgraph Client["Votre Machine"]
        curl["ğŸ–¥ï¸ curl / Postman"]
    end
    
    subgraph Docker["Docker Environment"]
        Java["â˜• Java API<br/>Port: 18080"]
        DotNet["ğŸ”· .NET API<br/>Port: 18081"]
        Toxi["ğŸ’€ Toxiproxy<br/>Port: 8474<br/>(tests de pannes)"]
        K["ğŸ“¦ Kafka Broker<br/>Port: 29092"]
        UI["ğŸ“Š Kafka UI<br/>Port: 8080"]
    end
    
    curl --> Java
    curl --> DotNet
    Java -->|"kafka:29092"| K
    DotNet -->|"kafka:29092"| K
    Toxi -.->|"proxy disponible<br/>sur :29093"| K
    K --> UI
    
    style Toxi fill:#fff3e0
    style K fill:#e8f5e8
```

> **Note** : Les APIs se connectent directement Ã  Kafka. Toxiproxy est disponible sur le port 29093 pour les tests d'injection de pannes manuels.

---

## ğŸ”Œ Ports et endpoints

### Services

| Service | Port | URL |
|---------|------|-----|
| Java API | 18080 | http://localhost:18080 |
| .NET API | 18081 | http://localhost:18081 |
| Toxiproxy | 8474 | http://localhost:8474 |
| Kafka UI | 8080 | http://localhost:8080 |

### Endpoints des APIs

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/health` | Health check |
| POST | `/api/v1/send` | Envoyer un message |
| GET | `/api/v1/status` | Statut d'un envoi async |

### ParamÃ¨tres de `/api/v1/send`

| ParamÃ¨tre | Valeurs | Description |
|-----------|---------|-------------|
| `mode` | `plain`, `idempotent` | Mode du producer |
| `sendMode` | `sync`, `async` | Synchrone ou asynchrone |
| `eventId` | string | Identifiant unique du message |
| `key` | string (optionnel) | ClÃ© de partitionnement |
| `partition` | int (optionnel) | Partition cible |

---

## ğŸ“‹ PrÃ©-requis

### Logiciels

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

- âœ… Docker + Docker Compose
- âœ… curl (ligne de commande)
- âœ… Navigateur web

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

- âœ… Cluster Kubernetes (K3s, OKD, ou OpenShift)
- âœ… kubectl configurÃ©
- âœ… Strimzi Operator installÃ©
- âœ… curl (ligne de commande)

</details>

### Cluster Kafka dÃ©marrÃ©

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
cd formation-v2/
./scripts/up.sh   # Mode single-node par dÃ©faut
# ou: ./scripts/up.sh cluster   # Mode cluster 3 brokers
```

**VÃ©rification** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}' | grep kafka
```

**RÃ©sultat attendu** : `kafka` et `kafka-ui` sont `Up (healthy)`.

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# VÃ©rifier que le cluster Kafka est prÃªt
kubectl get kafka -n kafka

# RÃ©sultat attendu:
# NAME        DESIRED KAFKA REPLICAS   DESIRED ZK REPLICAS   READY   ...
# bhf-kafka   3                                              True    ...
```

**VÃ©rification des pods** :

```bash
kubectl get pods -n kafka -l strimzi.io/cluster=bhf-kafka
```

</details>

---

## ğŸ“š Lab 02.0 - DÃ©marrage du module

### Objectif

DÃ©marrer les services du module (APIs Java/.NET + Toxiproxy) et vÃ©rifier leur bon fonctionnement.

---

### Ã‰tape 1 - Positionnement

**Objectif** : Se placer dans le bon rÃ©pertoire.

```bash
cd formation-v2/
```

---

### Ã‰tape 2 - DÃ©marrage des services

**Objectif** : Lancer les conteneurs du module.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Explication** : Cette commande lance :

- **Toxiproxy** : Proxy rÃ©seau pour injecter des pannes
- **toxiproxy-init** : Configuration initiale du proxy (one-shot)
- **m02-java-api** : API Spring Boot (Java)
- **m02-dotnet-api** : API ASP.NET (.NET)

**Commande** :

```bash
# Si le cluster Kafka est dÃ©jÃ  dÃ©marrÃ© via ./scripts/up.sh :
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml up -d --build
```

**â±ï¸ Temps d'attente** : 2-3 minutes (build des images Java/.NET).

**RÃ©sultat attendu** :

```text
[+] Running 4/4
 âœ” Container toxiproxy        Healthy
 âœ” Container toxiproxy-init   Started
 âœ” Container m02-java-api     Started
 âœ” Container m02-dotnet-api   Started
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Explication** : En mode K8s, les APIs doivent Ãªtre dÃ©ployÃ©es comme des Deployments avec des Services NodePort.

**Option 1 - Utiliser les images Docker locales** :

```bash
# Builder et pousser les images vers le registry local
cd formation-v2/day-01-foundations/module-02-producer-reliability

# Build Java API
docker build -t localhost:5000/m02-java-api:latest -f java-api/Dockerfile java-api/
docker push localhost:5000/m02-java-api:latest

# Build .NET API
docker build -t localhost:5000/m02-dotnet-api:latest -f dotnet-api/Dockerfile dotnet-api/
docker push localhost:5000/m02-dotnet-api:latest
```

**Option 2 - DÃ©ployer sur K8s** :

```bash
# CrÃ©er le dÃ©ploiement Java API
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: m02-java-api
  namespace: kafka
spec:
  replicas: 1
  selector:
    matchLabels:
      app: m02-java-api
  template:
    metadata:
      labels:
        app: m02-java-api
    spec:
      containers:
      - name: java-api
        image: localhost:5000/m02-java-api:latest
        ports:
        - containerPort: 8080
        env:
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "bhf-kafka-kafka-bootstrap.kafka.svc:9092"
---
apiVersion: v1
kind: Service
metadata:
  name: m02-java-api
  namespace: kafka
spec:
  type: NodePort
  ports:
  - port: 8080
    targetPort: 8080
    nodePort: 31080
  selector:
    app: m02-java-api
EOF
```

**VÃ©rification** :

```bash
kubectl get pods -n kafka -l app=m02-java-api
kubectl get svc m02-java-api -n kafka
```

> **Note** : En mode K8s, Toxiproxy n'est pas utilisÃ©. Les tests de latence peuvent Ãªtre effectuÃ©s avec des outils comme `tc` (traffic control) ou en simulant des pannes de pods.

</details>

---

### Ã‰tape 3 - VÃ©rification des conteneurs

**Objectif** : S'assurer que tous les services sont opÃ©rationnels.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Commande** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'
```

**RÃ©sultat attendu** :

| Conteneur | Statut attendu |
|-----------|----------------|
| kafka | Up (healthy) |
| kafka-ui | Up (healthy) |
| toxiproxy | Up |
| toxiproxy-init | Exited (0) âœ… normal |
| m02-java-api | Up |
| m02-dotnet-api | Up |

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
kubectl get pods -n kafka
```

**RÃ©sultat attendu** :

| Pod | Statut attendu |
|-----|----------------|
| bhf-kafka-* | Running |
| m02-java-api-* | Running |
| m02-dotnet-api-* | Running (si dÃ©ployÃ©) |

</details>

---

### Ã‰tape 4 - Test de santÃ© des APIs

**Objectif** : VÃ©rifier que les APIs rÃ©pondent.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
# Test Java API
curl -fsS http://localhost:18080/health
# RÃ©sultat attendu: OK

# Test .NET API
curl -fsS http://localhost:18081/health
# RÃ©sultat attendu: OK
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# Test Java API (NodePort 31080)
curl -fsS http://localhost:31080/health
# RÃ©sultat attendu: OK

# Test .NET API (NodePort 31081)
curl -fsS http://localhost:31081/health
# RÃ©sultat attendu: OK

# Si localhost ne fonctionne pas, utilisez l'IP du node:
curl -fsS http://$(hostname -I | awk '{print $1}'):31080/health
```

</details>

**âœ… Checkpoint 02.0** : Les deux APIs rÃ©pondent `OK`.

---

## ğŸ“š Lab 02.1 - Envoi synchrone (baseline)

### Objectif

Envoyer un message en mode **synchrone** et comprendre la rÃ©ponse avec l'offset.

---

### Ã‰tape 5 - Envoi d'un message synchrone (Java API)

**Objectif** : Envoyer un message et recevoir l'ACK Kafka.

**ThÃ©orie** : En mode **synchrone**, l'API attend la confirmation de Kafka avant de rÃ©pondre. La rÃ©ponse contient :
- Le **topic** de destination
- La **partition** utilisÃ©e
- L'**offset** du message

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
# GÃ©nÃ©rer un ID unique
EVENT_ID="JAVA-SYNC-$(date +%s)"
echo "EventId: $EVENT_ID"

# Envoyer le message
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# GÃ©nÃ©rer un ID unique
EVENT_ID="JAVA-SYNC-$(date +%s)"
echo "EventId: $EVENT_ID"

# Envoyer le message (NodePort 31080)
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

**RÃ©sultat attendu** :

```json
{
  "status": "OK",
  "topic": "bhf-transactions",
  "partition": 0,
  "offset": 5,
  "eventId": "JAVA-SYNC-1706400000"
}
```

**Explication de la rÃ©ponse** :

| Champ | Description |
|-------|-------------|
| `status` | OK = message Ã©crit avec succÃ¨s |
| `topic` | Topic de destination |
| `partition` | Partition oÃ¹ le message est stockÃ© |
| `offset` | Position du message dans la partition |
| `eventId` | Identifiant unique envoyÃ© |

---

### Ã‰tape 6 - Envoi avec l'API .NET

**Objectif** : VÃ©rifier que l'API .NET fonctionne de la mÃªme maniÃ¨re.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
EVENT_ID="DOTNET-SYNC-$(date +%s)"
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
EVENT_ID="DOTNET-SYNC-$(date +%s)"
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

</details>

**âœ… Checkpoint 02.1** : Les deux APIs retournent un JSON avec `partition` et `offset`.

---

### Ã‰tape 7 - Visualisation dans Kafka UI

**Objectif** : Observer les messages envoyÃ©s.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Actions** :

1. Ouvrez **http://localhost:8080**
2. Cliquez sur le cluster **BHF-Training**
3. Menu **Topics** â†’ **bhf-transactions**
4. Onglet **Messages** â†’ **Fetch Messages**

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Via kubectl** :

```bash
# Consommer les messages directement
kubectl run kafka-consumer --rm -it --restart=Never \
  --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  -n kafka -- bin/kafka-console-consumer.sh \
  --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic bhf-transactions --from-beginning --max-messages 5
```

**Via Kafka UI (si dÃ©ployÃ©)** : AccÃ©dez via le NodePort ou Route configurÃ©.

</details>

**Ce que vous devez voir** :
- Vos messages avec les `eventId` envoyÃ©s
- La partition et l'offset de chaque message
- Le timestamp d'envoi

---

## ğŸ“š Lab 02.2 - Envoi asynchrone et callbacks

### Objectif

Comprendre le mode **asynchrone** et comment rÃ©cupÃ©rer le statut via polling.

---

### Ã‰tape 8 - Envoi asynchrone (Java)

**Objectif** : Envoyer un message sans attendre l'ACK.

**ThÃ©orie** : En mode **asynchrone** :
1. L'API retourne immÃ©diatement un `requestId`
2. Le message est envoyÃ© en arriÃ¨re-plan
3. Vous consultez le statut via `/api/v1/status`

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
EVENT_ID="JAVA-ASYNC-$(date +%s)"

# Envoyer en asynchrone
RESPONSE=$(curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=idempotent&sendMode=async&eventId=$EVENT_ID")
echo "RÃ©ponse: $RESPONSE"

# Extraire le requestId
REQ_ID=$(echo "$RESPONSE" | sed -n 's/.*"requestId":"\([^"]*\)".*/\1/p')
echo "RequestId: $REQ_ID"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
EVENT_ID="JAVA-ASYNC-$(date +%s)"

# Envoyer en asynchrone (NodePort 31080)
RESPONSE=$(curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=idempotent&sendMode=async&eventId=$EVENT_ID")
echo "RÃ©ponse: $RESPONSE"

# Extraire le requestId
REQ_ID=$(echo "$RESPONSE" | sed -n 's/.*"requestId":"\([^"]*\)".*/\1/p')
echo "RequestId: $REQ_ID"
```

</details>

**RÃ©sultat attendu** :

```json
{
  "status": "ACCEPTED",
  "requestId": "abc123-def456",
  "eventId": "JAVA-ASYNC-1706400000"
}
```

---

### Ã‰tape 9 - Consultation du statut

**Objectif** : RÃ©cupÃ©rer le rÃ©sultat de l'envoi asynchrone.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
# Attendre 2 secondes pour que l'envoi se termine
sleep 2

# Consulter le statut
curl -fsS "http://localhost:18080/api/v1/status?requestId=$REQ_ID"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# Attendre 2 secondes pour que l'envoi se termine
sleep 2

# Consulter le statut (NodePort 31080)
curl -fsS "http://localhost:31080/api/v1/status?requestId=$REQ_ID"
```

</details>

**RÃ©sultat attendu (succÃ¨s)** :

```json
{
  "state": "OK",
  "topic": "bhf-transactions",
  "partition": 1,
  "offset": 10
}
```

**RÃ©sultat possible (en cours)** :

```json
{
  "state": "PENDING"
}
```

**âœ… Checkpoint 02.2** : Vous savez envoyer en asynchrone et rÃ©cupÃ©rer le statut.

---

## ğŸ“š Lab 02.3 - Injection de pannes avec Toxiproxy

### Objectif

Simuler des problÃ¨mes rÃ©seau pour observer le comportement des retries.

> â˜¸ï¸ **Note K8s** : Toxiproxy n'est pas disponible en mode K8s. Les Ã©tapes 10-13 sont spÃ©cifiques au mode Docker. Pour simuler des pannes en K8s, utilisez des outils comme `kubectl delete pod` ou des NetworkPolicies.

---

### Ã‰tape 10 - VÃ©rification du proxy Toxiproxy

**Objectif** : Confirmer que le proxy Kafka est configurÃ©.

**Commande** :

```bash
curl -fsS http://localhost:8474/proxies | python3 -m json.tool
```

**RÃ©sultat attendu** : Un proxy nommÃ© `kafka` avec :
- `listen`: `0.0.0.0:29093`
- `upstream`: `kafka:29092`

---

### Ã‰tape 11 - Injection de latence

**Objectif** : Ajouter 5 secondes de latence sur les rÃ©ponses Kafka.

**ThÃ©orie** : La latence peut provoquer des **timeouts** cÃ´tÃ© producer, ce qui dÃ©clenche des **retries**.

**Commande pour ajouter la latence** :

```bash
curl -fsS -H 'Content-Type: application/json' \
  -X POST http://localhost:8474/proxies/kafka/toxics \
  -d '{
    "name": "latency",
    "type": "latency",
    "stream": "downstream",
    "attributes": {
      "latency": 5000,
      "jitter": 0
    }
  }'
```

**VÃ©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
```

---

### Ã‰tape 12 - Test avec latence

**Objectif** : Observer le comportement avec la latence.

**Commande** :

```bash
EVENT_ID="LATENCY-TEST-$(date +%s)"
time curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**Observation** : La requÃªte prend ~5 secondes de plus que d'habitude.

---

### Ã‰tape 13 - Suppression de la latence

**Objectif** : Retirer la latence pour continuer les tests.

**Commande** :

```bash
curl -fsS -X DELETE http://localhost:8474/proxies/kafka/toxics/latency
```

**VÃ©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
# RÃ©sultat: [] (liste vide)
```

---

## ğŸ“š Lab 02.4 - Idempotence vs Plain (test clÃ©)

### Objectif

Prouver que l'idempotence Ã©vite les doublons lors des retries.

---

### Ã‰tape 14 - ExÃ©cution du test automatisÃ©

**Objectif** : Valider le comportement idempotent vs non-idempotent.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

**Explication** : Le script `validate.sh` :

1. Injecte de la latence via Toxiproxy
2. Envoie des messages en mode `plain` et `idempotent`
3. Compte les messages dans Kafka
4. VÃ©rifie que `idempotent` = 1 message exactement

**Commande** :

```bash
./day-01-foundations/module-02-producer-reliability/scripts/validate.sh
```

**RÃ©sultat attendu** :

```text
OK: java_idempotent=1 java_plain=1 dotnet_idempotent=1 dotnet_plain=1
```

**Note** : Si `java_plain` ou `dotnet_plain` > 1, c'est normal ! Cela prouve que les retries peuvent crÃ©er des doublons sans idempotence.

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

**Explication** : En mode K8s, le script valide le producteur idempotent sans injection de latence Toxiproxy.

**Commande** :

```bash
./day-01-foundations/module-02-producer-reliability/scripts/validate.sh --k8s
```

**RÃ©sultat attendu** :

```text
Running validation in K8s mode...
NOTE: K8s mode tests idempotent producer without Toxiproxy latency injection
OK: java_idempotent=1 (K8s mode - no latency injection)
```

> **Note** : Si les APIs ne sont pas dÃ©ployÃ©es sur K8s, le script validera uniquement le cluster Kafka.

</details>

**âœ… Checkpoint 02.4** : L'idempotence produit exactement 1 message.

---

## ğŸ“š Lab 02.5 - Partitionnement

### Objectif

Comprendre comment les clÃ©s influencent le partitionnement.

---

### Ã‰tape 15 - Envoi sur des partitions diffÃ©rentes

**Objectif** : Envoyer des messages sur des partitions spÃ©cifiques.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
# Message sur partition 0
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P0-$(date +%s)&partition=0"

# Message sur partition 1
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P1-$(date +%s)&partition=1"

# Message sur partition 2
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P2-$(date +%s)&partition=2"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
# Message sur partition 0 (NodePort 31080)
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=P0-$(date +%s)&partition=0"

# Message sur partition 1
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=P1-$(date +%s)&partition=1"

# Message sur partition 2
curl -fsS -X POST "http://localhost:31080/api/v1/send?mode=plain&sendMode=sync&eventId=P2-$(date +%s)&partition=2"
```

</details>

---

### Ã‰tape 16 - VÃ©rification des partitions

**Objectif** : Confirmer la distribution des messages.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic bhf-transactions \
  --from-beginning \
  --timeout-ms 5000 \
  --property print.partition=true \
  --property print.offset=true
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
kubectl run kafka-consumer --rm -it --restart=Never \
  --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  -n kafka -- bin/kafka-console-consumer.sh \
  --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic bhf-transactions --from-beginning \
  --timeout-ms 5000 \
  --property print.partition=true \
  --property print.offset=true
```

</details>

**RÃ©sultat attendu** : Messages sur diffÃ©rentes partitions (0, 1, 2).

---

## ğŸ“š Lab 02.6 - Log compaction

### Objectif

Comprendre la compaction et son utilitÃ© pour les Ã©tats.

---

### Ã‰tape 17 - CrÃ©ation d'un topic compactÃ©

**Objectif** : CrÃ©er un topic avec la politique de compaction.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic bhf-compact-demo \
  --partitions 1 \
  --replication-factor 1 \
  --config cleanup.policy=compact \
  --config segment.ms=1000 \
  --config min.cleanable.dirty.ratio=0.01
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
cat <<EOF | kubectl apply -f -
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: bhf-compact-demo
  namespace: kafka
  labels:
    strimzi.io/cluster: bhf-kafka
spec:
  partitions: 1
  replicas: 3
  config:
    cleanup.policy: compact
    segment.ms: "1000"
    min.cleanable.dirty.ratio: "0.01"
EOF
```

</details>

---

### Ã‰tape 18 - Envoi de plusieurs versions

**Objectif** : Envoyer plusieurs valeurs pour la mÃªme clÃ©.

<details>
<summary>ğŸ³ <b>Mode Docker</b></summary>

```bash
KEY="customer-42"

# Version 1
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V1&key=$KEY"

# Version 2
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V2&key=$KEY"

# Version 3 (finale)
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V3&key=$KEY"
```

</details>

<details>
<summary>â˜¸ï¸ <b>Mode OKD/K3s</b></summary>

```bash
KEY="customer-42"

# Version 1 (NodePort 31081)
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V1&key=$KEY"

# Version 2
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V2&key=$KEY"

# Version 3 (finale)
curl -fsS -X POST "http://localhost:31081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V3&key=$KEY"
```

</details>

**Note** : AprÃ¨s compaction (asynchrone), seul `V3` sera conservÃ© pour `customer-42`.

**âœ… Checkpoint 02.6** : Vous comprenez la log compaction.

---

## âœ… RÃ©capitulatif des checkpoints

| # | Checkpoint | Statut |
|---|------------|--------|
| 02.0 | APIs Java et .NET rÃ©pondent OK | â˜ |
| 02.1 | Envoi synchrone retourne partition/offset | â˜ |
| 02.2 | Envoi asynchrone + rÃ©cupÃ©ration du statut | â˜ |
| 02.3 | Injection de latence via Toxiproxy | â˜ |
| 02.4 | Script validate.sh retourne OK | â˜ |
| 02.5 | Messages sur diffÃ©rentes partitions | â˜ |
| 02.6 | ComprÃ©hension de la log compaction | â˜ |

---

## ğŸ”§ Troubleshooting

### APIs ne dÃ©marrent pas

**SymptÃ´me** : `m02-java-api` ou `m02-dotnet-api` en erreur.

**Solution** :

```bash
# VÃ©rifier les logs
docker logs m02-java-api --tail 100
docker logs m02-dotnet-api --tail 100

# Reconstruire les images
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml \
  up -d --build --force-recreate
```

### Toxiproxy ne rÃ©pond pas

**SymptÃ´me** : `curl: (7) Failed to connect to localhost port 8474`.

**Solution** :

```bash
# VÃ©rifier les logs
docker logs toxiproxy

# VÃ©rifier le healthcheck
docker inspect toxiproxy --format='{{.State.Health.Status}}'

# RedÃ©marrer si nÃ©cessaire
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml restart toxiproxy

# RecrÃ©er le proxy aprÃ¨s redÃ©marrage
curl -fsS -X POST http://localhost:8474/proxies \
  -H 'Content-Type: application/json' \
  -d '{"name":"kafka","listen":"0.0.0.0:29093","upstream":"kafka:29092"}'
```

### Messages non visibles dans Kafka UI

**SymptÃ´me** : Le topic existe mais pas de messages.

**Solution** :

1. Cliquez sur **Fetch Messages**
2. RÃ©glez le filtre sur **Earliest** (depuis le dÃ©but)
3. VÃ©rifiez le bon topic (`bhf-transactions`)

---

## ğŸ§¹ Nettoyage

**Objectif** : ArrÃªter les services du module.

**Commande** :

```bash
# ArrÃªter uniquement le module
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml down

# ArrÃªter tout (module + cluster Kafka)
./scripts/down.sh
```

---

## ğŸ“– Pour aller plus loin

### Exercices supplÃ©mentaires

1. **Modifiez les timeouts** dans `docker-compose.module.yml` et observez l'impact
2. **Injectez un timeout complet** avec Toxiproxy et observez les erreurs
3. **Testez avec diffÃ©rentes clÃ©s** et observez la distribution sur les partitions

### Ressources

- [Kafka Producer Configuration](https://kafka.apache.org/documentation/#producerconfigs)
- [Idempotent Producer](https://kafka.apache.org/documentation/#semantics)
- [Toxiproxy Documentation](https://github.com/Shopify/toxiproxy)

---

## ğŸ› ï¸ Tutorials pas-Ã -pas

| IDE | Tutorial | Description |
|-----|----------|-------------|
| **VS Code** | [TUTORIAL-DOTNET.md](./TUTORIAL-DOTNET.md) | Minimal API avec Confluent.Kafka |
| **Visual Studio 2022** | [TUTORIAL-VS2022.md](./TUTORIAL-VS2022.md) | Projet complet avec debugging, tests, Swagger |
| **IntelliJ / VS Code** | [TUTORIAL-JAVA.md](./TUTORIAL-JAVA.md) | Spring Boot avec kafka-clients |

---

## â¡ï¸ Module suivant

Une fois ce module terminÃ©, passez au :

ğŸ‘‰ **[Module 03 - Consumer Read-Committed](../module-03-consumer-read-committed/README.md)**
