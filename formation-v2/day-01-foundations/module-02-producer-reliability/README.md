# Module 02 - FiabilitÃ© du Producteur Kafka (Idempotence) - Formation Auto-rythmÃ©e

## DurÃ©e estimÃ©e

â±ï¸ **60-90 minutes**

## Objectifs pÃ©dagogiques

Ã€ la fin de ce module, vous serez capable de :

1. âœ… Comprendre la diffÃ©rence entre un producer **idempotent** et **non-idempotent**
2. âœ… MaÃ®triser l'envoi **synchrone** vs **asynchrone** et les callbacks
3. âœ… Configurer les **retries** et **timeouts** pour la fiabilitÃ©
4. âœ… Comprendre l'impact des **clÃ©s** sur le partitionnement
5. âœ… Utiliser **Toxiproxy** pour simuler des pannes rÃ©seau
6. âœ… Observer et dÃ©boguer les messages via **Kafka UI**
7. âœ… Comprendre la **log compaction** et son utilitÃ©

---

## ğŸ“– Partie ThÃ©orique Approfondie

### 1. Le Producteur Kafka en dÃ©tail

#### Cycle de vie d'un message

```mermaid
sequenceDiagram
    participant App as Application
    participant Prod as Producer
    participant Ser as Serializer
    participant Part as Partitioner
    participant Batch as RecordAccumulator
    participant Net as NetworkClient
    participant Broker as Kafka Broker
    
    App->>Prod: send(record)
    Prod->>Ser: serialize(key, value)
    Ser-->>Prod: byte[]
    Prod->>Part: partition(topic, key)
    Part-->>Prod: partition number
    Prod->>Batch: append to batch
    Note over Batch: Attend linger.ms ou batch.size
    Batch->>Net: send batch
    Net->>Broker: ProduceRequest
    Broker->>Broker: Write to log
    Broker->>Broker: Replicate
    Broker-->>Net: ProduceResponse (offset)
    Net-->>Prod: RecordMetadata
    Prod-->>App: Future/Callback
```

#### Composants internes du Producer

```mermaid
flowchart TB
    subgraph Producer["ğŸ“¤ Kafka Producer"]
        subgraph Config["Configuration"]
            BS["batch.size<br/>16KB"]
            LI["linger.ms<br/>0ms"]
            AC["acks<br/>all"]
            RE["retries<br/>âˆ"]
        end
        
        subgraph Pipeline["Pipeline d'envoi"]
            SER["ğŸ”„ Serializer<br/>Key + Value"]
            PAR["ğŸ“Š Partitioner<br/>Round-robin / Hash"]
            ACC["ğŸ“¦ RecordAccumulator<br/>Batching"]
            SND["ğŸŒ Sender Thread<br/>Network I/O"]
        end
        
        SER --> PAR --> ACC --> SND
    end
    
    SND -->|"ProduceRequest"| K["ğŸ“¦ Kafka Broker"]
    K -->|"ACK"| SND
```

---

### 2. Les Acknowledgments (ACKs)

#### Niveaux d'ACK

```mermaid
flowchart TB
    subgraph acks0["acks=0 (Fire & Forget)"]
        P0["Producer"] -->|"Envoie"| B0["Broker"]
        P0 -.->|"N'attend pas"| X0["âŒ"]
    end
    
    subgraph acks1["acks=1 (Leader Only)"]
        P1["Producer"] -->|"Envoie"| L1["Leader"]
        L1 -->|"ACK"| P1
        L1 -.->|"RÃ©plique aprÃ¨s"| F1["Follower"]
    end
    
    subgraph acksAll["acks=all (Toutes les ISR)"]
        P2["Producer"] -->|"Envoie"| L2["Leader"]
        L2 -->|"RÃ©plique"| F2["Follower 1"]
        L2 -->|"RÃ©plique"| F3["Follower 2"]
        F2 -->|"ACK"| L2
        F3 -->|"ACK"| L2
        L2 -->|"ACK"| P2
    end
    
    style acks0 fill:#ffebee
    style acks1 fill:#fff3e0
    style acksAll fill:#e8f5e9
```

#### Comparaison des modes ACK

| Mode | DurabilitÃ© | Performance | Risque de perte |
|------|------------|-------------|-----------------|
| `acks=0` | âŒ Aucune | âš¡âš¡âš¡ Maximale | Ã‰levÃ© |
| `acks=1` | âš ï¸ Partielle | âš¡âš¡ Bonne | Moyen |
| `acks=all` | âœ… ComplÃ¨te | âš¡ ModÃ©rÃ©e | Minimal |

---

### 3. L'Idempotence en profondeur

#### Le problÃ¨me des doublons

```mermaid
sequenceDiagram
    participant P as Producer
    participant B as Broker
    
    P->>B: Message "order-123"
    B->>B: Write OK
    B--xP: ACK perdu (rÃ©seau)
    Note over P: Timeout â†’ Retry
    P->>B: Message "order-123" (retry)
    B->>B: Write OK (DOUBLON !)
    B-->>P: ACK
    
    Note over B: âŒ 2 messages identiques
```

#### Solution : Producer Idempotent

```mermaid
sequenceDiagram
    participant P as Producer (PID=42)
    participant B as Broker
    
    P->>B: Message "order-123" (seq=0)
    B->>B: Write OK, store seq=0
    B--xP: ACK perdu
    Note over P: Timeout â†’ Retry
    P->>B: Message "order-123" (seq=0, retry)
    B->>B: Check: seq=0 dÃ©jÃ  vu â†’ SKIP
    B-->>P: ACK (avec offset original)
    
    Note over B: âœ… 1 seul message
```

#### MÃ©canisme interne

| Concept | Description |
|---------|-------------|
| **PID** (Producer ID) | Identifiant unique du producer (assignÃ© au dÃ©marrage) |
| **Epoch** | Version du producer (incrÃ©mentÃ© si redÃ©marrage) |
| **Sequence Number** | NumÃ©ro sÃ©quentiel par partition (0, 1, 2, ...) |

```
Message format avec idempotence:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PID: 42 â”‚ Epoch: 0 â”‚ SeqNum: 5 â”‚ Partition: 0  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                   Payload                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4. Retries et Gestion des erreurs

#### Timeline des retries

```mermaid
gantt
    title ScÃ©nario de retry avec succÃ¨s
    dateFormat X
    axisFormat %s
    
    section Request 1
    Envoi initial        :a1, 0, 1
    Attente ACK         :a2, 1, 2
    Timeout             :crit, a3, 2, 3
    
    section Retry 1
    Backoff (100ms)     :b1, 3, 4
    Retry               :b2, 4, 5
    Attente ACK         :b3, 5, 6
    Timeout             :crit, b4, 6, 7
    
    section Retry 2
    Backoff (200ms)     :c1, 7, 9
    Retry               :c2, 9, 10
    ACK reÃ§u            :done, c3, 10, 11
```

#### ParamÃ¨tres de retry

```mermaid
flowchart LR
    subgraph Timeouts["â±ï¸ Timeouts"]
        RT["request.timeout.ms<br/>30s"]
        DT["delivery.timeout.ms<br/>120s"]
    end
    
    subgraph Retries["ğŸ”„ Retries"]
        R["retries<br/>2147483647"]
        RB["retry.backoff.ms<br/>100ms"]
    end
    
    subgraph Constraint["âš ï¸ Contrainte"]
        C["delivery.timeout.ms â‰¥<br/>request.timeout.ms +<br/>linger.ms"]
    end
```

#### Erreurs rÃ©cupÃ©rables vs non-rÃ©cupÃ©rables

| Type | Exemples | Action |
|------|----------|--------|
| **RÃ©cupÃ©rable** | NetworkException, LeaderNotAvailable | Retry automatique |
| **Non-rÃ©cupÃ©rable** | InvalidTopicException, AuthorizationException | Ã‰chec immÃ©diat |
| **Fatal** | ProducerFenced, OutOfMemory | ArrÃªt du producer |

---

### 5. Synchrone vs Asynchrone

#### Mode Synchrone

```mermaid
sequenceDiagram
    participant C as Client HTTP
    participant A as API
    participant P as Producer
    participant K as Kafka
    
    C->>A: POST /send (sync)
    A->>P: send()
    P->>K: ProduceRequest
    K-->>P: ProduceResponse
    P-->>A: RecordMetadata
    A-->>C: 200 OK + offset
    
    Note over C,A: â±ï¸ Client bloquÃ© pendant l'envoi
```

#### Mode Asynchrone

```mermaid
sequenceDiagram
    participant C as Client HTTP
    participant A as API
    participant P as Producer
    participant K as Kafka
    participant S as StatusStore
    
    C->>A: POST /send (async)
    A->>P: send() + callback
    A->>S: Store requestId=PENDING
    A-->>C: 202 Accepted + requestId
    
    Note over C: Client libÃ©rÃ© immÃ©diatement
    
    P->>K: ProduceRequest
    K-->>P: ProduceResponse
    P->>S: Update requestId=OK
    
    C->>A: GET /status?requestId=...
    A->>S: Get status
    A-->>C: 200 OK + offset
```

#### Comparaison

| Aspect | Synchrone | Asynchrone |
|--------|-----------|------------|
| **Latence perÃ§ue** | Haute | Basse |
| **ComplexitÃ©** | Simple | Plus complexe |
| **Gestion d'erreur** | ImmÃ©diate | DiffÃ©rÃ©e (polling) |
| **DÃ©bit** | LimitÃ© | Ã‰levÃ© |
| **Cas d'usage** | APIs critiques | Haute performance |

---

### 6. Partitionnement et ClÃ©s

#### StratÃ©gies de partitionnement

```mermaid
flowchart TB
    subgraph NoKey["Sans clÃ© (Round-Robin)"]
        M1["Msg 1"] --> P0a["Partition 0"]
        M2["Msg 2"] --> P1a["Partition 1"]
        M3["Msg 3"] --> P2a["Partition 2"]
        M4["Msg 4"] --> P0a
    end
    
    subgraph WithKey["Avec clÃ© (Hash)"]
        K1["key=A"] --> Hash1["hash('A') % 3 = 1"]
        K2["key=B"] --> Hash2["hash('B') % 3 = 0"]
        K3["key=A"] --> Hash3["hash('A') % 3 = 1"]
        
        Hash1 --> P1b["Partition 1"]
        Hash2 --> P0b["Partition 0"]
        Hash3 --> P1b
    end
    
    style NoKey fill:#fff3e0
    style WithKey fill:#e8f5e9
```

#### Garantie d'ordre avec les clÃ©s

```
Topic: orders (3 partitions)

key="customer-42":
  Partition 1: [order-1] â†’ [order-2] â†’ [order-3] âœ… Ordre garanti

key="customer-99":
  Partition 0: [order-A] â†’ [order-B] â†’ [order-C] âœ… Ordre garanti

âš ï¸ Pas d'ordre garanti ENTRE les partitions
```

---

### 7. Log Compaction

#### Principe

```mermaid
flowchart LR
    subgraph Before["Avant Compaction"]
        B1["k1:v1"]
        B2["k2:v1"]
        B3["k1:v2"]
        B4["k3:v1"]
        B5["k1:v3"]
        B6["k2:v2"]
    end
    
    Compact["ğŸ”„ Compaction"]
    
    subgraph After["AprÃ¨s Compaction"]
        A1["k3:v1"]
        A2["k1:v3"]
        A3["k2:v2"]
    end
    
    Before --> Compact --> After
```

#### Cas d'usage

| ScÃ©nario | Exemple | ClÃ© | Valeur |
|----------|---------|-----|--------|
| **Ã‰tat utilisateur** | Profil client | userId | JSON profil |
| **Position GPS** | Flotte vÃ©hicules | vehicleId | lat/long |
| **Configuration** | Feature flags | featureName | enabled/disabled |
| **Inventaire** | Stock produits | productId | quantitÃ© |

---

### 8. Toxiproxy : Simulation de pannes

#### Architecture avec Toxiproxy

```mermaid
flowchart LR
    subgraph Normal["Mode Normal"]
        A1["API"] -->|"29092"| K1["Kafka"]
    end
    
    subgraph Proxy["Mode Proxy"]
        A2["API"] -->|"29093"| T["ğŸ’€ Toxiproxy"]
        T -->|"29092"| K2["Kafka"]
        
        subgraph Toxics["Effets injectables"]
            L["â±ï¸ Latency"]
            TO["â¹ï¸ Timeout"]
            BW["ğŸ“‰ Bandwidth"]
            SL["ğŸ”€ Slicer"]
        end
    end
    
    style T fill:#fff3e0
```

#### Types de pannes simulables

| Toxic | Effet | ParamÃ¨tres |
|-------|-------|------------|
| **latency** | Ajoute un dÃ©lai | `latency`, `jitter` |
| **timeout** | Coupe la connexion aprÃ¨s N ms | `timeout` |
| **bandwidth** | Limite le dÃ©bit | `rate` (KB/s) |
| **slicer** | Fragmente les paquets | `average_size`, `delay` |
| **slow_close** | Fermeture lente | `delay` |

```json
// Exemple : ajouter 5 secondes de latence
{
  "name": "latency",
  "type": "latency",
  "stream": "downstream",
  "attributes": {
    "latency": 5000,
    "jitter": 500
  }
}
```

---

## ğŸ—ï¸ Architecture du module

```mermaid
flowchart TB
    subgraph Client["Votre Machine"]
        curl["ğŸ–¥ï¸ curl / Postman"]
    end
    
    subgraph Docker["Docker Environment"]
        Java["â˜• Java API<br/>Port: 18080"]
        DotNet["ğŸ”· .NET API<br/>Port: 18081"]
        Toxi["ğŸ’€ Toxiproxy<br/>Port: 8474<br/>(tests de pannes)"]
        K["ğŸ“¦ Kafka Broker<br/>Port: 29092"]
        UI["ğŸ“Š Kafka UI<br/>Port: 8080"]
    end
    
    curl --> Java
    curl --> DotNet
    Java -->|"kafka:29092"| K
    DotNet -->|"kafka:29092"| K
    Toxi -.->|"proxy disponible<br/>sur :29093"| K
    K --> UI
    
    style Toxi fill:#fff3e0
    style K fill:#e8f5e8
```

> **Note** : Les APIs se connectent directement Ã  Kafka. Toxiproxy est disponible sur le port 29093 pour les tests d'injection de pannes manuels.

---

## ğŸ”Œ Ports et endpoints

### Services

| Service | Port | URL |
|---------|------|-----|
| Java API | 18080 | http://localhost:18080 |
| .NET API | 18081 | http://localhost:18081 |
| Toxiproxy | 8474 | http://localhost:8474 |
| Kafka UI | 8080 | http://localhost:8080 |

### Endpoints des APIs

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/health` | Health check |
| POST | `/api/v1/send` | Envoyer un message |
| GET | `/api/v1/status` | Statut d'un envoi async |

### ParamÃ¨tres de `/api/v1/send`

| ParamÃ¨tre | Valeurs | Description |
|-----------|---------|-------------|
| `mode` | `plain`, `idempotent` | Mode du producer |
| `sendMode` | `sync`, `async` | Synchrone ou asynchrone |
| `eventId` | string | Identifiant unique du message |
| `key` | string (optionnel) | ClÃ© de partitionnement |
| `partition` | int (optionnel) | Partition cible |

---

## ğŸ“‹ PrÃ©-requis

### Logiciels

- âœ… Docker + Docker Compose
- âœ… curl (ligne de commande)
- âœ… Navigateur web

### Cluster Kafka dÃ©marrÃ©

```bash
cd formation-v2/
./scripts/up.sh   # Mode single-node par dÃ©faut
# ou: ./scripts/up.sh cluster   # Mode cluster 3 brokers
```

**VÃ©rification** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}' | grep kafka
```

**RÃ©sultat attendu** : `kafka` et `kafka-ui` sont `Up (healthy)`.

---

## ğŸ“š Lab 02.0 - DÃ©marrage du module

### Objectif

DÃ©marrer les services du module (APIs Java/.NET + Toxiproxy) et vÃ©rifier leur bon fonctionnement.

---

### Ã‰tape 1 - Positionnement

**Objectif** : Se placer dans le bon rÃ©pertoire.

```bash
cd formation-v2/
```

---

### Ã‰tape 2 - DÃ©marrage des services

**Objectif** : Lancer les conteneurs du module.

**Explication** : Cette commande lance :
- **Toxiproxy** : Proxy rÃ©seau pour injecter des pannes
- **toxiproxy-init** : Configuration initiale du proxy (one-shot)
- **m02-java-api** : API Spring Boot (Java)
- **m02-dotnet-api** : API ASP.NET (.NET)

**Commande** :

```bash
# Si le cluster Kafka est dÃ©jÃ  dÃ©marrÃ© via ./scripts/up.sh :
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml up -d --build
```

**â±ï¸ Temps d'attente** : 2-3 minutes (build des images Java/.NET).

**RÃ©sultat attendu** :

```
[+] Running 4/4
 âœ” Container toxiproxy        Healthy
 âœ” Container toxiproxy-init   Started
 âœ” Container m02-java-api     Started
 âœ” Container m02-dotnet-api   Started
```

---

### Ã‰tape 3 - VÃ©rification des conteneurs

**Objectif** : S'assurer que tous les services sont opÃ©rationnels.

**Commande** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'
```

**RÃ©sultat attendu** :

| Conteneur | Statut attendu |
|-----------|----------------|
| kafka | Up (healthy) |
| kafka-ui | Up (healthy) |
| toxiproxy | Up |
| toxiproxy-init | Exited (0) âœ… normal |
| m02-java-api | Up |
| m02-dotnet-api | Up |

---

### Ã‰tape 4 - Test de santÃ© des APIs

**Objectif** : VÃ©rifier que les APIs rÃ©pondent.

**Commandes** :

```bash
# Test Java API
curl -fsS http://localhost:18080/health
# RÃ©sultat attendu: OK

# Test .NET API
curl -fsS http://localhost:18081/health
# RÃ©sultat attendu: OK
```

**âœ… Checkpoint 02.0** : Les deux APIs rÃ©pondent `OK`.

---

## ğŸ“š Lab 02.1 - Envoi synchrone (baseline)

### Objectif

Envoyer un message en mode **synchrone** et comprendre la rÃ©ponse avec l'offset.

---

### Ã‰tape 5 - Envoi d'un message synchrone (Java API)

**Objectif** : Envoyer un message et recevoir l'ACK Kafka.

**ThÃ©orie** : En mode **synchrone**, l'API attend la confirmation de Kafka avant de rÃ©pondre. La rÃ©ponse contient :
- Le **topic** de destination
- La **partition** utilisÃ©e
- L'**offset** du message

**Commande** :

```bash
# GÃ©nÃ©rer un ID unique
EVENT_ID="JAVA-SYNC-$(date +%s)"
echo "EventId: $EVENT_ID"

# Envoyer le message
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**RÃ©sultat attendu** :

```json
{
  "status": "OK",
  "topic": "bhf-transactions",
  "partition": 0,
  "offset": 5,
  "eventId": "JAVA-SYNC-1706400000"
}
```

**Explication de la rÃ©ponse** :

| Champ | Description |
|-------|-------------|
| `status` | OK = message Ã©crit avec succÃ¨s |
| `topic` | Topic de destination |
| `partition` | Partition oÃ¹ le message est stockÃ© |
| `offset` | Position du message dans la partition |
| `eventId` | Identifiant unique envoyÃ© |

---

### Ã‰tape 6 - Envoi avec l'API .NET

**Objectif** : VÃ©rifier que l'API .NET fonctionne de la mÃªme maniÃ¨re.

**Commande** :

```bash
EVENT_ID="DOTNET-SYNC-$(date +%s)"
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**âœ… Checkpoint 02.1** : Les deux APIs retournent un JSON avec `partition` et `offset`.

---

### Ã‰tape 7 - Visualisation dans Kafka UI

**Objectif** : Observer les messages envoyÃ©s.

**Actions** :

1. Ouvrez **http://localhost:8080**
2. Cliquez sur le cluster **BHF-Training**
3. Menu **Topics** â†’ **bhf-transactions**
4. Onglet **Messages** â†’ **Fetch Messages**

**Ce que vous devez voir** :
- Vos messages avec les `eventId` envoyÃ©s
- La partition et l'offset de chaque message
- Le timestamp d'envoi

---

## ğŸ“š Lab 02.2 - Envoi asynchrone et callbacks

### Objectif

Comprendre le mode **asynchrone** et comment rÃ©cupÃ©rer le statut via polling.

---

### Ã‰tape 8 - Envoi asynchrone (Java)

**Objectif** : Envoyer un message sans attendre l'ACK.

**ThÃ©orie** : En mode **asynchrone** :
1. L'API retourne immÃ©diatement un `requestId`
2. Le message est envoyÃ© en arriÃ¨re-plan
3. Vous consultez le statut via `/api/v1/status`

**Commande** :

```bash
EVENT_ID="JAVA-ASYNC-$(date +%s)"

# Envoyer en asynchrone
RESPONSE=$(curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=idempotent&sendMode=async&eventId=$EVENT_ID")
echo "RÃ©ponse: $RESPONSE"

# Extraire le requestId
REQ_ID=$(echo "$RESPONSE" | sed -n 's/.*"requestId":"\([^"]*\)".*/\1/p')
echo "RequestId: $REQ_ID"
```

**RÃ©sultat attendu** :

```json
{
  "status": "ACCEPTED",
  "requestId": "abc123-def456",
  "eventId": "JAVA-ASYNC-1706400000"
}
```

---

### Ã‰tape 9 - Consultation du statut

**Objectif** : RÃ©cupÃ©rer le rÃ©sultat de l'envoi asynchrone.

**Commande** :

```bash
# Attendre 2 secondes pour que l'envoi se termine
sleep 2

# Consulter le statut
curl -fsS "http://localhost:18080/api/v1/status?requestId=$REQ_ID"
```

**RÃ©sultat attendu (succÃ¨s)** :

```json
{
  "state": "OK",
  "topic": "bhf-transactions",
  "partition": 1,
  "offset": 10
}
```

**RÃ©sultat possible (en cours)** :

```json
{
  "state": "PENDING"
}
```

**âœ… Checkpoint 02.2** : Vous savez envoyer en asynchrone et rÃ©cupÃ©rer le statut.

---

## ğŸ“š Lab 02.3 - Injection de pannes avec Toxiproxy

### Objectif

Simuler des problÃ¨mes rÃ©seau pour observer le comportement des retries.

---

### Ã‰tape 10 - VÃ©rification du proxy Toxiproxy

**Objectif** : Confirmer que le proxy Kafka est configurÃ©.

**Commande** :

```bash
curl -fsS http://localhost:8474/proxies | python3 -m json.tool
```

**RÃ©sultat attendu** : Un proxy nommÃ© `kafka` avec :
- `listen`: `0.0.0.0:29093`
- `upstream`: `kafka:29092`

---

### Ã‰tape 11 - Injection de latence

**Objectif** : Ajouter 5 secondes de latence sur les rÃ©ponses Kafka.

**ThÃ©orie** : La latence peut provoquer des **timeouts** cÃ´tÃ© producer, ce qui dÃ©clenche des **retries**.

**Commande pour ajouter la latence** :

```bash
curl -fsS -H 'Content-Type: application/json' \
  -X POST http://localhost:8474/proxies/kafka/toxics \
  -d '{
    "name": "latency",
    "type": "latency",
    "stream": "downstream",
    "attributes": {
      "latency": 5000,
      "jitter": 0
    }
  }'
```

**VÃ©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
```

---

### Ã‰tape 12 - Test avec latence

**Objectif** : Observer le comportement avec la latence.

**Commande** :

```bash
EVENT_ID="LATENCY-TEST-$(date +%s)"
time curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=$EVENT_ID"
```

**Observation** : La requÃªte prend ~5 secondes de plus que d'habitude.

---

### Ã‰tape 13 - Suppression de la latence

**Objectif** : Retirer la latence pour continuer les tests.

**Commande** :

```bash
curl -fsS -X DELETE http://localhost:8474/proxies/kafka/toxics/latency
```

**VÃ©rification** :

```bash
curl -fsS http://localhost:8474/proxies/kafka/toxics
# RÃ©sultat: [] (liste vide)
```

---

## ğŸ“š Lab 02.4 - Idempotence vs Plain (test clÃ©)

### Objectif

Prouver que l'idempotence Ã©vite les doublons lors des retries.

---

### Ã‰tape 14 - ExÃ©cution du test automatisÃ©

**Objectif** : Valider le comportement idempotent vs non-idempotent.

**Explication** : Le script `validate.sh` :
1. Injecte de la latence via Toxiproxy
2. Envoie des messages en mode `plain` et `idempotent`
3. Compte les messages dans Kafka
4. VÃ©rifie que `idempotent` = 1 message exactement

**Commande** :

```bash
./day-01-foundations/module-02-producer-reliability/scripts/validate.sh
```

**RÃ©sultat attendu** :

```
OK: java_idempotent=1 java_plain=1 dotnet_idempotent=1 dotnet_plain=1
```

**Note** : Si `java_plain` ou `dotnet_plain` > 1, c'est normal ! Cela prouve que les retries peuvent crÃ©er des doublons sans idempotence.

**âœ… Checkpoint 02.4** : L'idempotence produit exactement 1 message.

---

## ğŸ“š Lab 02.5 - Partitionnement

### Objectif

Comprendre comment les clÃ©s influencent le partitionnement.

---

### Ã‰tape 15 - Envoi sur des partitions diffÃ©rentes

**Objectif** : Envoyer des messages sur des partitions spÃ©cifiques.

**Commandes** :

```bash
# Message sur partition 0
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P0-$(date +%s)&partition=0"

# Message sur partition 1
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P1-$(date +%s)&partition=1"

# Message sur partition 2
curl -fsS -X POST "http://localhost:18080/api/v1/send?mode=plain&sendMode=sync&eventId=P2-$(date +%s)&partition=2"
```

---

### Ã‰tape 16 - VÃ©rification des partitions

**Objectif** : Confirmer la distribution des messages.

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic bhf-transactions \
  --from-beginning \
  --timeout-ms 5000 \
  --property print.partition=true \
  --property print.offset=true
```

**RÃ©sultat attendu** : Messages sur diffÃ©rentes partitions (0, 1, 2).

---

## ğŸ“š Lab 02.6 - Log compaction

### Objectif

Comprendre la compaction et son utilitÃ© pour les Ã©tats.

---

### Ã‰tape 17 - CrÃ©ation d'un topic compactÃ©

**Objectif** : CrÃ©er un topic avec la politique de compaction.

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --if-not-exists \
  --topic bhf-compact-demo \
  --partitions 1 \
  --replication-factor 1 \
  --config cleanup.policy=compact \
  --config segment.ms=1000 \
  --config min.cleanable.dirty.ratio=0.01
```

---

### Ã‰tape 18 - Envoi de plusieurs versions

**Objectif** : Envoyer plusieurs valeurs pour la mÃªme clÃ©.

**Commande** :

```bash
KEY="customer-42"

# Version 1
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V1&key=$KEY"

# Version 2
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V2&key=$KEY"

# Version 3 (finale)
curl -fsS -X POST "http://localhost:18081/api/v1/send?mode=plain&sendMode=sync&topic=bhf-compact-demo&eventId=V3&key=$KEY"
```

**Note** : AprÃ¨s compaction (asynchrone), seul `V3` sera conservÃ© pour `customer-42`.

**âœ… Checkpoint 02.6** : Vous comprenez la log compaction.

---

## âœ… RÃ©capitulatif des checkpoints

| # | Checkpoint | Statut |
|---|------------|--------|
| 02.0 | APIs Java et .NET rÃ©pondent OK | â˜ |
| 02.1 | Envoi synchrone retourne partition/offset | â˜ |
| 02.2 | Envoi asynchrone + rÃ©cupÃ©ration du statut | â˜ |
| 02.3 | Injection de latence via Toxiproxy | â˜ |
| 02.4 | Script validate.sh retourne OK | â˜ |
| 02.5 | Messages sur diffÃ©rentes partitions | â˜ |
| 02.6 | ComprÃ©hension de la log compaction | â˜ |

---

## ğŸ”§ Troubleshooting

### APIs ne dÃ©marrent pas

**SymptÃ´me** : `m02-java-api` ou `m02-dotnet-api` en erreur.

**Solution** :

```bash
# VÃ©rifier les logs
docker logs m02-java-api --tail 100
docker logs m02-dotnet-api --tail 100

# Reconstruire les images
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml \
  up -d --build --force-recreate
```

### Toxiproxy ne rÃ©pond pas

**SymptÃ´me** : `curl: (7) Failed to connect to localhost port 8474`.

**Solution** :

```bash
# VÃ©rifier les logs
docker logs toxiproxy

# VÃ©rifier le healthcheck
docker inspect toxiproxy --format='{{.State.Health.Status}}'

# RedÃ©marrer si nÃ©cessaire
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml restart toxiproxy

# RecrÃ©er le proxy aprÃ¨s redÃ©marrage
curl -fsS -X POST http://localhost:8474/proxies \
  -H 'Content-Type: application/json' \
  -d '{"name":"kafka","listen":"0.0.0.0:29093","upstream":"kafka:29092"}'
```

### Messages non visibles dans Kafka UI

**SymptÃ´me** : Le topic existe mais pas de messages.

**Solution** :

1. Cliquez sur **Fetch Messages**
2. RÃ©glez le filtre sur **Earliest** (depuis le dÃ©but)
3. VÃ©rifiez le bon topic (`bhf-transactions`)

---

## ğŸ§¹ Nettoyage

**Objectif** : ArrÃªter les services du module.

**Commande** :

```bash
# ArrÃªter uniquement le module
docker compose -f day-01-foundations/module-02-producer-reliability/docker-compose.module.yml down

# ArrÃªter tout (module + cluster Kafka)
./scripts/down.sh
```

---

## ğŸ“– Pour aller plus loin

### Exercices supplÃ©mentaires

1. **Modifiez les timeouts** dans `docker-compose.module.yml` et observez l'impact
2. **Injectez un timeout complet** avec Toxiproxy et observez les erreurs
3. **Testez avec diffÃ©rentes clÃ©s** et observez la distribution sur les partitions

### Ressources

- [Kafka Producer Configuration](https://kafka.apache.org/documentation/#producerconfigs)
- [Idempotent Producer](https://kafka.apache.org/documentation/#semantics)
- [Toxiproxy Documentation](https://github.com/Shopify/toxiproxy)

---

## ğŸ› ï¸ Tutorials pas-Ã -pas

| IDE | Tutorial | Description |
|-----|----------|-------------|
| **VS Code** | [TUTORIAL-DOTNET.md](./TUTORIAL-DOTNET.md) | Minimal API avec Confluent.Kafka |
| **Visual Studio 2022** | [TUTORIAL-VS2022.md](./TUTORIAL-VS2022.md) | Projet complet avec debugging, tests, Swagger |
| **IntelliJ / VS Code** | [TUTORIAL-JAVA.md](./TUTORIAL-JAVA.md) | Spring Boot avec kafka-clients |

---

## â¡ï¸ Module suivant

Une fois ce module terminÃ©, passez au :

ğŸ‘‰ **[Module 03 - Consumer Read-Committed](../module-03-consumer-read-committed/README.md)**
