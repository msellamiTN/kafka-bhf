# Module 01 - Architecture du Cluster Kafka (KRaft) - Formation Auto-rythm√©e

## Dur√©e estim√©e

‚è±Ô∏è **30-45 minutes**

## Objectifs p√©dagogiques

√Ä la fin de ce module, vous serez capable de :

1. ‚úÖ Comprendre l'architecture d'un cluster Kafka avec KRaft (sans ZooKeeper)
2. ‚úÖ D√©marrer et arr√™ter un cluster Kafka local via Docker Compose
3. ‚úÖ V√©rifier l'√©tat de sant√© du cluster
4. ‚úÖ Cr√©er un topic avec plusieurs partitions
5. ‚úÖ Produire et consommer des messages via la ligne de commande
6. ‚úÖ Naviguer dans Kafka UI pour visualiser les messages

---

## üìñ Partie Th√©orique

### 1. Qu'est-ce que Apache Kafka ?

**Apache Kafka** est une plateforme de streaming distribu√©e open-source, initialement d√©velopp√©e par LinkedIn et maintenant maintenue par la Apache Software Foundation.

#### Cas d'usage principaux

```mermaid
mindmap
  root((Apache Kafka))
    Messaging
      File d'attente de messages
      Pub/Sub
      D√©couplage des syst√®mes
    Streaming
      Traitement temps r√©el
      ETL en continu
      Agr√©gation de donn√©es
    Stockage
      Log distribu√©
      Event Sourcing
      Audit trail
    Int√©gration
      Microservices
      CDC (Change Data Capture)
      Data Pipeline
```

#### Caract√©ristiques cl√©s

| Caract√©ristique | Description |
|-----------------|-------------|
| **Haute performance** | Millions de messages/seconde avec latence < 10ms |
| **Scalabilit√© horizontale** | Ajout de brokers sans interruption |
| **Durabilit√©** | Messages persist√©s sur disque, r√©pliqu√©s |
| **Tol√©rance aux pannes** | R√©plication automatique, failover |
| **Ordre garanti** | Au sein d'une partition |

---

### 2. Architecture de Kafka

#### Vue d'ensemble

```mermaid
flowchart TB
    subgraph Producers["üì§ Producers"]
        P1["Application A"]
        P2["Application B"]
        P3["Service C"]
    end
    
    subgraph Cluster["üî∑ Kafka Cluster"]
        subgraph B1["Broker 1"]
            T1P0["Topic1-P0<br/>Leader"]
            T1P1["Topic1-P1<br/>Follower"]
        end
        subgraph B2["Broker 2"]
            T1P0F["Topic1-P0<br/>Follower"]
            T1P1L["Topic1-P1<br/>Leader"]
        end
        subgraph B3["Broker 3"]
            T1P2["Topic1-P2<br/>Leader"]
        end
    end
    
    subgraph Consumers["üì• Consumers"]
        CG1["Consumer Group A"]
        CG2["Consumer Group B"]
    end
    
    P1 --> B1
    P2 --> B2
    P3 --> B3
    
    B1 --> CG1
    B2 --> CG1
    B3 --> CG2
    
    style Cluster fill:#e8f5e8
```

#### Composants fondamentaux

| Composant | Ic√¥ne | Description |
|-----------|-------|-------------|
| **Broker** | üñ•Ô∏è | Serveur Kafka qui stocke les messages et sert les clients |
| **Topic** | üìÅ | Cat√©gorie logique pour organiser les messages |
| **Partition** | üìä | Subdivision d'un topic pour la parall√©lisation |
| **Producer** | üì§ | Application qui envoie des messages |
| **Consumer** | üì• | Application qui lit des messages |
| **Consumer Group** | üë• | Ensemble de consumers qui se partagent la lecture |

---

### 3. Topics et Partitions

#### Concept de Topic

Un **Topic** est un flux de messages nomm√©. C'est la cat√©gorie dans laquelle les messages sont publi√©s.

```mermaid
flowchart LR
    subgraph Topic["üìÅ Topic: orders"]
        P0["Partition 0<br/>‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"]
        P1["Partition 1<br/>‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"]
        P2["Partition 2<br/>‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"]
    end
    
    Producer["üì§ Producer"] --> Topic
    Topic --> Consumer["üì• Consumer"]
```

#### Anatomie d'une Partition

Une **Partition** est un log ordonn√© et immuable de messages :

```
Partition 0:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  0  ‚îÇ  1  ‚îÇ  2  ‚îÇ  3  ‚îÇ  4  ‚îÇ  5  ‚îÇ  6  ‚îÇ  7  ‚îÇ  ‚Üê Offsets
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ Msg ‚îÇ  ‚Üê Messages
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚Üë
                                         Nouveaux messages
                                         (append-only)
```

#### Pourquoi plusieurs partitions ?

```mermaid
flowchart TB
    subgraph Single["‚ùå 1 Partition = Goulot d'√©tranglement"]
        S1["Consumer 1"] --> SP["Partition 0"]
        S2["Consumer 2"] -.->|"attend"| SP
        S3["Consumer 3"] -.->|"attend"| SP
    end
    
    subgraph Multi["‚úÖ 3 Partitions = Parall√©lisme"]
        M1["Consumer 1"] --> MP0["Partition 0"]
        M2["Consumer 2"] --> MP1["Partition 1"]
        M3["Consumer 3"] --> MP2["Partition 2"]
    end
```

| Nombre de partitions | Avantages | Inconv√©nients |
|----------------------|-----------|---------------|
| **1** | Ordre global garanti | Pas de parall√©lisme |
| **3-10** | Bon √©quilibre | Standard pour la plupart des cas |
| **100+** | Tr√®s haut d√©bit | Plus de ressources, latence accrue |

---

### 4. Offsets et Consommation

#### Qu'est-ce qu'un Offset ?

L'**Offset** est la position unique d'un message dans une partition. C'est un entier croissant.

```mermaid
flowchart LR
    subgraph Partition["Partition 0"]
        O0["Offset 0<br/>Message A"]
        O1["Offset 1<br/>Message B"]
        O2["Offset 2<br/>Message C"]
        O3["Offset 3<br/>Message D"]
        O4["Offset 4<br/>Message E"]
    end
    
    O0 --> O1 --> O2 --> O3 --> O4
    
    Consumer["üì• Consumer<br/>Position: Offset 3"]
    Consumer -.->|"Lit"| O3
```

#### Gestion des Offsets

| Mode | Description | Cas d'usage |
|------|-------------|-------------|
| **Earliest** | Lire depuis le d√©but | Retraitement complet |
| **Latest** | Lire les nouveaux messages uniquement | Temps r√©el |
| **Specific** | Lire depuis un offset pr√©cis | Reprise apr√®s erreur |

---

### 5. Mode KRaft vs ZooKeeper

#### √âvolution de l'architecture

```mermaid
timeline
    title √âvolution de Kafka
    2011 : Kafka cr√©√© par LinkedIn avec ZooKeeper
    2017 : KIP-500 propos√© (suppression ZooKeeper)
    2022 : KRaft en production (Kafka 3.3)
    2024 : ZooKeeper d√©pr√©ci√© (Kafka 4.0)
```

#### Comparaison

```mermaid
flowchart TB
    subgraph Old["‚ùå Ancienne Architecture (ZooKeeper)"]
        ZK["üî∑ ZooKeeper<br/>Coordination"]
        KB1["Kafka Broker 1"]
        KB2["Kafka Broker 2"]
        KB3["Kafka Broker 3"]
        
        ZK <--> KB1
        ZK <--> KB2
        ZK <--> KB3
    end
    
    subgraph New["‚úÖ Nouvelle Architecture (KRaft)"]
        KC1["Kafka 1<br/>Broker + Controller"]
        KC2["Kafka 2<br/>Broker + Controller"]
        KC3["Kafka 3<br/>Broker + Controller"]
        
        KC1 <-->|"Raft"| KC2
        KC2 <-->|"Raft"| KC3
        KC3 <-->|"Raft"| KC1
    end
```

| Aspect | ZooKeeper | KRaft |
|--------|-----------|-------|
| **Composants** | Kafka + ZooKeeper | Kafka seul |
| **Complexit√©** | √âlev√©e | R√©duite |
| **Performances** | Bonnes | Meilleures |
| **Scalabilit√©** | Limit√©e par ZK | Am√©lior√©e |
| **D√©marrage** | Lent | Rapide |

---

### 6. Producer et Consumer

#### Le Producer

```mermaid
sequenceDiagram
    participant App as Application
    participant P as Producer
    participant K as Kafka Broker
    
    App->>P: send(topic, message)
    P->>P: S√©rialisation
    P->>P: Partitionnement
    P->>K: Envoi au leader
    K->>K: √âcriture sur disque
    K->>K: R√©plication
    K-->>P: ACK (acknowledgment)
    P-->>App: Confirmation
```

#### Le Consumer

```mermaid
sequenceDiagram
    participant C as Consumer
    participant K as Kafka Broker
    participant App as Application
    
    C->>K: subscribe(topic)
    loop Polling
        C->>K: poll()
        K-->>C: Messages (batch)
        C->>App: Traitement
        C->>K: commit(offset)
    end
```

---

### 7. Diagramme d'architecture du Lab

#### Option A : Docker (D√©veloppement local)

```mermaid
flowchart TB
    subgraph Docker["üê≥ Docker Environment"]
        subgraph KafkaContainer["Container: kafka"]
            KB["Apache Kafka<br/>Mode: KRaft<br/>Image: apache/kafka:latest"]
            KData[("üìÅ Volume<br/>kafka-data")]
        end
        
        subgraph UIContainer["Container: kafka-ui"]
            UI["Kafka UI<br/>Image: provectuslabs/kafka-ui"]
        end
        
        Network["üåê Network: bhf-kafka-network"]
    end
    
    subgraph Host["üíª Votre Machine"]
        Terminal["üñ•Ô∏è Terminal<br/>kafka-console-*"]
        Browser["üåê Navigateur"]
    end
    
    Terminal -->|"Port 9092"| KB
    Browser -->|"Port 8080"| UI
    UI -->|"Port 29092<br/>(interne)"| KB
    KB --> KData
    
    KB --- Network
    UI --- Network
    
    style Docker fill:#e3f2fd
    style KafkaContainer fill:#e8f5e8
    style UIContainer fill:#fff3e0
```

#### Option B : OKD/K3s (Production-like)

```mermaid
flowchart TB
    subgraph K8s["‚ò∏Ô∏è Kubernetes (K3s/OKD)"]
        subgraph KafkaNS["Namespace: kafka"]
            subgraph Strimzi["Strimzi Operator"]
                SO["üîß Cluster Operator"]
            end
            
            subgraph KafkaCluster["Kafka Cluster: bhf-kafka"]
                B0["Broker 0"]
                B1["Broker 1"]
                B2["Broker 2"]
                C0["Controller 0"]
                C1["Controller 1"]
                C2["Controller 2"]
            end
            
            subgraph Services["Services"]
                Bootstrap["bootstrap:9092"]
                External["NodePort:32092"]
            end
            
            KUI["Kafka UI<br/>NodePort:30808"]
        end
    end
    
    subgraph Host["üíª Votre Machine"]
        Kubectl["üñ•Ô∏è kubectl"]
        Browser["üåê Navigateur"]
    end
    
    SO -->|"manages"| KafkaCluster
    Kubectl -->|"NodePort 32092"| External
    Browser -->|"NodePort 30808"| KUI
    KUI --> Bootstrap
    Bootstrap --> B0 & B1 & B2
    
    style K8s fill:#e8f5e8
    style KafkaNS fill:#e3f2fd
    style Strimzi fill:#fff3e0
```

## Ports et URLs

### üê≥ Mode Docker

| Service | Port | URL |
|---------|------|-----|
| Kafka (externe) | 9092 | `localhost:9092` |
| Kafka (interne Docker) | 29092 | `kafka:29092` |
| Kafka UI | 8080 | http://localhost:8080 |

### ‚ò∏Ô∏è Mode OKD/K3s

| Service | Port | URL |
|---------|------|-----|
| Kafka Bootstrap (interne) | 9092 | `bhf-kafka-kafka-bootstrap.kafka.svc:9092` |
| Kafka Bootstrap (externe) | 32092 | `<NODE_IP>:32092` |
| Kafka UI | 30808 | http://<NODE_IP>:30808 |

## Pr√©-requis

### üê≥ Mode Docker (D√©veloppement local)

- ‚úÖ **Docker Desktop** ou **Docker Engine** (version 20.10+)
- ‚úÖ **Docker Compose** plugin (`docker compose` - pas `docker-compose`)
- ‚úÖ **Terminal** (Bash, PowerShell, ou autre)
- ‚úÖ **Navigateur web** (Chrome, Firefox, Edge)

```bash
# V√©rifier Docker
docker --version
# Attendu: Docker version 20.10+ ou sup√©rieur

# V√©rifier Docker Compose
docker compose version
# Attendu: Docker Compose version v2.x.x
```

### ‚ò∏Ô∏è Mode OKD/K3s (Production-like)

- ‚úÖ **K3s** ou **OKD/OpenShift** install√©
- ‚úÖ **kubectl** configur√©
- ‚úÖ **Strimzi Operator** d√©ploy√©
- ‚úÖ **Kafka cluster** d√©ploy√© via Strimzi
- ‚úÖ **Terminal** (Bash, PowerShell, ou autre)
- ‚úÖ **Navigateur web** (Chrome, Firefox, Edge)

```bash
# V√©rifier kubectl
kubectl version --client
# Attendu: Client Version: v1.28+ ou sup√©rieur

# V√©rifier le cluster
kubectl get nodes
# Attendu: Au moins 1 node en status Ready

# V√©rifier Kafka
kubectl get kafka -n kafka
# Attendu: bhf-kafka avec status Ready
```

> üìñ **Installation K3s + Kafka** : Voir [Guide d'installation OKD/K3s](../../00-overview/INSTALL-OKD-UBUNTU.md) et les scripts dans `infra/Scripts/`

---

## üìö Guide pas √† pas

### √âtape 0 - Positionnement dans le r√©pertoire

**Objectif** : Se placer dans le bon r√©pertoire de travail.

```bash
cd formation-v2/
```

**V√©rification** :

```bash
ls -la scripts/
```

**R√©sultat attendu** : Vous devez voir les fichiers `up.sh`, `down.sh`, `start.sh`, `stop.sh`.

---

### √âtape 1 - D√©marrage du cluster Kafka

**Objectif** : Lancer le cluster Kafka en mode KRaft avec Kafka UI.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Explication** : Le script `up.sh` va :
1. T√©l√©charger l'image `apache/kafka:latest` (si n√©cessaire)
2. Cr√©er le r√©seau Docker `bhf-kafka-network`
3. D√©marrer le conteneur Kafka en mode KRaft
4. D√©marrer Kafka UI pour la visualisation

**Commande** :

```bash
./scripts/up.sh
```

**R√©sultat attendu** :

```
Starting Kafka KRaft SINGLE NODE...
Checking for existing containers...
[+] Running 3/3
 ‚úî Network bhf-kafka-network  Created
 ‚úî Container kafka            Started
 ‚úî Container kafka-ui         Started
‚úÖ Kafka KRaft single-node is ready!
Kafka UI: http://localhost:8080
```

**‚è±Ô∏è Temps d'attente** : 30-60 secondes pour le premier d√©marrage.

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Explication** : Le cluster Kafka est d√©j√† d√©ploy√© via Strimzi. V√©rifiez son √©tat :

**Commande** :

```bash
# V√©rifier que le cluster Kafka est pr√™t
kubectl get kafka -n kafka

# V√©rifier les pods Kafka
kubectl get pods -n kafka
```

**R√©sultat attendu** :

```
NAME        CLUSTER     READY   WARNINGS
bhf-kafka   bhf-kafka   True    

NAME                                         READY   STATUS
bhf-kafka-broker-0                           1/1     Running
bhf-kafka-broker-1                           1/1     Running
bhf-kafka-broker-2                           1/1     Running
bhf-kafka-controller-3                       1/1     Running
bhf-kafka-controller-4                       1/1     Running
bhf-kafka-controller-5                       1/1     Running
bhf-kafka-entity-operator-xxxx               2/2     Running
kafka-ui-xxxx                                1/1     Running
strimzi-cluster-operator-xxxx                1/1     Running
```

> üìù **Note** : Si le cluster n'est pas d√©ploy√©, ex√©cutez `sudo ./infra/Scripts/03-install-kafka.sh`

</details>

**üí° Astuce** : Si vous voyez des erreurs, attendez 30 secondes et passez √† l'√©tape suivante pour v√©rifier l'√©tat.

---

### √âtape 2 - V√©rification de l'√©tat du cluster

**Objectif** : S'assurer que tous les composants sont en fonctionnement.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'
```

**R√©sultat attendu** :

```
NAMES       STATUS                   PORTS
kafka-ui    Up X minutes (healthy)   0.0.0.0:8080->8080/tcp
kafka       Up X minutes (healthy)   0.0.0.0:9092->9092/tcp, 0.0.0.0:29092->29092/tcp
```

**‚úÖ Checkpoint 1** : Les deux conteneurs affichent `(healthy)`.

**‚ö†Ô∏è Si "unhealthy" ou "starting"** : Attendez 30 secondes suppl√©mentaires et relancez la commande.

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
# V√©rifier l'√©tat du cluster Kafka
kubectl get kafka bhf-kafka -n kafka

# V√©rifier les pods
kubectl get pods -n kafka -l strimzi.io/cluster=bhf-kafka

# V√©rifier les services
kubectl get svc -n kafka
```

**R√©sultat attendu** :

```
NAME        CLUSTER     READY   WARNINGS
bhf-kafka   bhf-kafka   True    

NAME                        TYPE        CLUSTER-IP      PORT(S)
bhf-kafka-kafka-bootstrap   ClusterIP   10.43.x.x       9091/TCP,9092/TCP,9093/TCP
bhf-kafka-kafka-brokers     ClusterIP   None            9090/TCP,9091/TCP,9092/TCP
bhf-kafka-kafka-external    NodePort    10.43.x.x       9094:32092/TCP
```

**‚úÖ Checkpoint 1** : Le cluster affiche `READY: True` et les pods sont `Running`.

</details>

---

### √âtape 3 - Acc√®s √† Kafka UI

**Objectif** : V√©rifier que l'interface web est accessible.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Action** : Ouvrez votre navigateur et acc√©dez √† :

üëâ **http://localhost:8080**

**Ce que vous devez voir** :

1. Page d'accueil de Kafka UI
2. Cluster nomm√© `BHF-Training` dans la liste
3. Statut du cluster : **Online**

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Action** : R√©cup√©rez l'IP du node et acc√©dez √† Kafka UI :

```bash
# R√©cup√©rer l'IP du node
NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')
echo "Kafka UI: http://$NODE_IP:30808"
```

üëâ **http://<NODE_IP>:30808**

**Ce que vous devez voir** :

1. Page d'accueil de Kafka UI
2. Cluster nomm√© `bhf-kafka` dans la liste
3. Statut du cluster : **Online**

</details>

**Navigation dans Kafka UI** :

| Menu | Description |
|------|-------------|
| **Dashboard** | Vue d'ensemble du cluster |
| **Brokers** | Liste des brokers (1 dans notre cas) |
| **Topics** | Liste des topics existants |
| **Consumers** | Groupes de consommateurs |

**‚úÖ Checkpoint 2** : Kafka UI est accessible et affiche le cluster.

---

### √âtape 4 - Lister les topics existants

**Objectif** : Utiliser la CLI Kafka pour lister les topics.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Explication** : Nous ex√©cutons la commande `kafka-topics.sh` √† l'int√©rieur du conteneur Kafka.

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --list
```

**R√©sultat attendu** : Liste vide ou quelques topics internes (commen√ßant par `__`).

**Explication des param√®tres** :

| Param√®tre | Description |
|-----------|-------------|
| `docker exec kafka` | Ex√©cute une commande dans le conteneur `kafka` |
| `/opt/kafka/bin/kafka-topics.sh` | Script de gestion des topics |
| `--bootstrap-server localhost:9092` | Adresse du broker Kafka |
| `--list` | Action : lister les topics |

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Explication** : Nous utilisons un pod √©ph√©m√®re avec l'image Strimzi pour ex√©cuter les commandes Kafka.

**Commande** :

```bash
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-topics.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 --list
```

**R√©sultat attendu** : Liste des topics pr√©-cr√©√©s par Strimzi :

```
bhf-events
bhf-transactions
orders
orders-dlt
orders-retry
```

**Explication des param√®tres** :

| Param√®tre | Description |
|-----------|-------------|
| `kubectl run kafka-cli` | Cr√©e un pod √©ph√©m√®re nomm√© `kafka-cli` |
| `-it --rm` | Interactif et supprim√© apr√®s ex√©cution |
| `--image=quay.io/strimzi/kafka:latest-kafka-4.0.0` | Image Kafka Strimzi |
| `bhf-kafka-kafka-bootstrap:9092` | Service bootstrap interne |
| `--list` | Action : lister les topics |

</details>

---

### √âtape 5 - Cr√©ation d'un topic avec 3 partitions

**Objectif** : Cr√©er un topic nomm√© `bhf-demo` avec 3 partitions.

**Th√©orie** : Les partitions permettent :
- **Parall√©lisme** : Plusieurs consommateurs peuvent lire en parall√®le
- **Scalabilit√©** : Les donn√©es sont distribu√©es sur plusieurs partitions
- **Ordre** : L'ordre est garanti uniquement au sein d'une partition

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create \
  --if-not-exists \
  --topic bhf-demo \
  --partitions 3 \
  --replication-factor 1
```

**R√©sultat attendu** :

```
Created topic bhf-demo.
```

**Explication des param√®tres** :

| Param√®tre | Description |
|-----------|-------------|
| `--create` | Action : cr√©er un topic |
| `--if-not-exists` | Ne pas √©chouer si le topic existe d√©j√† |
| `--topic bhf-demo` | Nom du topic |
| `--partitions 3` | Nombre de partitions |
| `--replication-factor 1` | Facteur de r√©plication (1 car cluster single-node) |

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Option 1 : Via KafkaTopic CR (recommand√©)** :

```bash
cat <<EOF | kubectl apply -n kafka -f -
apiVersion: kafka.strimzi.io/v1
kind: KafkaTopic
metadata:
  name: bhf-demo
  labels:
    strimzi.io/cluster: bhf-kafka
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 604800000
EOF
```

**Option 2 : Via CLI** :

```bash
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-topics.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --create --if-not-exists --topic bhf-demo --partitions 3 --replication-factor 3
```

**R√©sultat attendu** :

```
kafkatopic.kafka.strimzi.io/bhf-demo created
```

> üìù **Note** : En mode K8s avec 3 brokers, utilisez `--replication-factor 3` pour la haute disponibilit√©.

</details>

---

### √âtape 6 - Description du topic

**Objectif** : V√©rifier la configuration du topic cr√©√©.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe \
  --topic bhf-demo
```

**R√©sultat attendu** :

```
Topic: bhf-demo	TopicId: xxxxx	PartitionCount: 3	ReplicationFactor: 1	Configs: 
	Topic: bhf-demo	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
	Topic: bhf-demo	Partition: 1	Leader: 1	Replicas: 1	Isr: 1
	Topic: bhf-demo	Partition: 2	Leader: 1	Replicas: 1	Isr: 1
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Option 1 : Via kubectl** :

```bash
kubectl get kafkatopic bhf-demo -n kafka -o yaml
```

**Option 2 : Via CLI Kafka** :

```bash
kubectl run kafka-cli -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-topics.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --describe --topic bhf-demo
```

**R√©sultat attendu** :

```
Topic: bhf-demo	TopicId: xxxxx	PartitionCount: 3	ReplicationFactor: 3	Configs: 
	Topic: bhf-demo	Partition: 0	Leader: 0	Replicas: 0,1,2	Isr: 0,1,2
	Topic: bhf-demo	Partition: 1	Leader: 1	Replicas: 1,2,0	Isr: 1,2,0
	Topic: bhf-demo	Partition: 2	Leader: 2	Replicas: 2,0,1	Isr: 2,0,1
```

</details>

**Explication de la sortie** :

| Champ | Description |
|-------|-------------|
| `PartitionCount: 3` | Le topic a bien 3 partitions |
| `Leader: X` | Le broker X est leader de la partition |
| `Replicas` | Liste des brokers h√©bergeant une r√©plique |
| `Isr` | In-Sync Replicas : r√©pliques synchronis√©es |

**‚úÖ Checkpoint 3** : Le topic `bhf-demo` existe avec 3 partitions.

---

### √âtape 7 - Production d'un message

**Objectif** : Envoyer un message dans le topic `bhf-demo`.

**Th√©orie** : Le **Producer** est responsable de :
- S√©rialiser les messages
- D√©terminer la partition de destination
- Envoyer les messages au broker

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
# G√©n√©rer un message unique avec timestamp
MSG="hello-bhf-$(date +%s)"
echo "Message √† envoyer: $MSG"

# Envoyer le message
echo "$MSG" | docker exec -i kafka /opt/kafka/bin/kafka-console-producer.sh \
  --bootstrap-server localhost:9092 \
  --topic bhf-demo
```

**R√©sultat attendu** : Pas de message d'erreur (la commande se termine silencieusement).

**üí° Note** : Le flag `-i` permet de passer l'entr√©e standard au conteneur.

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
# G√©n√©rer un message unique avec timestamp
MSG="hello-bhf-$(date +%s)"
echo "Message √† envoyer: $MSG"

# Envoyer le message via pod √©ph√©m√®re
echo "$MSG" | kubectl run kafka-producer -i --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-console-producer.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 --topic bhf-demo
```

**R√©sultat attendu** : Le pod se termine avec succ√®s apr√®s envoi du message.

</details>

---

### √âtape 8 - Consommation du message

**Objectif** : Lire le message envoy√© depuis le topic.

**Th√©orie** : Le **Consumer** est responsable de :
- Souscrire √† un ou plusieurs topics
- Lire les messages depuis les partitions
- G√©rer les offsets (position de lecture)

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
docker exec kafka /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic bhf-demo \
  --from-beginning \
  --timeout-ms 10000
```

**R√©sultat attendu** :

```
hello-bhf-1706390000
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
kubectl run kafka-consumer -it --rm --image=quay.io/strimzi/kafka:latest-kafka-4.0.0 \
  --restart=Never -n kafka -- \
  bin/kafka-console-consumer.sh --bootstrap-server bhf-kafka-kafka-bootstrap:9092 \
  --topic bhf-demo --from-beginning --timeout-ms 10000
```

**R√©sultat attendu** :

```
hello-bhf-1706390000
```

</details>

**Explication des param√®tres** :

| Param√®tre | Description |
|-----------|-------------|
| `--from-beginning` | Lire depuis le d√©but du topic |
| `--timeout-ms 10000` | Timeout de 10 secondes si pas de nouveaux messages |

**‚úÖ Checkpoint 4** : Le message produit a √©t√© consomm√© avec succ√®s.

---

### √âtape 9 - Visualisation dans Kafka UI

**Objectif** : Observer les messages via l'interface graphique.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Actions** :

1. Ouvrez **http://localhost:8080** dans votre navigateur
2. Cliquez sur le cluster **BHF-Training**
3. Dans le menu, cliquez sur **Topics**
4. Cliquez sur le topic **bhf-demo**
5. Cliquez sur l'onglet **Messages**
6. Cliquez sur le bouton **‚ñ∂ Fetch Messages** ou r√©glez sur **Live mode**

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Actions** :

1. R√©cup√©rez l'URL Kafka UI :
   ```bash
   NODE_IP=$(kubectl get nodes -o jsonpath='{.items[0].status.addresses[?(@.type=="InternalIP")].address}')
   echo "Kafka UI: http://$NODE_IP:30808"
   ```
2. Ouvrez **http://<NODE_IP>:30808** dans votre navigateur
3. Cliquez sur le cluster **bhf-kafka**
4. Dans le menu, cliquez sur **Topics**
5. Cliquez sur le topic **bhf-demo**
6. Cliquez sur l'onglet **Messages**
7. Cliquez sur le bouton **‚ñ∂ Fetch Messages** ou r√©glez sur **Live mode**

</details>

**Ce que vous devez voir** :

- Le message `hello-bhf-XXXX` appara√Æt dans la liste
- La partition d'affectation (0, 1 ou 2)
- L'offset du message
- Le timestamp

**üí° Exploration suppl√©mentaire** :

- Onglet **Overview** : statistiques du topic
- Onglet **Partitions** : r√©partition des partitions
- Onglet **Settings** : configuration du topic

**‚úÖ Checkpoint 5** : Le message est visible dans Kafka UI.

---

### √âtape 10 - Validation automatis√©e

**Objectif** : Ex√©cuter le script de validation pour confirmer que tout fonctionne.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
./day-01-foundations/module-01-cluster/scripts/validate.sh
```

**R√©sultat attendu** :

```
OK
```

**Ce que le script v√©rifie** :
1. ‚úÖ Le conteneur `kafka` est en cours d'ex√©cution
2. ‚úÖ Le conteneur `kafka-ui` est en cours d'ex√©cution
3. ‚úÖ Kafka UI r√©pond sur le port 8080
4. ‚úÖ Le topic `bhf-demo` existe avec 3 partitions
5. ‚úÖ Un message peut √™tre produit et consomm√©

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

**Commande** :

```bash
./day-01-foundations/module-01-cluster/scripts/validate.sh --k8s
```

**R√©sultat attendu** :

```
OK
```

**Ce que le script v√©rifie** :
1. ‚úÖ Le cluster Kafka est en √©tat `Ready`
2. ‚úÖ Les pods Kafka sont en √©tat `Running`
3. ‚úÖ Kafka UI est accessible
4. ‚úÖ Le topic `bhf-demo` existe avec 3 partitions
5. ‚úÖ Un message peut √™tre produit et consomm√©

</details>

---

## ‚úÖ R√©capitulatif des checkpoints

### üê≥ Mode Docker

| # | Checkpoint | Statut |
|---|------------|--------|
| 1 | Conteneurs `kafka` et `kafka-ui` sont healthy | ‚òê |
| 2 | Kafka UI accessible sur http://localhost:8080 | ‚òê |
| 3 | Topic `bhf-demo` cr√©√© avec 3 partitions | ‚òê |
| 4 | Message produit et consomm√© via CLI | ‚òê |
| 5 | Message visible dans Kafka UI | ‚òê |
| 6 | Script `validate.sh` retourne OK | ‚òê |

### ‚ò∏Ô∏è Mode OKD/K3s

| # | Checkpoint | Statut |
|---|------------|--------|
| 1 | Cluster Kafka `bhf-kafka` est Ready | ‚òê |
| 2 | Kafka UI accessible sur http://<NODE_IP>:30808 | ‚òê |
| 3 | Topic `bhf-demo` cr√©√© avec 3 partitions | ‚òê |
| 4 | Message produit et consomm√© via kubectl | ‚òê |
| 5 | Message visible dans Kafka UI | ‚òê |
| 6 | Script `validate.sh --k8s` retourne OK | ‚òê |

---

## üîß Troubleshooting

### üê≥ Mode Docker

#### Probl√®me : Kafka ne d√©marre pas

**Sympt√¥me** : Le conteneur `kafka` reste en `starting` ou `unhealthy`.

**Solutions** :

1. **V√©rifiez les logs** :
   ```bash
   docker logs kafka --tail 50
   ```

2. **Red√©marrez le cluster** :
   ```bash
   ./scripts/down.sh
   ./scripts/up.sh
   ```

3. **Nettoyez les volumes** (perte de donn√©es) :
   ```bash
   docker volume rm bhf-kafka_kafka-data
   ```

#### Probl√®me : Kafka UI non accessible

**Sympt√¥me** : http://localhost:8080 ne r√©pond pas.

**Solutions** :

1. **V√©rifiez que kafka-ui est running** :
   ```bash
   docker ps | grep kafka-ui
   ```

2. **V√©rifiez les logs** :
   ```bash
   docker logs kafka-ui --tail 50
   ```

3. **V√©rifiez qu'un autre service n'utilise pas le port 8080** :
   ```bash
   # Linux/Mac
   lsof -i :8080
   # Windows
   netstat -ano | findstr :8080
   ```

#### Probl√®me : Commande kafka-topics.sh non trouv√©e

**Sympt√¥me** : `kafka-topics: command not found`

**Solution** : Utilisez le chemin complet `/opt/kafka/bin/kafka-topics.sh`.

---

### ‚ò∏Ô∏è Mode OKD/K3s

#### Probl√®me : Kafka cluster non Ready

**Sympt√¥me** : `kubectl get kafka -n kafka` affiche `READY: False`.

**Solutions** :

1. **V√©rifiez les √©v√©nements** :
   ```bash
   kubectl describe kafka bhf-kafka -n kafka
   ```

2. **V√©rifiez les logs de l'op√©rateur Strimzi** :
   ```bash
   kubectl logs -n kafka -l name=strimzi-cluster-operator --tail=50
   ```

3. **V√©rifiez les pods Kafka** :
   ```bash
   kubectl get pods -n kafka
   kubectl logs -n kafka bhf-kafka-broker-0 --tail=50
   ```

#### Probl√®me : Kafka UI non accessible

**Sympt√¥me** : http://<NODE_IP>:30808 ne r√©pond pas.

**Solutions** :

1. **V√©rifiez le pod Kafka UI** :
   ```bash
   kubectl get pods -n kafka -l app=kafka-ui
   kubectl logs -n kafka -l app=kafka-ui --tail=50
   ```

2. **V√©rifiez le service NodePort** :
   ```bash
   kubectl get svc kafka-ui -n kafka
   ```

3. **V√©rifiez le firewall** :
   ```bash
   sudo ufw status
   # Si actif, ouvrir le port
   sudo ufw allow 30808/tcp
   ```

#### Probl√®me : Pod kafka-cli reste en Pending

**Sympt√¥me** : Le pod √©ph√©m√®re ne d√©marre pas.

**Solutions** :

1. **Supprimez les pods orphelins** :
   ```bash
   kubectl delete pod kafka-cli kafka-producer kafka-consumer -n kafka --ignore-not-found
   ```

2. **V√©rifiez les ressources du cluster** :
   ```bash
   kubectl top nodes
   kubectl describe nodes
   ```

---

## üßπ Nettoyage

**Objectif** : Arr√™ter et supprimer l'environnement.

<details>
<summary>üê≥ <b>Mode Docker</b></summary>

**Commande** :

```bash
./scripts/down.sh
```

**R√©sultat attendu** :

```
Stopping Kafka KRaft SINGLE NODE...
[+] Running 3/3
 ‚úî Container kafka-ui         Removed
 ‚úî Container kafka            Removed
 ‚úî Volume bhf-kafka_kafka-data Removed
‚úÖ Kafka KRaft single-node stopped and cleaned up!
```

</details>

<details>
<summary>‚ò∏Ô∏è <b>Mode OKD/K3s</b></summary>

> ‚ö†Ô∏è **Attention** : Le nettoyage en mode K8s supprime le cluster Kafka complet. N'utilisez que si n√©cessaire.

**Supprimer uniquement le topic bhf-demo** :

```bash
kubectl delete kafkatopic bhf-demo -n kafka
```

**Nettoyage complet** (utiliser le script) :

```bash
sudo ./infra/Scripts/06-cleanup.sh --kafka
```

**Ce que le script supprime** :
- Le cluster Kafka `bhf-kafka`
- Les KafkaNodePools (brokers, controllers)
- Les topics cr√©√©s
- Les PVCs de donn√©es
- Kafka UI

</details>

---

## üìñ Pour aller plus loin

### Exercices suppl√©mentaires

1. **Cr√©ez un topic avec 5 partitions** et observez la distribution dans Kafka UI
2. **Produisez 10 messages** et observez comment ils sont r√©partis sur les partitions
3. **Utilisez une cl√©** lors de la production pour garantir l'ordre :
   ```bash
   echo "key1:message1" | docker exec -i kafka /opt/kafka/bin/kafka-console-producer.sh \
     --bootstrap-server localhost:9092 \
     --topic bhf-demo \
     --property "parse.key=true" \
     --property "key.separator=:"
   ```

### Ressources

- [Documentation officielle Apache Kafka](https://kafka.apache.org/documentation/)
- [KRaft Mode Documentation](https://kafka.apache.org/documentation/#kraft)
- [Kafka UI GitHub](https://github.com/provectus/kafka-ui)

---

## ‚û°Ô∏è Module suivant

Une fois ce module termin√©, passez au :

üëâ **[Module 02 - Fiabilit√© du Producteur](../module-02-producer-reliability/README.md)**
