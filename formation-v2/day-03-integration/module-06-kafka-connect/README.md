# üîå Module 06 - Kafka Connect : Int√©gration de Donn√©es

| Dur√©e | Niveau | Pr√©requis |
|-------|--------|-----------|
| 2 heures | Interm√©diaire | Modules 01-05 compl√©t√©s |

## üéØ Objectifs d'apprentissage

√Ä la fin de ce module, vous serez capable de :

- ‚úÖ Comprendre l'architecture de Kafka Connect
- ‚úÖ D√©ployer un connecteur Source (fichier ‚Üí Kafka)
- ‚úÖ D√©ployer un connecteur Sink (Kafka ‚Üí fichier)
- ‚úÖ Configurer et monitorer les connecteurs

---

## üìö Partie Th√©orique (30%)

### 1. Introduction √† Kafka Connect

#### Qu'est-ce que Kafka Connect ?

**Kafka Connect** est un framework d'int√©gration de donn√©es scalable et fiable pour connecter Kafka √† des syst√®mes externes (bases de donn√©es, fichiers, APIs, etc.).

```mermaid
flowchart LR
    subgraph sources["SOURCES"]
        DB1[("üóÑÔ∏è DB")]
        FILE1["üìÑ Files"]
        API1["üåê API"]
    end
    
    subgraph connect["KAFKA CONNECT"]
        SC["üîå Source<br/>Connector"]
        SK["üîå Sink<br/>Connector"]
    end
    
    subgraph kafka["KAFKA"]
        T[("üì¶ Topics")]
    end
    
    subgraph sinks["SINKS"]
        DB2[("üóÑÔ∏è DB")]
        FILE2["üìÑ Files"]
        S3["‚òÅÔ∏è S3"]
    end
    
    sources --> SC --> T --> SK --> sinks
    
    style connect fill:#e3f2fd
```

#### Concepts cl√©s

| Concept | Description |
|---------|-------------|
| **Connector** | Plugin qui d√©finit comment se connecter √† un syst√®me externe |
| **Task** | Unit√© de travail parall√©lisable du connecteur |
| **Worker** | Processus JVM qui ex√©cute les connecteurs et tasks |
| **Converter** | Transforme les donn√©es entre Kafka et le format du connecteur |

---

### 2. Types de connecteurs

```mermaid
flowchart TB
    subgraph source["üì• SOURCE CONNECTOR"]
        direction TB
        EXT1["External System<br/>(DB, File)"] -->|READ| SRC["üîå Source Connector"]
        SRC -->|PRODUCE| KT1[("üì¶ Kafka Topics")]
    end
    
    subgraph sink["üì§ SINK CONNECTOR"]
        direction TB
        KT2[("üì¶ Kafka Topics")] -->|CONSUME| SNK["üîå Sink Connector"]
        SNK -->|WRITE| EXT2["External System<br/>(DB, File, S3)"]
    end
    
    style source fill:#e8f5e9
    style sink fill:#fff3cd
```

#### Connecteurs populaires

| Type | Connecteur | Usage |
|------|------------|-------|
| Source | JDBC Source | Importer depuis SQL |
| Source | Debezium | CDC (Change Data Capture) |
| Source | FileStream | Importer depuis fichiers |
| Sink | JDBC Sink | Exporter vers SQL |
| Sink | Elasticsearch | Indexation |
| Sink | S3 Sink | Archivage cloud |

---

### 3. Modes de d√©ploiement

```mermaid
flowchart LR
    subgraph standalone["üíª STANDALONE"]
        W1["Worker<br/>Connector + Task"]
    end
    
    subgraph distributed["‚òÅÔ∏è DISTRIBUTED"]
        W2["Worker 1<br/>Task A, C"]
        W3["Worker 2<br/>Task B, D"]
    end
    
    style standalone fill:#fff3cd
    style distributed fill:#e8f5e9
```

| Mode | Avantages | Inconv√©nients |
|------|-----------|---------------|
| **Standalone** | Simple, Dev/Test | Non HA, Single machine |
| **Distributed** | Scalable, Fault-tolerant | Plus complexe |

---

### 4. Configuration d'un connecteur

```json
{
  "name": "file-source-connector",
  "config": {
    "connector.class": "FileStreamSource",
    "tasks.max": "1",
    "file": "/data/input.txt",
    "topic": "file-topic",
    "key.converter": "org.apache.kafka.connect.storage.StringConverter",
    "value.converter": "org.apache.kafka.connect.storage.StringConverter"
  }
}
```

#### Param√®tres essentiels

| Param√®tre | Description |
|-----------|-------------|
| `connector.class` | Classe Java du connecteur |
| `tasks.max` | Nombre max de tasks parall√®les |
| `key.converter` | Convertisseur pour les cl√©s |
| `value.converter` | Convertisseur pour les valeurs |

---

## üîå Ports et Services

| Service | Port | Description |
|---------|------|-------------|
| Kafka Connect | 8083 | REST API |
| Kafka UI | 8080 | Interface web |
| Kafka | 9092 | Broker |

---

## üõ†Ô∏è Partie Pratique (70%)

### Pr√©requis

```bash
cd formation-v2/
./scripts/up.sh
```

---

### √âtape 1 - D√©marrer Kafka Connect

```bash
docker compose -f day-03-integration/module-06-kafka-connect/docker-compose.module.yml up -d
```

**V√©rification** :

```bash
# Attendre le d√©marrage (30-60 secondes)
sleep 30

# V√©rifier le statut
curl -s http://localhost:8083/ | jq
```

**R√©sultat attendu** :

```json
{
  "version": "3.6.0",
  "commit": "...",
  "kafka_cluster_id": "..."
}
```

---

### √âtape 2 - Lab 1 : Lister les plugins disponibles

```bash
curl -s http://localhost:8083/connector-plugins | jq '.[].class'
```

**R√©sultat attendu** : Liste des connecteurs disponibles (FileStreamSource, FileStreamSink, etc.)

---

### √âtape 3 - Lab 2 : Cr√©er un Source Connector

**Objectif** : Lire un fichier et envoyer son contenu vers Kafka.

#### 3.1 Cr√©er le fichier source

```bash
docker exec kafka-connect sh -c 'echo "Hello Kafka Connect" > /tmp/source-data.txt'
docker exec kafka-connect sh -c 'echo "Line 2" >> /tmp/source-data.txt'
docker exec kafka-connect sh -c 'echo "Line 3" >> /tmp/source-data.txt'
```

#### 3.2 Cr√©er le connecteur

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "file-source",
    "config": {
      "connector.class": "FileStreamSource",
      "tasks.max": "1",
      "file": "/tmp/source-data.txt",
      "topic": "file-topic"
    }
  }'
```

#### 3.3 V√©rifier le statut

```bash
curl -s http://localhost:8083/connectors/file-source/status | jq
```

**R√©sultat attendu** :

```json
{
  "name": "file-source",
  "connector": { "state": "RUNNING" },
  "tasks": [{ "id": 0, "state": "RUNNING" }]
}
```

#### 3.4 V√©rifier les messages dans Kafka

```bash
docker exec kafka kafka-console-consumer \
  --topic file-topic \
  --from-beginning \
  --max-messages 3 \
  --bootstrap-server localhost:9092
```

---

### √âtape 4 - Lab 3 : Cr√©er un Sink Connector

**Objectif** : √âcrire les messages Kafka vers un fichier.

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "file-sink",
    "config": {
      "connector.class": "FileStreamSink",
      "tasks.max": "1",
      "file": "/tmp/sink-output.txt",
      "topics": "file-topic"
    }
  }'
```

**V√©rifier le fichier de sortie** :

```bash
docker exec kafka-connect cat /tmp/sink-output.txt
```

---

### √âtape 5 - Lab 4 : Ajouter des donn√©es en temps r√©el

```bash
# Ajouter des lignes au fichier source
docker exec kafka-connect sh -c 'echo "New line 4" >> /tmp/source-data.txt'
docker exec kafka-connect sh -c 'echo "New line 5" >> /tmp/source-data.txt'

# V√©rifier la propagation
sleep 5
docker exec kafka-connect cat /tmp/sink-output.txt
```

---

### √âtape 6 - Lab 5 : Gestion des connecteurs

#### 6.1 Lister tous les connecteurs

```bash
curl -s http://localhost:8083/connectors | jq
```

#### 6.2 Obtenir la configuration

```bash
curl -s http://localhost:8083/connectors/file-source/config | jq
```

#### 6.3 Mettre en pause

```bash
curl -X PUT http://localhost:8083/connectors/file-source/pause
curl -s http://localhost:8083/connectors/file-source/status | jq '.connector.state'
```

#### 6.4 Reprendre

```bash
curl -X PUT http://localhost:8083/connectors/file-source/resume
```

#### 6.5 Supprimer

```bash
curl -X DELETE http://localhost:8083/connectors/file-source
```

---

## ‚úÖ Checkpoint de validation

- [ ] Kafka Connect d√©marr√© et accessible sur :8083
- [ ] Source connector cr√©√© et RUNNING
- [ ] Messages visibles dans le topic file-topic
- [ ] Sink connector cr√©√© et √©crit dans le fichier
- [ ] Donn√©es en temps r√©el propag√©es
- [ ] Connecteurs g√©rables via REST API

---

## üîß Troubleshooting

### Connecteur en √©tat FAILED

```bash
# Voir les erreurs
curl -s http://localhost:8083/connectors/file-source/status | jq '.tasks[0].trace'

# Red√©marrer la task
curl -X POST http://localhost:8083/connectors/file-source/tasks/0/restart
```

### Kafka Connect ne d√©marre pas

```bash
docker logs kafka-connect --tail 100 | grep -i error
```

---

## üßπ Nettoyage

```bash
# Supprimer les connecteurs
curl -X DELETE http://localhost:8083/connectors/file-source
curl -X DELETE http://localhost:8083/connectors/file-sink

# Arr√™ter le module
docker compose -f day-03-integration/module-06-kafka-connect/docker-compose.module.yml down
```

---

## üìñ Pour aller plus loin

### Exercices suppl√©mentaires

1. **Cr√©ez un connecteur JDBC** pour importer depuis une base de donn√©es
2. **Configurez un SMT** (Single Message Transform) pour modifier les messages
3. **Testez le mode distribu√©** avec plusieurs workers

### Ressources

- [Kafka Connect Documentation](https://kafka.apache.org/documentation/#connect)
- [Confluent Hub](https://www.confluent.io/hub/) - Marketplace de connecteurs
- [Debezium](https://debezium.io/) - CDC pour Kafka
